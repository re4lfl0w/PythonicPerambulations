<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Pythonic Perambulations</title><link href="/" rel="alternate"></link><link href="/feeds/jake-vanderplas.atom.xml" rel="self"></link><id>/</id><updated>2014-10-16T09:30:00-07:00</updated><entry><title>How Bad Is Your Colormap?</title><link href="/blog/2014/10/16/how-bad-is-your-colormap/" rel="alternate"></link><updated>2014-10-16T09:30:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-10-16:blog/2014/10/16/how-bad-is-your-colormap/</id><summary type="html">&lt;p&gt;{% notebook HowBadIsYourColormap.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>On Frequentism and Fried Chicken</title><link href="/blog/2014/09/02/on-frequentism-and-fried-chicken/" rel="alternate"></link><updated>2014-09-02T16:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-09-02:blog/2014/09/02/on-frequentism-and-fried-chicken/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;My recent series of posts on &lt;a href="http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/"&gt;Frequentism and Bayesianism&lt;/a&gt; have drawn a lot of comments, but recently Frederick J. Ross, a UW colleague whom I have not yet had the pleasure of meeting, penned a particularly strong-worded critique: &lt;a href="http://madhadron.com/posts/2014-08-30-frequentist_and_bayesian_statistics.html"&gt;Bayesian vs frequentist: squabbling among the ignorant&lt;/a&gt;. Here I want to briefly explore and respond to the points he makes in the post.
&lt;!-- PELICAN_END_SUMMARY --&gt;&lt;/p&gt;
&lt;p&gt;Mr. Ross doesn't mince words. He starts as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Every so often some comparison of Bayesian and frequentist statistics comes to my attention. Today it was on a blog called &lt;a href="http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/"&gt;Pythonic Perambulations&lt;/a&gt;. It's the work of amateurs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He goes on to lodge specific complaints about subtleties I glossed-over in the four posts, all of which seem to miss one salient detail: the posts were an explicit response to my observation that "many scientific researchers never have opportunity to learn the distinctions between Frequentist and Bayesian methods and the different practical approaches that result..." That is, I aimed the discussion not toward someone with a deep background in statistics, but at someone who &lt;em&gt;can't even name the fundamental differences between frequentism and Bayesianism.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Did I gloss over advanced subtleties in this introductory primer? Certainly. As interesting as it may have been for Mr. Ross and other well-read folks had I delved into, say, the deeper questions of assumptions implicit in &lt;a href="http://www.stat.berkeley.edu/~stark/Preprints/constraintsPriors12.pdf"&gt;frequentist constraints vs. Bayesian priors&lt;/a&gt;, it would have distracted from the purpose of the posts, and would have lost the very readers for whom the posts were written.&lt;/p&gt;
&lt;h2&gt;Rethinking the Debate&lt;/h2&gt;
&lt;p&gt;Thus, we see that his first set of complaints can be chalked-up to a simple misunderstanding of the intended audience: that's an honest mistake, and I won't make more of it. But he goes beyond this, and proposes his own final answer to the centuries-old debate between frequentists and Bayesians. As he writes: "Which one is right? The answer, as usual when faced with a dichotomy, is neither."&lt;/p&gt;
&lt;p&gt;This should pique your interest: he's claiming that not only am I, a humble blogger, an ignorant amateur (which may be true), but that luminaries of the science and statistics world &amp;mdash; people like Neyman, Pearson, Fisher, Jaynes, Jeffreys, Savage, and many others who sometimes ardently addressed this question &amp;mdash; are simply ignorant squabblers within the field which they all but created. I doubt I'm alone in finding this sweeping indictment a bit suspect.&lt;/p&gt;
&lt;p&gt;But let's skip these charges and dig further: what third route does Mr. Ross propose to trample all this precedent?  The answer is decision theory:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Probability, as a mathematical theory, has no need of an interpretation... the real battleground is statistics, and the real purpose is to choose an action based on data. The formulation that everyone uses for this, from machine learning to the foundations of Bayesian statistics, is decision theory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;His argument is that frequentist and Bayesian methods, in a reductionist sense, are both simply means of reaching a decision based on data, and can therefore be viewed as related branches of decision theory. He goes on to define some notation which explains how any statistical procedure can be formulated as a question of progressing from data, via some loss function, to a particular decision. Frequentist and Bayesian approaches are simply manifestations of this unified theory which use particular loss functions, and thus squabbling about them is the pastime of the ignorant.&lt;/p&gt;
&lt;p&gt;I'd like to offer an analogy in response to this idea.&lt;/p&gt;
&lt;h2&gt;Baked or Fried?&lt;/h2&gt;
&lt;p&gt;One day in the kitchen, two chefs begin arguing about who makes the best chicken. Chef Hugh prefers his chicken fried: the quick action of the hot oil results light, crispy spiced outer breading complementing the tender meat it encloses. Chef Wolfgang, on the other hand, swears by baked chicken, asserting that its gentler process leaves more moisture, and allows more time for complex flavors to seep into the meat. They decide to have a cook-off: Fried vs. Baked, to decide once and for all which method is the best.&lt;/p&gt;
&lt;p&gt;They're just beginning their preparations in the test kitchen when Rick, the local Food Theorist, storms through the door. He follows these chefs on Twitter, and has heard about this great Fried vs. Baked debate. Given his clear expertise on the matter, he wants to offer his final say on the question. As Food Theorists are wont to do, he starts lecturing them:&lt;/p&gt;
&lt;p&gt;"Truly, I'm not really sure what this whole contest is about. Don't you know that baking and frying are both doing essentially the same thing? Proteins denature as they heat. Water evaporates, sugar caramelizes, and the Maillard Reaction turns carbohydrates and amino acids into a crispy crust. If you could just get into your ignorant heads that any cooking method is simply a manifestation of these simple principles, you'd realize that neither method is better, and we wouldn't need to waste our time on this silly competition."&lt;/p&gt;
&lt;p&gt;At this point, Chef Hugh and Chef Wolfgang pause, catch each other's gaze for a moment, and burst into a hearty laughter. They turn around continue the task of actually turning the raw chicken meat into an edible meal, enjoying the craft and camaraderie of cooking even in the midst of their friendly disagreement. Rick slips out the door and heads home to gaze at his navel while eating a dinner of microwaved pizza bagels.&lt;/p&gt;
&lt;h2&gt;Baked or Fried? Bayesian or Frequentist?&lt;/h2&gt;
&lt;p&gt;So what's my point here? The fact is that everything our Food Theorist has said is technically correct: from a completely reductionist perspective, cooking meat is nothing more than controlled denaturing of proteins, evaporation of water, and other well-understood chemical processes. But to &lt;em&gt;actually prepare a meal&lt;/em&gt;, you can't stop with the theory. You have to figure out how to apply that knowledge in practice, and that requires decisions about whether to use an oven, a deep fryer, or a charcoal grill.&lt;/p&gt;
&lt;p&gt;Similarly, everything Mr. Ross said in his blog post is more or less true, but you can't stop there. Applying his decision theory in practice requires making some choices: despite his protests, you actually &lt;em&gt;do&lt;/em&gt; have to decide how to map your theory of probability onto reality reflected in data, and that requires some actual philosophical choices about how you treat probability, which lead to fundamentally different questions being answered.&lt;/p&gt;
&lt;h2&gt;Frequentism vs. Bayesianism, Again&lt;/h2&gt;
&lt;p&gt;This brings us back to the original question Mr. Ross (not I) posed: Frequentism vs. Bayesianism: which is correct? As I've maintained throughout my posts (and as Mr. Ross seems to have overlooked when reading them): neither is correct. Or both. It really depends on the situation. As I have attempted to make clear, if you're asking questions about long-term limiting frequencies of repeated processes, classical frequentist approaches are probably your best bet. If you're hoping to update your knowledge about the world based on a finite set of data, Bayesian approaches are more appropriate.&lt;/p&gt;
&lt;p&gt;While I have argued that Frequentist approaches &lt;a href="https://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/"&gt;answer the wrong question&lt;/a&gt; in most scientific settings, I have never claimed that frequentism is fundamentally flawed, or that it is "wrong": on the contrary, in that particular post I went to great length to use Monte Carlo simulations to show that the frequentist approach &lt;em&gt;does&lt;/em&gt; in fact give the correct answer to the question it asks. Frequentist and Bayesian approaches answer different statistical questions, and that is a fact you must realize in order to use them.&lt;/p&gt;
&lt;p&gt;So where does this leave us? Well, Mr. Ross seems to have based his critique largely on misunderstandings: my intended audience was novices rather than experts, and despite his claims otherwise I have never held either the frequentist or Bayesian approach as globally correct at the expense of the other. His protests notwithstanding, I maintain that in practice, frequentism and Bayesianism remain as different as fried and baked chicken: you can huff and puff about unified theoretical frameworks until your face is blue, but at the end of the day you need to choose between the oven and the fryer.&lt;/p&gt;</summary></entry><entry><title>Hacking Academia: Data Science and the University</title><link href="/blog/2014/08/22/hacking-academia/" rel="alternate"></link><updated>2014-08-22T08:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-08-22:blog/2014/08/22/hacking-academia/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;&lt;em&gt;A reflection on our &lt;a href="http://www.digital-science.com/sciencefoo/"&gt;SciFoo&lt;/a&gt; breakout session, where we discussed issues of data science within academia.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Almost a year ago, I wrote a post I called the &lt;a href="http://jakevdp.github.io/blog/2013/10/26/big-data-brain-drain/"&gt;Big Data Brain Drain&lt;/a&gt;, lamenting the ways that academia is neglecting the skills of modern data-intensive research, and in doing so is driving away many of the men and women who are perhaps best equipped to enable progress in these fields. This seemed to strike a chord with a wide range of people, and has led me to some incredible opportunities for conversation and collaboration on the subject. One of those conversations took place at the recent SciFoo conference, and this article is my way of recording some reflections on that conversation.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.digital-science.com/sciencefoo/"&gt;SciFoo&lt;/a&gt; is an annual gathering of several hundred scientists, writers, and thinkers sponsored by Digital Science, Nature, O'Reilly Media &amp;amp; Google. SciFoo brings together an incredibly eclectic group of people: I met philosophers, futurists, alien hunters, quantum physicists, mammoth cloners, magazine editors, science funders, astrophysicists, musicians, mycologists, mesmerists, and many many more: the list could go on and on. The conference is about as unstructured as it can be: the organizers simply provide food, drink, and a venue for conversation, and attendees put together breakout discussions on nearly any imaginable topic. If you ever get the chance to go, my advice is to drop everything else and attend. It was one of the most quirky and intellectually stimulating weekends I've ever spent.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;The SciFoo meeting is by invitation only, and given the incredible work of other attendees, I'm still not quite sure how I ended up on the invite list (it was perhaps the worst flare-up of impostor syndrome I've ever had!) I forced myself to get over it, though, and teamed-up with Chris Mentzel, a program director in the &lt;a href="http://www.moore.org/"&gt;Moore Foundation&lt;/a&gt;, and led a session: we called it &lt;em&gt;Hacking Academia from Inside and Out&lt;/em&gt;. The session was in many ways a conversation around the general topic of my &lt;em&gt;Brain Drain&lt;/em&gt; post, though it was clear that many of the folks in attendance had been thinking in these terms long before I penned that particular essay.&lt;/p&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;The problem we discussed is laid out in some detail in my &lt;a href="http://jakevdp.github.io/blog/2013/10/26/big-data-brain-drain/"&gt;Brain Drain&lt;/a&gt; post, but a quick summary is this: scientific research in many disciplines is becoming more and more dependent on the careful analysis of large datasets. This analysis requires a skill-set as broad as it is deep: scientists must be experts not only in their own domain, but in statistics, computing, algorithm building, and software design as well. Many researchers are working hard to attain these skills; the problem is that academia's reward structure is not well-poised to reward the value of this type of work. In short, time spent developing high-quality reusable software tools translates to less time writing and publishing, which under the current system translates to little hope for academic career advancement.&lt;/p&gt;
&lt;p&gt;In my &lt;em&gt;Brain Drain&lt;/em&gt; post, I observed the rise of data-intensive research and lamented that researchers with the requisite interdisciplinary knowledge are largely unrecognized and unrewarded in academia, even as they are highly-sought-after in the tech industry.
I previously labeled this type of person a "new breed of scientist", but since then it's become clear that the working label for this type of person has become (for better or worse) a &lt;em&gt;data scientist&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Defining Data Science&lt;/h2&gt;
&lt;p&gt;The term "Data Science" generally seems to get a bad rap: it's variously dismissed as &lt;a href="http://insideanalysis.com/2013/08/a-data-science-rant/"&gt;misleading&lt;/a&gt;, an &lt;a href="http://www.forbes.com/sites/gilpress/2013/08/19/data-science-whats-the-half-life-of-a-buzzword/"&gt;empty buzzword&lt;/a&gt;, or begrudgingly conceded to be &lt;a href="http://radar.oreilly.com/2011/05/data-science-terminology.html"&gt;flawed, but useful&lt;/a&gt;. Perhaps "Data Scientist" can be understood as just a more subdued term for the &lt;a href="http://www.nytimes.com/2009/08/06/technology/06stats.html"&gt;"sexy statistician"&lt;/a&gt; that Hal Varian predicted would become the top career of this decade.&lt;/p&gt;
&lt;p&gt;I think the best illustration of data science's definition comes from Drew Conway's &lt;a href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram"&gt;Data Science Venn Diagram&lt;/a&gt;, which applies the label "Data Science" to the intersection of hacking skills, statistical knowledge, and domain expertise.&lt;/p&gt;
&lt;p&gt;{% img /images/Data_Science_VD.png 440 440 %}&lt;/p&gt;
&lt;p&gt;The key is that in addition to the normal depth of knowledge in one's own field, there as a rare breadth to the knowledge and skill-set of a data scientist.&lt;/p&gt;
&lt;p&gt;In the words of Alex Szalay, these sorts of researchers must be "Pi-shaped" as opposed to the more traditional "T-shaped" researcher.
In Szalay's view, a classic PhD program generates &lt;em&gt;T-shaped&lt;/em&gt; researchers: scientists with wide-but-shallow general knowledge, but deep skill and expertise in one particular area.
The new breed of scientific researchers, the data scientists, must be &lt;em&gt;Pi-shaped&lt;/em&gt;: that is, they maintain the same wide breadth, but push deeper both in their own subject area and in the statistical or computational methods that help drive modern research:&lt;/p&gt;
&lt;p&gt;{% img /images/pi_shaped.png 440 440 %}&lt;/p&gt;
&lt;p&gt;Perhaps neither of these labels or descriptions is quite right. Another school of thought on data science is Jim Gray's idea of the &lt;a href="http://research.microsoft.com/en-us/collaboration/fourthparadigm/"&gt;"Fourth Paradigm"&lt;/a&gt; of scientific discovery: First came the observational insights of empirical science; second were the mathematically-driven insights of theoretical science; third were the simulation-driven insights of computational science. The fourth paradigm involves primarily data-driven insights of modern scientific research.
Perhaps just as the scientific method morphed and grew through each of the previous paradigmatic transitions, so should the scientific method across all disciplines be modified again for this new data-driven realm of knowledge.&lt;/p&gt;
&lt;p&gt;Regardless of what metaphor, definition, or label you apply to this class of researcher, it is clear that their skill set is highly valuable in both academia and industry: the brain drain that many have observed comes from the unfortunate fact that academia fails to properly reward the valuable skill set of the data scientist.&lt;/p&gt;
&lt;h2&gt;Our Discussion: Academia and Data Science&lt;/h2&gt;
&lt;p&gt;With this label in mind, our SciFoo discussion focused largely around the following questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Where does Data Science fit within the current structure of the university?&lt;/li&gt;
&lt;li&gt;What is it that academic data scientists want from their career? How can academia offer that?&lt;/li&gt;
&lt;li&gt;What drivers might shift academia toward recognizing &amp;amp; rewarding data scientists in domain fields?&lt;/li&gt;
&lt;li&gt;Recognizing that graduates will go on to work in both academia and industry, how do we best prepare them for success in both worlds?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I'll go through some of the thoughts we discussed below:&lt;/p&gt;
&lt;h3&gt;1. Where does Data Science fit within the current structure of the university?&lt;/h3&gt;
&lt;p&gt;The question of data science's place in academia drew a variety of responses and ideas:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The "Fourth Paradigm": data science is simply a label for a new skill-set, and shouldn't be separated from the departments in which it is useful.&lt;/strong&gt; The thinking here is that data science is simply an umbrella term for an essential skill in modern scientific research. For example, laboratory biologists are dependent on pipetting skills: this doesn't mean that the university should create a new "Department of Applied Pipetting". On the contrary, it simply means that pipetting technique should be part of a laboratory biologist's normal training. Similarly, departments across the university should simply incorporate relevant data science techniques into their normal curriculum.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data science as a consulting service.&lt;/strong&gt; Perhaps data science is more like Information Technologies (IT). All modern science labs depend on some sort of computer infrastructure, and most universities long ago realized that it's counter-productive to expect their specialized researchers to effectively manage that infrastructure. Instead, IT organizations were created which provide these services to multiple departments. Data science might be treated the same way: we can't expect every scientist to be fluent in the statistical and computational methods required to work with large datasets, so we might instead out-source these tasks to data science experts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data science as an applied computer science department.&lt;/strong&gt; There has been a trend in the 20th-century of academic subjects splitting into "pure" and "applied" sub-domains. Many Universities have departments of "applied math" and "applied physics", which (loosely speaking) distinguish themselves from the non-applied version by employing the techniques of the field within practical rather than theoretical contexts. Perhaps data science is best viewed as an applied branch of computer science or of statistics which should become its own academic department.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data science as a new role for libraries.&lt;/strong&gt; It is no secret that digitization is changing the role of libraries on university campuses. The general public thinks of libraries little more than warehouses for books, but those in the field see printed books as just one particular manifestation of their focus, which has always been &lt;em&gt;data curation&lt;/em&gt;. Many library scientists I've talked with recently are excited about the role that new methods and technologies can play in this task of curating and extracting information from their stores of data. From this perspective, Library &amp;amp; Information Science departments may be a natural home for interdisciplinary data science.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data science as a new interdisciplinary institute.&lt;/strong&gt; A middle ground to the above approaches may be to organize data science within an interdisciplinary institute; this is a common approach for topics that are inherently multi-disciplinary. Such institutes are already common in academia: for example, the University of Washington is home to the &lt;a href="http://jisao.washington.edu/"&gt;Joint Institute for the Study of Atmosphere and Ocean&lt;/a&gt;, which brings together dozens of &lt;a href="http://jisao.washington.edu/about/collaborators"&gt;department, schools, and labs&lt;/a&gt; to collaborate on topics related to the climate and the environment. Perhaps such an umbrella institute is the place for data science in the University.&lt;/p&gt;
&lt;h3&gt;2. What is it that academic data scientists want from their job? How can academia offer that?&lt;/h3&gt;
&lt;p&gt;Moving from university-level issues to personal-level issues, we brainstormed a list of goals that drive data scientists within academia and industry. While scientists are by no means a homogeneous group, most are driven by some combination of the following concerns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Salary &amp;amp; other financial compensation&lt;/li&gt;
&lt;li&gt;Stability: the desire to live in one place rather than move every few years&lt;/li&gt;
&lt;li&gt;Opportunity for Advancement&lt;/li&gt;
&lt;li&gt;Respect of Peers&lt;/li&gt;
&lt;li&gt;Opportunity to work on open source software projects&lt;/li&gt;
&lt;li&gt;Opportunity to travel &amp;amp; attend conferences&lt;/li&gt;
&lt;li&gt;Flexibility to work on interesting projects&lt;/li&gt;
&lt;li&gt;Opportunity to publish / freedom from the burden of publishing&lt;/li&gt;
&lt;li&gt;Opportunity to teach / freedom from the burden of teaching&lt;/li&gt;
&lt;li&gt;Opportunity to mentor students / freedom from the burden of mentoring students&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I've tried to generally order these from "perks of industry" to "perks of academia" from the perspective of a recently-minted PhD, but this rough one-dimensional categorization misses the variety of opportunities in both worlds. For example, some academic research scientists do not spend time teaching or mentoring students, and some tech industry jobs contain the type of flexibility usually associated with academic research.&lt;/p&gt;
&lt;p&gt;Those younger participants in our conversation who have most recently been "in the game", so to speak, especially noted problems in academia with the first three points. Compared to an industry data scientist position, an academic post-doc has some distinct disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Money: the &lt;a href="http://grants.nih.gov/grants/guide/notice-files/NOT-OD-14-046.html"&gt;NIH postdoc salary&lt;/a&gt; hovers somewhere around $\$$40,000 - $\$$50,000 per year. Industry often starts recent PhDs at several times that salary.&lt;/li&gt;
&lt;li&gt;Stability: before finding a permanent position, it is common now for young scientists to do several short-term post-doctoral appointments, often in different corners of the country. This means that many academics cannot expect to root themselves in a community until their mid-30s or later. For an industry data scientist, on the other hand, there may be many attractive and permanent job options near home.&lt;/li&gt;
&lt;li&gt;Advancement: those who focus on software and data in academia, rather than a breakneck pace of publication, have little hope for a tenure-track position under the current system. A researcher who spends significant time building software tools can expect little reward within academia, no matter how influential those tools might be.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Anecdotally, these seem to be the top three issues for talented data scientists in academia. With the tech-industry market for data scientists as hot as it is, skilled PhD candidates have many compelling incentives to leave their field of research.&lt;/p&gt;
&lt;h3&gt;3. What drivers might shift academia toward recognizing &amp;amp; rewarding data scientists in domain fields?&lt;/h3&gt;
&lt;p&gt;We discussed several drivers that might make academia a more friendly place for data scientists. Generally, these centered around notions of changing the current broken reward structure to recognize success metrics other than classic publication or citation counts. These drivers may be divided into two different categories: those outside academia who might push for change (e.g. funding agencies, publishers, etc.) and those inside academia who might implement the change themselves (e.g. university leadership and department leadership). We discussed the following ideas:&lt;/p&gt;
&lt;h4&gt;From the outside:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Publishers might provide a means of publishing code as a primary research project. Introducing a DOI for software with easy means of updating contributor lists over time, for example, might lead to increased citation and recognition of alternative research activities.&lt;/li&gt;
&lt;li&gt;Publishers might push for reproducibility as a requirement for publication. Reproducibility of data-intensive research requires the well-engineered code that data scientists can produce, and would increase the value placed on these skills.&lt;/li&gt;
&lt;li&gt;Funding agencies might provide funding specifically for interdisciplinary data scientists within specific domain fields.&lt;/li&gt;
&lt;li&gt;Funding agencies might encourage interdisciplinary collaboration through specific grant requirements.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;From the inside:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;University leadership might set aside funding for new data science departments or for interdisciplinary institutes focused on data science.&lt;/li&gt;
&lt;li&gt;University leadership might create joint positions: e.g. paying half of a professor or researcher's salary so that he or she can focus that time on tasks such as creating, maintaining, or teaching about important software tools.&lt;/li&gt;
&lt;li&gt;Department leadership might take the lead to adapt their curriculum to include data science topics, and specifically hire faculty who emphasize these areas in their work.&lt;/li&gt;
&lt;li&gt;Department leadership might adjust their hiring practice to recognize alternative metrics that go beyond the H-index: for example, recognizing the importance of an open source software tool that is well-used, but may not generate a classic citation record.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;4. Recognizing that graduates will go on to work in both academia and industry, how do we best prepare them for success in both worlds?&lt;/h3&gt;
&lt;p&gt;This question is the flip-side of the &lt;em&gt;Brain Drain&lt;/em&gt; theme: the number of PhDs granted each year far exceeds the number of academic positions available, so it is simply impossible for every graduate to remain in academia.&lt;/p&gt;
&lt;p&gt;This is, for some reason, a somewhat taboo subject in academia: I've talked to many who at the end of their PhD program were leaning toward leaving academia, and dreaded having "the talk" with their thesis advisor.
But academic departments should take seriously the job prospects for their graduates, and that involves making sure they have marketable skills upon graduation.&lt;/p&gt;
&lt;p&gt;Fortunately, these marketable skills overlap highly with the skills that can lead to success in modern data-intensive scientific research: the ability to design and write good software, to create tools that others can reuse, to collaboratively work on large software projects, to effectively extract insight from large datasets, etc.
Unfortunately, development of this skill set takes time and energy at the level of both graduate coursework and research mentorship.
Departments should push to make sure that their students are learning these skills, and are rewarded for exercising them: this will have the happy side-effect of increasing demand within academia for the scientists who nurture these skills.&lt;/p&gt;
&lt;h2&gt;Hacking Academia: How is this problem being addressed?&lt;/h2&gt;
&lt;p&gt;At the beginning of the SciFoo conference, each of the ~250 people present were invited to introduce themselves with a one line description of who they are and what they spend their time thinking about.
The title of this post, &lt;em&gt;Hacking Academia&lt;/em&gt;, is a phrase that I borrowed from Chris Mentzel's one-line description of his own focus.&lt;/p&gt;
&lt;p&gt;This is hacking not in the Hollywood sense of using computers for malicious purposes, but hacking in the sense of working within a rigid system to accomplish something it is not necessarily designed to do.
This type of "institutional hacking" is the best description of what we're after: finding shortcuts that will mold the world of academic scientific research into a more effective version of itself.&lt;/p&gt;
&lt;p&gt;Complaining about the state of academia is a favorite past-time of academics, but it is far rarer to see actual solutions to these problems.
One of the best pieces of the SciFoo discussion was just this: hearing about the steps that various individuals, foundations, and institutions are taking to address the concerns outlined above. I'll mention a few examples here:&lt;/p&gt;
&lt;h3&gt;UW, Berkeley, NYU: The Moore-Sloan Initiative&lt;/h3&gt;
&lt;p&gt;As I mentioned, my co-conspirator in leading this session was Chris, whom I know through his involvement with the recent &lt;a href="http://www.moore.org/programs/science/data-driven-discovery/data-science-environments"&gt;Moore-Sloan Data Science Initiative&lt;/a&gt;.
For years within his role in the Moore Foundation, Chris has been thinking about these issues from the perspective of a funder of scientific research. His efforts in this area have recently led to this $\$$38 million initiative, which is built around a five-year grant to three institutions: University of Washington, University of California Berkeley, and New York University.
One of the primary and explicit goals of the grant is to jump-start new career paths for data scientists in scientific domain fields, and each of the three universities has a team who is approaching the work in their own way.&lt;/p&gt;
&lt;p&gt;In January, I was hired by UW's &lt;a href="http://escience.washington.edu/"&gt;eScience Institute&lt;/a&gt; to help lead the UW portion of this effort. We are in the middle of building a data science studio space that will be a central hub for multi-disciplinary data-intensive research on campus, and are currently in the process of hiring our first round of interdisciplinary postdocs, data scientists, and research scientists. These positions are designed especially to attract those skilled "Pi-shaped" researchers who may fall through the cracks in classic academic tracks, and we place particular value on alternative metrics such as open source contributions and efforts toward reproducibility. Berkeley and NYU are undertaking similar efforts on their own campuses with the &lt;a href="http://vcresearch.berkeley.edu/datascience/bids"&gt;Berkeley Institute for Data Science&lt;/a&gt; and NYU's &lt;a href="http://cds.nyu.edu/"&gt;Center for Data Science&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;The Moore Foundation: Data Driven Discovery&lt;/h3&gt;
&lt;p&gt;The Moore Foundation is not stopping with this Data Science Initiative. They will soon be announcing their &lt;a href="http://www.moore.org/programs/science/data-driven-discovery"&gt;Data Driven Discovery&lt;/a&gt; grant winners: 14 individuals who will split a total of $\$$21 million over five years, along with up to $\$$9 million in additional grants to scale-up specific data-driven software and methods. The Moore foundation seems intent on using their endowment to effect real change in this area, and I am excited to see the results (I can assure you that I'm not just saying this because they currently pay my salary!)&lt;/p&gt;
&lt;h3&gt;NSF: the IGERT program&lt;/h3&gt;
&lt;p&gt;The NSF's long-standing Interactive Graduate Education and Research Traineeship (IGERT) program provides funding for interdisciplinary training for PhDs and postdocs, and recent grants in particular have had a data science focus. UW was &lt;a href="http://escience.washington.edu/education/IGERT/overview"&gt;recently awarded&lt;/a&gt; an IGERT grant for an interdisciplinary data-focused PhD program, and the first group of these students will be starting this fall. An important piece of this was that home departments agreed to allow these students to forego some of their normal degree requirements to make room for joint courses on data science skills and techniques. IGERT remains an active NSF program, and has similar interdisciplinary grants to schools and departments around the United States.&lt;/p&gt;
&lt;h3&gt;UW: Provost's Data Science Initiative&lt;/h3&gt;
&lt;p&gt;At UW, the university-wide leadership is also thinking along these lines with some concrete actions of their own: the provost has set aside funding for half-positions to encourage hiring of interdisciplinary faculty. The next Astronomy professor hired by UW, for example, might spend half of his or her time working and teaching through the eScience institute on general computational and data science methods.&lt;/p&gt;
&lt;h3&gt;Publishing Code: the Journal of Statistical Software&lt;/h3&gt;
&lt;p&gt;Though this isn't a recent initiative, the &lt;a href="http://www.jstatsoft.org/"&gt;Journal of Statistical Software&lt;/a&gt; (JSS) is an example of a non-profit publisher which is having a positive impact in the area of statistical software, by giving scientists a forum to publish the software they write and cite the software they use. Perhaps in part because of the extreme usefulness of well-written, reusable software, JSS is very highly-ranked (see, for example, the &lt;a href="http://www.scimagojr.com/journalrank.php?category=2613"&gt;SCImago rankings&lt;/a&gt;). More journals like this, which place explicit value on reproducible computation and well-written software tools, could be a huge benefit to the academic data scientist. &lt;em&gt;(full disclosure: I'm on the editorial board of JSS).&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Harvard University: Initiative in Innovative Computing &amp;amp; Institute for Advanced Computational Science&lt;/h3&gt;
&lt;p&gt;Alyssa Goodman of Harvard was part of our discussion, and mentioned that nearly a decade ago Harvard foresaw and began addressing the value of interdisciplinary data-intensive science and research. They created a short-lived &lt;a href="http://iic.seas.harvard.edu/"&gt;Initiative in Innovative Computing (IIC)&lt;/a&gt;, which existed from 2005-2009, until the global financial crisis led its funding to be cut. At its peak, the IIC was supported to the tune of around $4 million per year and was home to roughly 40 staff, most working jointly between the IIC and other departments.
After the IIC funding dissipated, it seems that most of this momentum (and many of the IIC staff) moved to the Harvard's &lt;a href="http://iacs.seas.harvard.edu"&gt;Institute for Advanced Computational Science (IACS)&lt;/a&gt;, started by Tim Kaxiras and the Harvard School of Engineering in 2010.  Though IACS has traditionally focused more on simulation and computation, it has recently begun to branch out to visualization and data science as well. Alyssa seems optimistic that momentum in this area is again building, and mentioned also Harvard's &lt;a href="http://www.iq.harvard.edu/"&gt;Institute for Quantitative Social Science&lt;/a&gt;, the &lt;a href="http://projects.iq.harvard.edu/seamlessastronomy"&gt;Seamless Astronomy Program&lt;/a&gt;, and the Library as key players.&lt;/p&gt;
&lt;h3&gt;Michigan State: new Applied Computation Department&lt;/h3&gt;
&lt;p&gt;Another active participant in the discussion was Steve Hsu, Vice President for Research at Michigan State University. He shared some exciting news about a new development at Michigan State: the creation of a new department, tentatively called &lt;em&gt;Applied Computation and Mathematics&lt;/em&gt;. According to Steve, MSU will soon be hiring around twenty interdisciplinary tenure-track faculty, who will have one foot in their home department and one foot in this new department. MSU already has many impressive researchers working in data-intensive areas across the university: with this effort I'm excited to see the dynamic interdisciplinary community they will build.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The SciFoo discussion was excellent, as was the weekend as a whole: I would like to take this chance to thank O'Reilly Media, Digital Science, Nature Publishing Group, and Google for making it all possible.&lt;/p&gt;
&lt;p&gt;Nearly a year after my &lt;em&gt;Brain Drain&lt;/em&gt; brain dump, I am thrilled to see that there are so many good people thinking about and working on these problems, and so many real solutions both in process and on the horizon.
While the lure of a well-funded tech industry will doubtless still attract a steady stream of scientists away from their academic research, I'm heartened to see such focused effort toward carving-out niches within academia for those who have so much to contribute.&lt;/p&gt;</summary></entry><entry><title>Frequentism and Bayesianism IV: How to be a Bayesian in Python</title><link href="/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/" rel="alternate"></link><updated>2014-06-14T09:30:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-06-14:blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/</id><summary type="html">&lt;p&gt;{% notebook FreqBayes4.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Frequentism and Bayesianism III: Confidence, Credibility, and why Frequentism and Science do not Mix</title><link href="/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/" rel="alternate"></link><updated>2014-06-12T12:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-06-12:blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/</id><summary type="html">&lt;p&gt;{% notebook FreqBayes3.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Is Seattle Really Seeing an Uptick In Cycling?</title><link href="/blog/2014/06/10/is-seattle-really-seeing-an-uptick-in-cycling/" rel="alternate"></link><updated>2014-06-10T08:30:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-06-10:blog/2014/06/10/is-seattle-really-seeing-an-uptick-in-cycling/</id><summary type="html">&lt;p&gt;{% notebook SeattleCycling.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Frequentism and Bayesianism II: When Results Differ</title><link href="/blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/" rel="alternate"></link><updated>2014-06-06T02:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-06-06:blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/</id><summary type="html">&lt;p&gt;{% notebook FreqBayes2.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Why Python is Slow: Looking Under the Hood</title><link href="/blog/2014/05/09/why-python-is-slow/" rel="alternate"></link><updated>2014-05-09T07:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-05-09:blog/2014/05/09/why-python-is-slow/</id><summary type="html">&lt;p&gt;{% notebook WhyPythonIsSlow.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>An Introduction to the Python Buffer Protocol</title><link href="/blog/2014/05/05/introduction-to-the-python-buffer-protocol/" rel="alternate"></link><updated>2014-05-05T16:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-05-05:blog/2014/05/05/introduction-to-the-python-buffer-protocol/</id><summary type="html">&lt;p&gt;{% notebook BufferProtocol.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Frequentism and Bayesianism: A Practical Introduction</title><link href="/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/" rel="alternate"></link><updated>2014-03-11T11:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-03-11:blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/</id><summary type="html">&lt;p&gt;{% notebook FreqBayes.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>D3 Plugins: Truly Interactive Matplotlib In Your Browser</title><link href="/blog/2014/01/10/d3-plugins-truly-interactive/" rel="alternate"></link><updated>2014-01-10T16:00:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2014-01-10:blog/2014/01/10/d3-plugins-truly-interactive/</id><summary type="html">&lt;p&gt;{% notebook mpld3_plugins.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>A D3 Viewer for Matplotlib Visualizations</title><link href="/blog/2013/12/19/a-d3-viewer-for-matplotlib/" rel="alternate"></link><updated>2013-12-19T13:00:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-12-19:blog/2013/12/19/a-d3-viewer-for-matplotlib/</id><summary type="html">&lt;p&gt;{% notebook mpld3Demo.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Static Interactive Widgets for IPython Notebooks</title><link href="/blog/2013/12/05/static-interactive-widgets/" rel="alternate"></link><updated>2013-12-05T19:00:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-12-05:blog/2013/12/05/static-interactive-widgets/</id><summary type="html">&lt;p&gt;{% notebook IPythonWidgets.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Kernel Density Estimation in Python</title><link href="/blog/2013/12/01/kernel-density-estimation/" rel="alternate"></link><updated>2013-12-01T08:00:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-12-01:blog/2013/12/01/kernel-density-estimation/</id><summary type="html">&lt;p&gt;{% notebook KDEBench.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>The Big Data Brain Drain: Why Science is in Trouble</title><link href="/blog/2013/10/26/big-data-brain-drain/" rel="alternate"></link><updated>2013-10-26T13:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-10-26:blog/2013/10/26/big-data-brain-drain/</id><summary type="html">&lt;p&gt;&lt;em&gt;Update, August 2014: see &lt;a href="/blog/2014/08/22/hacking-academia/"&gt;Hacking Academia&lt;/a&gt;, my most recent reflection on this subject.&lt;/em&gt;&lt;/p&gt;
&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;Regardless of what you might think of the ubiquity of the "Big Data" meme, it's clear that the growing size of datasets is changing the way we approach the world around us.  This is true in fields from industry to government to media to academia and virtually everywhere in between. Our increasing abilities to gather, process, visualize, and learn from large datasets is helping to push the boundaries of our knowledge.&lt;/p&gt;
&lt;p&gt;But where scientific research is concerned, this recently accelerated shift to data-centric science has a dark side, which boils down to this: &lt;strong&gt;the skills required to be a successful scientific researcher are increasingly indistinguishable from the skills required to be successful in industry.&lt;/strong&gt; While academia, with typical inertia, gradually shifts to accommodate this, the rest of the world has already begun to embrace and reward these skills to a much greater degree. &lt;em&gt;The unfortunate result is that some of the most promising upcoming researchers are finding no place for themselves in the academic community, while the for-profit world of industry stands by with deep pockets and open arms.&lt;/em&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;&lt;/p&gt;
&lt;h2&gt;The Unreasonable Effectiveness of Data&lt;/h2&gt;
&lt;p&gt;In 1960, the physicist Eugene Wigner published his famous essay, &lt;a href="http://en.wikipedia.org/wiki/The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences"&gt;&lt;em&gt;The Unreasonable Effectiveness of Mathematics in the Natural Sciences&lt;/em&gt;&lt;/a&gt;.  It expounds on the surprising extent to which abstract mathematical concepts seem to hold validity in contexts far beyond those in which they were developed. After all, who would have guessed that Riemann's 19th century studies in non-Euclidean geometry would form the basis of Einstein's rethinking of gravitation, or that a codification of the rotation groups of abstract solids might eventually lead physicists to successfully predict the existence of the Higgs Boson?&lt;/p&gt;
&lt;p&gt;Echoing this, in 2009 Google researchers Alon Halevy, Peter Norvig, and Fernando Pereira penned an article under the title &lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/35179.pdf"&gt;&lt;em&gt;The Unreasonable Effectiveness of Data&lt;/em&gt;&lt;/a&gt;.  In it, they describe the surprising insight that given enough data, often the choice of mathematical model stops being as important &amp;mdash; that particularly for their task of automated language translation, "simple models and a lot of data trump more elaborate models based on less data."&lt;/p&gt;
&lt;p&gt;If we make the leap and assume that this insight can be at least partially extended to fields beyond natural language processing, what we can expect is a situation in which domain knowledge is increasingly trumped by "mere" data-mining skills. I would argue that this prediction has already begun to pan-out: &lt;strong&gt;in a wide array of academic fields, the ability to effectively process data is superseding other more classical modes of research.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, I'm not arguing here that domain understanding is entirely obsolete; after all the &lt;a href="http://home.web.cern.ch/about/computing"&gt;10GB/second&lt;/a&gt; produced by the Large Hadron Collider (LHC) would be virtually useless apart from a solid theoretical understanding of the particle interactions that produce them, just as the &lt;a href="http://www.lsst.org/lsst/public/tour_software"&gt;15TB/night&lt;/a&gt; of raw image data produced by the Large Synoptic Survey Telescope (LSST) would have very little to tell us about cosmology absent our theoretical insight into the physical processes driving the expansion of the Universe.  But the LHC and LSST reflect the increasingly common situation where scientific results are entirely dependent upon the use of sophisticated methods to analyze large datasets. Indeed, we're finding that even when the data don't quite qualify as "Big", progress in science is increasingly being driven by those with the skills to manipulate, visualize, mine, and learn from data.&lt;/p&gt;
&lt;h2&gt;The New Breed of Scientist&lt;/h2&gt;
&lt;p&gt;In some senses, this data-driven research is simply a continuation of past trends. Since we shed Aristotelianism in the 16th-17th centuries, scientific progress has been largely based on empirical experiment and observation.  It was Tycho Brahe's unprecedented 16th-century survey of the sky, after all, that led to Kepler's 17th century Laws of planetary motion, and paved the way for Newton's Universal Law of Gravitation and eventually Einstein's General Theory of Relativity.  Scientists have always grappled with data; the difference is that today this act of grappling is increasingly central to the scientific process.&lt;/p&gt;
&lt;p&gt;The increasing data-centeredness of science, however, is already leading to new approaches to problems: in the era of the LHC and LSST, the most exciting research is being driven by those who have the expertise to apply high-performance data-parallel statistical algorithms to ask interesting questions of huge, community-generated datasets.  It is driven by the application of new statistical approaches, of new machine learning algorithms, and of new and faster codes to repeat classic analyses at a previously unattainable scale.  &lt;strong&gt;In short, the new breed of scientist must be a broadly-trained expert in statistics, in computing, in algorithm-building, in software design,&lt;/strong&gt; and (perhaps as an afterthought) in domain knowledge as well. From particle physics to genomics to biochemistry to neuroscience to oceanography to atmospheric physics and everywhere in-between, research is increasingly data-driven, and the pace of data collection shows no sign of abating.&lt;/p&gt;
&lt;h2&gt;The Fundamental Role of Scientific Software&lt;/h2&gt;
&lt;p&gt;The common thread here is that of scientific software: none of this work happens without the writing of code.  Unless that code is well-written, well-documented, and shared openly with the community, the reproducibility paramount to the scientific process will be threatened. Much has been written about the current &lt;a href="http://phys.org/news/2013-09-science-crisis.html"&gt;crisis of irreproducibility&lt;/a&gt; in science, about the need for &lt;a href="http://python.6.x6.nabble.com/IPython-Notebooks-dissertations-and-scholarly-publication-td5036272.html"&gt;new forms&lt;/a&gt; of &lt;a href="http://www.elsevier.com/connect/executable-papers-in-computer-science-go-live-on-sciencedirect"&gt;publication&lt;/a&gt;, and new &lt;a href="http://www.openscience.org/blog/?p=686"&gt;openness of access&lt;/a&gt; to research, code, and data.  I won't dwell on those issues here.&lt;/p&gt;
&lt;p&gt;What I will dwell on is the central role of optimized, specialized software in the analysis and visualization of large datasets, and the direct translation of that to its central role in modern scientific research. My collaborator Gael Varoquaux and his colleagues recently published an &lt;a href="http://hal.inria.fr/hal-00858663/en"&gt;editorial&lt;/a&gt; arguing this point (see Gael's short summary &lt;a href="http://gael-varoquaux.info/blog/?p=170"&gt;here&lt;/a&gt;), and making the case that &lt;strong&gt;open, well-documented, and well-tested scientific code is essential not only to reproducibility in modern scientific research, but to the very progression of research itself.&lt;/strong&gt; New research cannot build upon past results if those results are simply mentioned in a paper, with the actual process of producing them trapped in undocumented code hidden somewhere in somebody's laptop. As &lt;a href="http://www-stat.stanford.edu/~wavelab/Wavelab_850/wavelab.pdf"&gt;Buckheit and Donoho&lt;/a&gt; have written,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An article about computational science in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set
of instructions which generated the figures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Making code public might seem like an afterthought, but in general simply releasing code is not enough.  As Brandon Rhodes put it at his &lt;a href="http://13.rupy.eu/"&gt;RuPy 2013 talk&lt;/a&gt;, "The moment a program works, it's better to say that it &lt;em&gt;barely&lt;/em&gt; works".  Making scientific code useful to those beyond the research group that generated it takes a significant amount of investment.  This is the incredible value of projects like NumPy, SciPy, Scikit-learn, and others: they give researchers a framework in which their code is shared, peer-reviewed on github, and released for the benefit of the research community.&lt;/p&gt;
&lt;h2&gt;Academia's Disconnect&lt;/h2&gt;
&lt;p&gt;This brings us to Academia's core problem: despite the centrality of well-documented, well-written software to the current paradigm of scientific research, &lt;strong&gt;academia has been singularly successful at discouraging these very practices that would contribute to its success.&lt;/strong&gt;  In the "publish-or-perish" model which dominates most research universities, any time spent building and documenting software tools is time spent &lt;em&gt;not&lt;/em&gt; writing research papers, which are the primary currency of the academic reward structure.  As a result, except in certain exceptional circumstances, those who focus on reproducible and open software are less likely to build the resume required for promotion within the academic system.  And those poor souls whose gifts lie in scientific software development rather than the writing of research papers will mostly find themselves on the margins of the academic community.&lt;/p&gt;
&lt;p&gt;To an extent, disconnects like this have always existed.  The academic system has always rewarded some skills at the expense of others: teaching is a classic example of an essential skill which is perennially marginalized.  But there are two main differences that make the current discussion more worrying:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;As I've mentioned, the skills now slipping through the cracks of the academic reward structure are the very skills required for the success of modern research.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With virtually the entire world utilizing the tools of data-intensive discovery, the same skills academia now ignores and devalues are &lt;em&gt;precisely&lt;/em&gt; the skills which are most valued and rewarded within industry.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The result of this perfect storm is that skilled researchers feel an insidious gradient out of research and into industry jobs. While software-focused jobs do exist within academia, they tend to be lower-paid positions without the prestige and opportunity for advancement found in the tenure track.  Industry is highly attractive: it is addressing interesting and pressing problems; it offers good pay and benefits; it offers a path out of the migratory rat-wheel of temporary postdoctoral positions, and often even encourages research and publication in fundamental topics.  Most importantly, perhaps, &lt;strong&gt;industry offers positions with a real possibility for prestige and career advancement.&lt;/strong&gt;  It's really a wonder that any of us stay in the academy at all.&lt;/p&gt;
&lt;p&gt;I particularly worry about this in my own field of astronomy and astrophysics.  The &lt;a href="http://www.lsst.org/"&gt;LSST project&lt;/a&gt; is ramping up for first-light toward the end of this decade. Its goal of real-time processing of 30TB of data per night over the course of a decade is incredibly ambitious. To handle this volume of data, the project will likely be looking to hire several dozen data-focused astronomical researchers over the coming years.  Given the required skill set, along with the current compensation level and career outlook of engineering-oriented positions in academia, I have some serious doubts about whether the project will be able to attract a sufficient pool of applicants for these positions.&lt;/p&gt;
&lt;h2&gt;How should Academia Adapt?&lt;/h2&gt;
&lt;p&gt;I'm in no way the only person thinking about these issues.  I've discussed pieces of this topic with many folks from around the country and the world, and I know that there are policy-makers and funding agencies thinking about these very problems. But the practical question of how to address these concerns looms large.  Complaining about the culture of academia seems to be a common past-time of academics: some of what I'm saying here echoes Deirdre McCloskey's &lt;em&gt;Law of Academic Prestige&lt;/em&gt;: "the more useful the field, the lower its prestige".  Though this was originally coined in lamentation of the low status of essential topics like freshman writing and composition, it seems readily applicable to the current subject.&lt;/p&gt;
&lt;p&gt;I would argue that the concept of prestige is the key: the solution to the problem lies in taking deliberate measures within academia to catch-up with industry and increase the prestige of those who work to develop the software tools essential to current data-driven scientific research.  There are a few specific things that researchers, funding agencies, and policy leaders can do to promote this.  Here are a few ideas:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Continue to press the importance of reproducibility in academic publication&lt;/strong&gt;. Not only is this absolutely essential to the scientific process itself, but reproducibility depends on open, well-documented, and well-written code. Making this code an essential part of the publication process will make those with software skills an essential part of the academic community.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Push for a new standard for tenure-track evaluation criteria&lt;/strong&gt;: one which considers the creation and maintenance of open software along with more traditional activities like publication and teaching.  This will remove a main disincentive against investing time producing clean, well-documented, and open code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create and fund a new academic employment track&lt;/strong&gt;, from graduate and post-doctoral fellowships to teaching, research, and tenure-track faculty.  These positions should particularly emphasize and reward the development of open, cross-disciplinary scientific software tools.  Positions like these would present a viable academic career path for those interested in building and maintaining the essential software used by themselves and their colleagues.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Increase the pay of post-doctoral scientific research positions.&lt;/strong&gt;  Some might find this idea controversial, but the current situation is absolutely unsustainable.  The base postdoctoral salary for NIH positions is &lt;a href="http://grants.nih.gov/grants/guide/notice-files/NOT-OD-12-033.html"&gt;under $40,000 per year&lt;/a&gt; for someone who has just completed a PhD in their field. This is generously increased to about $50,000 per year after seven (!) years of post-doctoral experience. Those with the skills mentioned in this article could easily ask for several times that compensation in a first-year industry job, and would find themselves working on interesting problems in a setting where their computational skills are utilized and valued.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I fear that without these sorts of changes in the culture of academia itself, the progress of scientific research will be severely handicapped in the coming years.&lt;/p&gt;
&lt;p&gt;We live in an exciting time, where the depth and breadth of our scientific understanding of the world around us are being driven by an ever accelerating ability to gather, store, process, and learn from datasets of unprecedented size.  To keep up this pace of discovery, the best researchers need incentives to stay within the research community.  It's not an easy problem to address, but with a little effort, we can assure the health and sustainability of the scientific research community into the future.&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;em&gt;I'm indebted to many colleagues for discussions which prompted these thoughts, in particular Bill Howe and Fernando Perez. Thanks also to my good friend Will Mari (&lt;a href="https://twitter.com/willthewordguy"&gt;@willthewordguy&lt;/a&gt;) for reading over this post and giving helpful feedback.&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;</summary></entry><entry><title>Understanding the FFT Algorithm</title><link href="/blog/2013/08/28/understanding-the-fft/" rel="alternate"></link><updated>2013-08-28T13:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-08-28:blog/2013/08/28/understanding-the-fft/</id><summary type="html">&lt;p&gt;{% notebook UnderstandingTheFFT.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>The Game of Life in Python</title><link href="/blog/2013/08/07/conways-game-of-life/" rel="alternate"></link><updated>2013-08-07T16:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-08-07:blog/2013/08/07/conways-game-of-life/</id><summary type="html">&lt;p&gt;{% notebook GameOfLife.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>XKCD Plots in Matplotlib: Going the Whole Way</title><link href="/blog/2013/07/10/XKCD-plots-in-matplotlib/" rel="alternate"></link><updated>2013-07-10T16:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-07-10:blog/2013/07/10/XKCD-plots-in-matplotlib/</id><summary type="html">&lt;p&gt;{% notebook XKCD_sketch_path.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Numba vs. Cython: Take 2</title><link href="/blog/2013/06/15/numba-vs-cython-take-2/" rel="alternate"></link><updated>2013-06-15T08:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-06-15:blog/2013/06/15/numba-vs-cython-take-2/</id><summary type="html">&lt;p&gt;{% notebook NumbaCython.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>IPython Notebook: Javascript/Python Bi-directional Communication</title><link href="/blog/2013/06/01/ipython-notebook-javascript-python-communication/" rel="alternate"></link><updated>2013-06-01T10:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-06-01:blog/2013/06/01/ipython-notebook-javascript-python-communication/</id><summary type="html">&lt;p&gt;{% notebook JSInteraction.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>A Simple Animation: The Magic Triangle</title><link href="/blog/2013/05/28/a-simple-animation-the-magic-triangle/" rel="alternate"></link><updated>2013-05-28T21:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-05-28:blog/2013/05/28/a-simple-animation-the-magic-triangle/</id><summary type="html">&lt;p&gt;{% notebook MagicTriangle.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>A Javascript Viewer for Matplotlib Animations</title><link href="/blog/2013/05/19/a-javascript-viewer-for-matplotlib-animations/" rel="alternate"></link><updated>2013-05-19T07:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-05-19:blog/2013/05/19/a-javascript-viewer-for-matplotlib-animations/</id><summary type="html">&lt;p&gt;{% notebook JSAnimation.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Embedding Matplotlib Animations in IPython Notebooks</title><link href="/blog/2013/05/12/embedding-matplotlib-animations/" rel="alternate"></link><updated>2013-05-12T19:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-05-12:blog/2013/05/12/embedding-matplotlib-animations/</id><summary type="html">&lt;p&gt;{% notebook AnimationEmbedding.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Migrating from Octopress to Pelican</title><link href="/blog/2013/05/07/migrating-from-octopress-to-pelican/" rel="alternate"></link><updated>2013-05-07T17:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-05-07:blog/2013/05/07/migrating-from-octopress-to-pelican/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;After nine months on Octopress, I've decided to move on.&lt;/p&gt;
&lt;p&gt;I should start by saying that Octopress is a great platform for static
blogging: it's powerful, flexible, well-supported, well-integrated with
GitHub pages, and has tools and plugins to do just about anything you might
imagine.  There's only one problem:&lt;/p&gt;
&lt;p&gt;It's written in Ruby.&lt;/p&gt;
&lt;p&gt;Now I don't have anything against Ruby per se.  However, it was starting to
seem a bit awkward that a blog called &lt;em&gt;Pythonic Perambulations&lt;/em&gt;
was built with Ruby, especially given the availability of so many
excellent Python-based static site generators
(&lt;a href="http://hyde.github.io/"&gt;Hyde&lt;/a&gt;,
&lt;a href="http://nikola.ralsina.com.ar/"&gt;Nikola&lt;/a&gt;,
and &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt; in particular).&lt;/p&gt;
&lt;p&gt;Additionally, a few things with Octopress were starting to become difficult:
&lt;!-- PELICAN_END_SUMMARY --&gt;
first, I wanted a way to easily insert IPython notebooks into posts.
Sure, I developed a &lt;a href="/blog/2012/10/04/blogging-with-ipython/"&gt;hackish solution&lt;/a&gt;
to notebooks in Octopress which had worked
well enough for a while, but a cleaner method would have involved
digging into the Ruby source code and writing a full-fledged Octopress
extension, based on nbconvert.  This would have involved a fair bit of effort
to learn Ruby and figure out how to best interface it with the Python nbconvert
code. Second, Ruby has so many strange and difficult pieces:
GemFiles, RVM, rake... and I never took the time to really understand
the real purpose of all of them (self-reflection:
what parts of Python would seem strange and difficult if I hadn't
been using them for so many years?).  The black-box nature of the process,
at least in my own case, was starting to bother me.&lt;/p&gt;
&lt;p&gt;But the kicker was this: In January I got a new computer, and after a reasonable
amount of effort was unable to successfully build my blog.  I've been writing
my posts exclusively on my old laptop which I somehow managed to successfully
set up last August.  But that laptop now has a sorely outdated Ubuntu distro
that I couldn't upgrade for fear of losing the ability to update my blog.
Needless to say, this was not the most effective setup.&lt;/p&gt;
&lt;p&gt;It was time to switch my blog engine to Python.&lt;/p&gt;
&lt;h2&gt;Choosing a Python Static Generator&lt;/h2&gt;
&lt;p&gt;I started asking around, and found that there were three solid contenders for
a Python-based platform to replace Octopress: &lt;a href="http://hyde.github.io/"&gt;Hyde&lt;/a&gt;,
&lt;a href="http://nikola.ralsina.com.ar/"&gt;Nikola&lt;/a&gt;,
and &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt;.  I gave Hyde a test-run a few weeks ago
in re-making my &lt;a href="http://www.astro.washington.edu/users/vanderplas"&gt;website&lt;/a&gt;,
and I really like it: it's clean, straightforward, powerful, and easy to use.
The documentation is a bit lacking, though, and I think it would take a fair
bit more effort at this point to build a more complicated site with Hyde.&lt;/p&gt;
&lt;p&gt;Nikola and Pelican both seem to be well-loved by their users, but I had to
choose one.  I went with Pelican for one simple reason:
it has more GitHub forks.  I'm sure this is entirely
unfair to Nikola and all the contributors who have poured
their energy into the project, but I had to choose one way or another.
I'm pleased to say that Pelican has not been a disappointment:
I've found it to be flexible and powerful.  It has an active developer-base,
and makes available a wide array of themes and plugins.
For the few extra pieces I needed, I found the plugin and theming
API to be well-documented and straightforward to use.&lt;/p&gt;
&lt;h2&gt;Migrating to Pelican from Octopress&lt;/h2&gt;
&lt;p&gt;I won't attempt to write a one-size-fits-all guide to migrating to Pelican
from Octopress: there are too many possibile combinations of formats, plugins,
themes, etc.  But I will walk through my own process in some detail, in hopes
that it might help others who find themselves in a similar predicament.&lt;/p&gt;
&lt;p&gt;I had several goals when doing this migration:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I wanted, as much as possible, to maintain the look and feel of the blog.
  I like the default Octopress theme: it's simple, clean, compact, and
  includes all the aspects I need for a good blog.&lt;/li&gt;
&lt;li&gt;I wanted, as much as possible, to leave the source of my posts unmodified:
  luckily Pelican supports writing posts in markdown and allows easy insertion
  of custom plugins, so this was relatively easy to accommodate.&lt;/li&gt;
&lt;li&gt;I wanted to maintain the history of Disqus comments for each page, as well
  as the Twitter and Google Pages tools.&lt;/li&gt;
&lt;li&gt;I wanted, as much as possible, to maintain the same URLs for all content,
  including posts, notebooks, images, and videos.&lt;/li&gt;
&lt;li&gt;I wanted a clean way to insert html-formatted IPython notebooks into blog
  posts. Nearly half my posts are written as notebooks, and the
  &lt;a href="/blog/2012/10/04/blogging-with-ipython/"&gt;old way&lt;/a&gt; of including them
  was becoming much too cumbersome.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was able to suitably address all these goals with Pelican
in a few evenings' effort.  Some of it was already
built-in to the Pelican settings architecture, some required
customization of themes and extensions, and some required writing some brand
new plugins.  I'll summarize these aspects below:&lt;/p&gt;
&lt;h3&gt;Blog theme&lt;/h3&gt;
&lt;p&gt;As I mentioned, I wanted to keep the look and feel of the blog consistent.
Luckily, someone had gone before me and created an
&lt;a href="https://github.com/duilio/pelican-octopress-theme"&gt;octopress Pelican theme&lt;/a&gt;
which did most of the heavy lifting.  I contributed
a few additional features, including the ability to
&lt;a href="https://github.com/duilio/pelican-octopress-theme/pull/12"&gt;specify Disqus tags&lt;/a&gt;
and maintain comment history, to
&lt;a href="https://github.com/duilio/pelican-octopress-theme/pull/11"&gt;add Twitter, Google Plus, and Facebook&lt;/a&gt; links in the sidebar and footer,
to add a &lt;a href="https://github.com/duilio/pelican-octopress-theme/pull/15"&gt;custom site search&lt;/a&gt;
box which appears in the upper right of the
navigation panel, as well as a few
&lt;a href="https://github.com/duilio/pelican-octopress-theme/pull/14"&gt;other&lt;/a&gt;
&lt;a href="https://github.com/duilio/pelican-octopress-theme/pull/13"&gt;tweaks&lt;/a&gt;.
The result is what you see here: nearly identical to the old layout, with
all the bells and whistles included.&lt;/p&gt;
&lt;h3&gt;Octopress Markdown to Pelican Markdown&lt;/h3&gt;
&lt;p&gt;Octopress has a few plugins which add some syntactic sugar to the markdown
language.  These are tags specified in
&lt;a href="https://github.com/Shopify/liquid"&gt;Liquid&lt;/a&gt;-style syntax:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;literal&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="n"&gt;arg1&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I have made extensive use of these in my octopress posts, primarily to insert
videos, images, and code blocks from file.
In order to accommodate this in Pelican, I wrote
a &lt;a href="https://github.com/getpelican/pelican-plugins/pull/21"&gt;Pelican plugin&lt;/a&gt;
which wraps a custom Markdown preprocessor written via the
&lt;a href="http://pythonhosted.org/Markdown/extensions/api.html"&gt;Markdown extension API&lt;/a&gt;
which can correctly interpret these types of tags.  The tags ported from
octopress thus far are:&lt;/p&gt;
&lt;h4&gt;The Image Tag&lt;/h4&gt;
&lt;p&gt;The image tag allows insertion of an image into the post with a
specified size and position:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;literal&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;position&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is an example of the result of the image tag:&lt;/p&gt;
&lt;p&gt;{% img /images/galaxy.jpg 300 200 A Galaxy %}&lt;/p&gt;
&lt;h4&gt;The Video Tag&lt;/h4&gt;
&lt;p&gt;The video tag allows embedding of an HTML5/Flash-compatible video
into the post:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;literal&lt;/span&gt; &lt;span class="n"&gt;video&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mp4&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;poster&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is an example of the output of the video tag:&lt;/p&gt;
&lt;p&gt;{% video /downloads/videos/animate_square.mp4 240 180 /downloads/videos/animate_square.png %}&lt;/p&gt;
&lt;p&gt;(see &lt;a href="/blog/2012/09/26/optical-illusions-in-matplotlib/"&gt;this post&lt;/a&gt; for a
description of this video).&lt;/p&gt;
&lt;h4&gt;The Code Include Tag&lt;/h4&gt;
&lt;p&gt;The &lt;code&gt;include_code&lt;/code&gt; tag allows the insertion of formatted lines from
a file into the post, with a title and a link to the source file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;literal&lt;/span&gt; &lt;span class="n"&gt;include_code&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is an example of the output of the code include tag:&lt;/p&gt;
&lt;p&gt;{% include_code hello_world.py lang:python Hello World %}&lt;/p&gt;
&lt;p&gt;For more information on using these tags, refer to the
&lt;a href="https://github.com/getpelican/pelican-plugins/pull/21"&gt;module doc-strings&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Maintaining Disqus Comment Threads&lt;/h3&gt;
&lt;p&gt;Static blogs are fast, lightweight, and easy to deploy.  A disadvantage, though,
is the inability to natively include dynamic elements such as comment threads.
&lt;a href="http://disqus.com/"&gt;Disqus&lt;/a&gt;
is a third-party service that skirts this disadvantage very
seamlessly.  All it takes is to add a small javascript snippet with some
identifiers in the appropriate place on your page, and Disqus takes care of
the rest.  To keep the comment history on each page required assuring that
the site identifier and page identifiers remained the same between blog
versions.  This part happens within the theme, and my
&lt;a href="https://github.com/duilio/pelican-octopress-theme/pull/12"&gt;Disqus PR&lt;/a&gt;
to the Pelican Octopress theme made this work correctly.&lt;/p&gt;
&lt;h3&gt;Maintaining the URL structure&lt;/h3&gt;
&lt;p&gt;By default, Octopress stores posts with a structure looking like
&lt;code&gt;blog/YYYY/MM/DD/article-slug/&lt;/code&gt;.  The Pelican default is different, but
easy enough to change.  In the &lt;code&gt;pelicanconf.py&lt;/code&gt;
settings file, this corresponds to the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ARTICLE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;blog&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;:%&lt;/span&gt;&lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;:%&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;:%&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;slug&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;ARTICLE_SAVE_AS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;blog&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;:%&lt;/span&gt;&lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;:%&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;:%&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;slug&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, at the top of the markdown file for each article, the metadata needs
to be slightly modified from the form used by Octopress -- here is the
actual metadata used in the document that generates this page:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Title&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Migrating&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;Octopress&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;Pelican&lt;/span&gt;
&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2013&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;07&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;slug&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;migrating&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;octopress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;pelican&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Additionally, the static elements of the blog (images, videos, IPython
notebooks, code snippets, etc.) must be put within the correct directory
structure.  These static files should be put in paths which are specified
via the &lt;code&gt;STATIC_PATHS&lt;/code&gt; setting:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;STATIC_PATHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;figures&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;downloads&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Pelican presented a challenge here: as of the time of this
writing, Pelican has a hard-coded &lt;code&gt;'static'&lt;/code&gt; subdirectory where these
static paths are saved.  I submitted a
&lt;a href="https://github.com/getpelican/pelican/pull/875"&gt;pull request&lt;/a&gt; to Pelican
that replaces this hard-coded setting with a configurable path: because
the change conflicts with a
&lt;a href="https://github.com/getpelican/pelican/pull/795"&gt;bigger refactoring&lt;/a&gt;
of the code which is ongoing, the PR will not be merged.  But until this
new refactoring is finished, I'll be using
&lt;a href="https://github.com/jakevdp/pelican/tree/specify-static"&gt;my own branch&lt;/a&gt;
of Pelican to make this blog, and specify the correct static paths.&lt;/p&gt;
&lt;h3&gt;Inserting Notebooks&lt;/h3&gt;
&lt;p&gt;The ability to seamlessly insert IPython notebooks into posts was one of the
biggest drivers of my switch to Pelican.  Pelican has an
&lt;a href="http://danielfrg.github.io/blog/2013/03/08/pelican-ipython-notebook-plugin/"&gt;ipython notebook plugin&lt;/a&gt;
available, but I wasn't completely happy with it.  The plugin implements
a reader which treats the notebooks themselves as the source of a post,
leading to the requirement to insert blog metadata into the notebook itself.
This is a suitable solution, but for my own purposes I much prefer a solution
in which the content of a notebook could be inserted into a stand-alone post,
such that the notebook and the blog metadata are completely separate.&lt;/p&gt;
&lt;p&gt;To accomplish this, I added a submodule to my
&lt;a href="https://github.com/jakevdp/pelican-plugins/blob/liquid_tags/liquid_tags/notebook.py"&gt;liquid_tags&lt;/a&gt; Pelican plugin which allows the insertion of notebooks
using the following syntax:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;literal&lt;/span&gt; &lt;span class="n"&gt;notebook&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;notebook&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ipynb&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;cells&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This inserts the notebook at the given location in the post, optionally
selecting a given range of notebook cells with standard Python list slicing
syntax.&lt;/p&gt;
&lt;p&gt;The formatting of notebooks requires some special CSS styles which must
be inserted into the header of each page where notebooks are shown.  Rather
than requiring the theme to be customized to support notebooks, I decided
on a solution where an &lt;code&gt;EXTRA_HEADER&lt;/code&gt; setting is used to specify html
and CSS which
should be added to the header of the main page.  The notebook plugin
saves the required header to a file called &lt;code&gt;_nb_header.html&lt;/code&gt; within
the main source directory.  To
insert the appropriate formatting, we add the following lines to the
settings file, &lt;code&gt;pelicanconf.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;EXTRA_HEADER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;_nb_header&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;utf&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the theme file, within the header tag, we add the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="cp"&gt;{%&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;EXTRA_HEADER&lt;/span&gt; &lt;span class="cp"&gt;%}&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;EXTRA_HEADER&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="cp"&gt;{%&lt;/span&gt; &lt;span class="k"&gt;endif&lt;/span&gt; &lt;span class="cp"&gt;%}&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is the result: a short notebook inserted directly into the post:&lt;/p&gt;
&lt;p&gt;{% notebook TestNotebook.ipynb %}&lt;/p&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;p&gt;With all those things in place, the blog was ready to be built.  The result
is right in front of you: you're reading it.  If you'd like to see the source
from which this blog built, it's available at
&lt;a href="http://www.github.com/jakevdp/PythonicPerambulations"&gt;http://www.github.com/jakevdp/PythonicPerambulations&lt;/a&gt;.  Feel free to adapt the configurations and theme
to suit your own needs.&lt;/p&gt;
&lt;p&gt;I'm glad to be working purely in Python from now on!&lt;/p&gt;</summary></entry><entry><title>Benchmarking Nearest Neighbor Searches in Python</title><link href="/blog/2013/04/29/benchmarking-nearest-neighbor-searches-in-python/" rel="alternate"></link><updated>2013-04-29T08:56:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-04-29:blog/2013/04/29/benchmarking-nearest-neighbor-searches-in-python/</id><summary type="html">&lt;p&gt;{% notebook TreeBench.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Code Golf in Python: Sudoku</title><link href="/blog/2013/04/15/code-golf-in-python-sudoku/" rel="alternate"></link><updated>2013-04-15T16:00:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-04-15:blog/2013/04/15/code-golf-in-python-sudoku/</id><summary type="html">&lt;p&gt;{% notebook SudokuCodeGolf.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Matplotlib and the Future of Visualization in Python</title><link href="/blog/2013/03/23/matplotlib-and-the-future-of-visualization-in-python/" rel="alternate"></link><updated>2013-03-23T08:31:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-03-23:blog/2013/03/23/matplotlib-and-the-future-of-visualization-in-python/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;Last week, I had the privilege of attending and speaking at the
PyCon and PyData conferences in Santa Clara, CA.  As usual, there were some
amazing and inspiring talks throughout: I would highly recommend browsing
through the videos as they are put up on
&lt;a href="http://pyvideo.org/category/33/pycon-us-2013"&gt;pyvideo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One thing I spent a lot of time thinking, talking, and learning about
during these two conferences was the topic of data visualization in Python.
Data visualization seemed to be everywhere: PyData had
&lt;a href="http://sv2013.pydata.org/abstracts/#11"&gt;two&lt;/a&gt;
&lt;a href="http://sv2013.pydata.org/abstracts/#15"&gt;tutorials&lt;/a&gt;
on matplotlib (the second given by yours truly), as well as a talk about
&lt;a href="http://sv2013.pydata.org/abstracts/#41"&gt;NodeBox OpenGL&lt;/a&gt; and a
&lt;a href="http://sv2013.pydata.org/keynotes/#abstract_33"&gt;keynote&lt;/a&gt; by
Fernando Perez about IPython, including the notebook and the
nice interactive data-visualization it allows. Pycon had a tutorial on
&lt;a href="https://us.pycon.org/2013/schedule/presentation/29/"&gt;network visualization&lt;/a&gt;,
a talk on &lt;a href="https://us.pycon.org/2013/schedule/presentation/58/"&gt;generating art&lt;/a&gt;
in Python, and a talk on
&lt;a href="https://us.pycon.org/2013/schedule/presentation/108/"&gt;visualizing Github&lt;/a&gt;. &lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;The latter of these I found to be a bit abstract -- more discussion of visual
design principles than particular tools or results -- but contained one
interesting nugget: though D3 is the current state-of-the-art for
publication-quality online, interactive visualization, practitioners often
use simpler tools like matplotlib or ggplot for their initial data exploration.
This was a thought echoed by Lynn Cherny in her presentation about NodeBox
OpenGL: it has some really nice features which allow the creation of beautiful,
flexible, and interactive graphics within Python.  But if you just want to
scatter-plot x versus y to see what your data looks like, matplotlib might
be a better option.&lt;/p&gt;
&lt;p&gt;I found Lynns talk incredibly interesting, and not just because of the
good-natured heckling I received from the stage!  Her main point was that
in the case of interactive &amp;amp; animated visualization, matplotlib is relatively
limited.  She introduced us to a project called
&lt;a href="http://www.cityinabottle.org/nodebox/"&gt;NodeBox OpenGL&lt;/a&gt;, which is a
cross-platform graphics creation package that has some nice Python bindings,
and can create some absolutely beautiful graphics.  This is one example of a
physics flow visualization, taken from the above website:&lt;/p&gt;
&lt;p&gt;{% img center /images/nodebox-physics-flock.jpg 'NodeBox OpenGL visualization' %}&lt;/p&gt;
&lt;p&gt;Despite Lynns admission that, with regards to the limitations of matplotlib,
I had taken a bit of the wind out of her sails with my interactive matplotlib
tutorial the day before (in which many of the examples I used will be familiar
to readers of this blog), I think her point on the limitations of matplotlib
is very well-put.  Though it remains my tool of choice for data visualization
and the creation of publication-quality scientific graphics, matplotlib is
also a decade-old platform, and sometimes shows its age.&lt;/p&gt;
&lt;h2&gt;Matplotlibs History&lt;/h2&gt;
&lt;p&gt;Matplotlib is a multi-platform data visualization tool built upon the Numpy
and Scipy framework.  It was conceived by John Hunter in 2002, originally as
a patch to IPython to enable interactive MatLab-style plotting via gnuplot
from the IPython command-line.  Fernando Perez was, at the time, scrambling
to finish his PhD, and let John know he wouldnt have time to review the patch
for several months.  John took this as a cue to set out on his own, and the
matplotlib package was born, with version 0.1 released in 2003.  It received
an early boost when it was adopted as the plotting package of choice of the
Space Telescope Science Institute, which financially supported matplotlibs
development and led to greatly expanded capabilities.&lt;/p&gt;
&lt;p&gt;One of matplotlibs most important features is its ability to play well with
many operating systems and graphics backends. John Hunter highlighted this
fact in a keynote talk he gave last summer, shortly before his sudden and
tragic passing (&lt;a href="http://pyvideo.org/video/1192/matplotlib-lessons-from-middle-age-or-how-you"&gt;video link&lt;/a&gt;):
We didnt try to be the best in the beginning, we just tried to be &lt;em&gt;there&lt;/em&gt;...
and fill-in the features as needed.  In this talk, John outlined the reasons
he thinks matplotlib succeeded in outlasting the dozens of competing packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it could be used on any operating system via its array of backends&lt;/li&gt;
&lt;li&gt;it had a familiar interface: one similar to MatLab&lt;/li&gt;
&lt;li&gt;it had a coherent vision: to do 2D graphics, and do them well&lt;/li&gt;
&lt;li&gt;it found early institutional support, from astronomers at STScI and JPL&lt;/li&gt;
&lt;li&gt;it had an outspoken advocate in Hunter himself, who enthusiastically
  promoted the project within the Python world&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Matplotlibs Challenge&lt;/h2&gt;
&lt;p&gt;This cross-platform, everything-to-everyone approach has been one of the great
strengths of matplotlib.  It has led to a large user-base, which in turn
has led to an active developer base and matplotlibs powerful tools and
ubiquity within the scientific Python world.  But as the
world of graphics visualization has changed, this strength has started to
become matplotlibs main weakness.  The hooks into multiple backends work
well for static images, but can be cumbersome and unpredictable for more
dynamic, interactive plots (for example, the animation toolkit still does
not work with the MacOSX backend, and this is
&lt;a href="https://github.com/matplotlib/matplotlib/issues/531"&gt;unlikely to improve&lt;/a&gt;
any time soon).&lt;/p&gt;
&lt;p&gt;Contrast this with one of the other great success stories in the scientific
Python world, the IPython Notebook.  It brings powerful, interactive computing
tools to the fingertips of the user, and works well across all platforms.
The IPython team, rather than spending time creating backend hooks for all
possible graphics toolkits, built the notebook to work in the browser,
effectively outsourcing the cross-platform compatibility problem to browser
providers.  This decision, I believe, is a fundamental piece which enabled
IPython notebook to become so widely adopted during its short existence.
The developers have been freed to spend their time implementing features,
rather than struggling with cross-platform compatibility.  Drawing from this
lesson, I would venture to predict that whichever graphics package is the
community standard five years from now will have adopted this approach as well.&lt;/p&gt;
&lt;p&gt;The matplotlib developers, of course, know this very well.  In his SciPy 2012
keynote mentioned above, John Hunter talked about lessons learned from ten
years of growing matplotlib, the challenges matplotlib faces, and the path
toward the future.  Prominently mentioned among the challenges was the fact
that users have come to expect dynamic, interactive, client-side graphics
rendering seen in popular tools like Protovis and D3.  Further, theyve come
to value and desire graphical tools which fit naturally in the research flow
enabled by the IPython notebook (just look at the spontaneous applause Fernando
received when showing off the IPython notebook/D3 integration in his
&lt;a href="http://www.youtube.com/watch?feature=player_embedded&amp;amp;v=F4rFuIb1Ie4"&gt;PyCon Canada keynote&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I would add one more challenge to that: even simple, static 2D visualization
concepts have come a long way since gnuplot and the advent of matplotlib:
in particular,
&lt;a href="http://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448"&gt;The Grammar of Graphics&lt;/a&gt;
has helped evolve views on best practices for exploratory data visualization.
The ggplot integraion in R is one feature that users cite as a clear advantage
over Python.  Yes, matplotlib is powerful enough to allow implemention of
&lt;a href="http://messymind.net/2012/07/making-matplotlib-look-like-ggplot/"&gt;some of these ideas&lt;/a&gt;,
but its plotting commands remain rather verbose, and its no-frills, default
output looks much more like Excel circa 1993 than ggplot circa 2013. 
(for a quick look at Grammar of Graphics in a Python context, see Peter Wangs
&lt;a href="http://pyvideo.org/video/1224/bokeh-an-extensible-implementation-of-the-gramma"&gt;Bokeh talk&lt;/a&gt; from Scipy 2012).&lt;/p&gt;
&lt;h2&gt;The Future of Visualization in Python&lt;/h2&gt;
&lt;p&gt;Looking toward the future, these are significant challenges for matplotlib.
I have no doubt that with a healthy effort from the development community,
along with a good dose of vision and leadership, matplotlib could adapt and
remain the leading visualization package in Python.  But there are challengers:
&lt;a href="http://www.cityinabottle.org/nodebox/"&gt;NodeBox OpenGL&lt;/a&gt; solves some of the
interactivity problems by providing a powerful interface on a single,
universally available graphics backend.
Packages like &lt;a href="http://code.enthought.com/chaco/"&gt;Chaco&lt;/a&gt; and
&lt;a href="http://code.enthought.com/projects/mayavi/"&gt;MayaVi&lt;/a&gt; push the boundaries in
interaction, extensibility, and 3D capabilities. But all three of these
options are still married to the old server-side paradigm of tools like
matplotlib and gnuplot rather than the client-side paradigm of tools like
IPython notebook, Protovis, and D3.&lt;/p&gt;
&lt;p&gt;A more exciting option right now, in my view, is
&lt;a href="https://github.com/continuumio/bokeh"&gt;Bokeh&lt;/a&gt;, a project of Peter Wang,
Hugo Shi, and others at Continuum Analytics.  Bokeh is an effort to create
a ggplot-inspired graphics package in Python which can produce beautiful,
dynamic data visualizations in the web browser.  Though Bokeh is young and
still missing a lot of features, I think its well-poised to address the
challenges mentioned above.  In particular, its explicitly built around the
ideas of Grammar of Graphics.  It is being designed toward a client-side,
in-browser javascript backend to enable the sharing of interactive graphics,
&lt;em&gt;a la&lt;/em&gt; D3 and Protovis.  And comparing to matplotlibs success story, Bokeh
displays many parallels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Just as matplotlib achieves cross-platform ubiquity using the old model of
  multiple backends, Bokeh achieves cross-platform ubiquity through IPythons
  new model of in-browser, client-side rendering.&lt;/li&gt;
&lt;li&gt;Just as matplotlib uses a syntax familiar to MatLab users, Bokeh uses a
  syntax familiar to R/ggplot users&lt;/li&gt;
&lt;li&gt;Just as matplotlib had a coherent vision of focusing on 2D cross-platform
  graphics, Bokeh has a coherent vision of building a ggplot-inspired,
  in-browser interactive visualization tool&lt;/li&gt;
&lt;li&gt;Just as matplotlib found institutional support from STScI and JPL, Bokeh
  has institutional support from Continuum Analytics and the recent $3 million
  &lt;a href="http://continuum.io/press/continuum-receives-darpa-xdata-funding"&gt;DARPA XDATA grant&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Just as matplotlib had John Hunters vision and enthusiastic advocacy,
  Bokeh has the same from Peter Wang.  Anyone who has met Peter will know
  that once you get him talking about projects hes excited about, its hard
  to make him stop!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Above all that, Bokeh, like matplotlib, is entirely open-sourced.  Now, I
should make clear that Bokeh still has a long way to go.  Its installation
instructions &amp;amp; examples are still a bit incomplete and opaque.  It currently
provides no way of outputting PNG or PDF versions of the graphics it produces.
Many of its goals still lie more firmly in the realm of vision than in the
realm of implementation. But for the reasons I gave above, I think its
a project to keep watching.&lt;/p&gt;
&lt;p&gt;And where does that leave matplotlib?  I would not, by any means, discount
it just yet.
Still, as John Hunter noted last summer, it faces some significant challenges,
particularly in the area of client-rendered, dynamic visualizations.  Any
core matplotlib developers reading this should go back and re-watch Johns
SciPy keynote: it was his last public outline of his vision for the project
he started and led over the course of a decade.  An IPython
notebook-compatible client-side matplotlib viewer along the lines of the
ideas John mentioned at the end of his talk would be the killer app
that would, in all likelihood, allow matlotlib to maintain its position
as the &lt;em&gt;de facto&lt;/em&gt;
standard visualization package for the Scientific Python community.&lt;/p&gt;
&lt;p&gt;And all that being said, regardless of what the future brings, you can be
assured that in the meantime I and many others will still be doing all our
daily work and research using matplotlib. Despite its weaknesses and the
challenges it faces, matplotlib is a powerful tool, and I dont anticipate
it withering away any time soon.&lt;/p&gt;</summary></entry><entry><title>Animating the Lorenz System in 3D</title><link href="/blog/2013/02/16/animating-the-lorentz-system-in-3d/" rel="alternate"></link><updated>2013-02-16T08:05:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-02-16:blog/2013/02/16/animating-the-lorentz-system-in-3d/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;One of the things I really enjoy about Python is how easy it makes it to solve
interesting problems and visualize those solutions in a compelling way. I've
done several posts on creating animations using matplotlib's relatively new
&lt;a href="http://matplotlib.sourceforge.net/api/animation_api.html"&gt;animation toolkit&lt;/a&gt;:
(some examples are a chaotic
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;double pendulum&lt;/a&gt;,
the collisions of
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;particles in a box&lt;/a&gt;,
the time-evolution of a
&lt;a href="/blog/2012/09/05/quantum-python/"&gt;quantum-mechanical wavefunction&lt;/a&gt;,
and even a scene from the classic video game,
&lt;a href="/blog/2013/01/13/hacking-super-mario-bros-with-python/"&gt;Super Mario Bros.&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Recently, a reader &lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/#comment-799781196"&gt;commented&lt;/a&gt; asking whether I might do a 3D animation example.  Matplotlib
has a decent 3D toolkit called
&lt;a href="http://matplotlib.org/mpl_toolkits/mplot3d/index.html"&gt;mplot3D&lt;/a&gt;,
and though I haven't previously seen it used in conjunction with the
animation tools, there's nothing fundamental that prevents it.&lt;/p&gt;
&lt;p&gt;At the commenter's suggestion, I decided to try this out with a simple
example of a chaotic system: the Lorenz equations.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;h2&gt;Solving the Lorenz System&lt;/h2&gt;
&lt;p&gt;The &lt;a href="http://en.wikipedia.org/wiki/Lorenz_system"&gt;Lorenz Equations&lt;/a&gt; are a
system of three coupled, first-order, nonlinear differential equations
which describe the trajectory of a particle through time.
The system was originally derived by Lorenz as a model
of atmospheric convection, but the deceptive simplicity
of the equations have made them an often-used example in fields beyond
atmospheric physics.&lt;/p&gt;
&lt;p&gt;The equations describe the evolution of the spatial variables $x$, $y$,
and $z$, given the governing parameters $\sigma$, $\beta$, and $\rho$,
through the specification of the time-derivatives of the spatial variables:&lt;/p&gt;
&lt;p&gt;${\rm d}x/{\rm d}t = \sigma(y - x)$&lt;/p&gt;
&lt;p&gt;${\rm d}y/{\rm d}t = x(\rho - z) - y$&lt;/p&gt;
&lt;p&gt;${\rm d}z/{\rm d}t = xy - \beta z$&lt;/p&gt;
&lt;p&gt;The resulting dynamics are entirely deterministic giving a starting point
$(x_0, y_0, z_0)$ and a time interval $t$.  Though it looks straightforward,
for certain choices of the parameters $(\sigma, \rho, \beta)$, the
trajectories become chaotic, and the resulting trajectories display some
surprising properties.&lt;/p&gt;
&lt;p&gt;Though no general analytic solution exists for this system, the solutions
can be computed numerically.
Python makes this sort of problem very easy to solve: one can
simply use Scipy's interface to
&lt;a href="https://computation.llnl.gov/casc/odepack/odepack_home.html"&gt;ODEPACK&lt;/a&gt;,
an optimized Fortran package for solving ordinary differential equations.
Here's how the problem can be set up:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;integrate&lt;/span&gt;

&lt;span class="c"&gt;# Note: t0 is required for the odeint function, though it&amp;#39;s not used here.&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;lorentz_deriv&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;t0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;8.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rho&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;28.0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Compute the time-derivative of a Lorenz system.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rho&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;x0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c"&gt;# starting vector&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# one thousand time steps&lt;/span&gt;
&lt;span class="n"&gt;x_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;integrate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;odeint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lorentz_deriv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That's all there is to it!&lt;/p&gt;
&lt;h2&gt;Visualizing the results&lt;/h2&gt;
&lt;p&gt;Now that we've computed these results, we can use matplotlib's
animation and 3D plotting toolkits
to visualize the trajectories of several particles.  Because
I've described the animation tools in-depth in a
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;previous post&lt;/a&gt;,
I will skip that discussion here and jump straight into the code:&lt;/p&gt;
&lt;p&gt;{% include_code lorentz_animation.py lang:python Lorenz System %}&lt;/p&gt;
&lt;p&gt;The resulting animation looks something like this:&lt;/p&gt;
&lt;p&gt;{% video /downloads/videos/lorentz_attractor.mp4 360 270 /downloads/videos/lorentz_attractor_frame.png %}&lt;/p&gt;
&lt;p&gt;Notice that there are two locations in the space that seem to draw-in all
paths: these are the so-called "Lorenz attractors", and have some interesting
properties which you can read about elsewhere.  The qualitative
characteristics of these Lorenz attractors
vary in somewhat surprising ways as the parameters
$(\sigma, \rho, \beta)$ are changed.  If you are so inclined, you may
wish to download the above code and play with these values to see what
the results look like.&lt;/p&gt;
&lt;p&gt;I hope that this brief exercise has shown you the power and flexibility of
Python for understanding and visualizing a large array of problems, and
perhaps given you the inspiration to explore similar problems.&lt;/p&gt;
&lt;p&gt;Happy coding!&lt;/p&gt;</summary></entry><entry><title>Setting Up a Mac for Python Development</title><link href="/blog/2013/02/02/setting-up-a-mac-for-python-development/" rel="alternate"></link><updated>2013-02-02T11:01:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-02-02:blog/2013/02/02/setting-up-a-mac-for-python-development/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;&lt;em&gt;Edit, August 2013: my current favorite way to set up a python installation
on mac (and any other system) is to use the
&lt;a href="https://store.continuum.io/"&gt;anaconda&lt;/a&gt; package offered by Continuum
Analytics.  It's free, full-featured, and extremely easy to use.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;{% img left /images/OSX10.8.png 'OSX 10.8 Logo' %} A few weeks ago,
after years of using Linux exclusively for all my computing,
I started a research fellowship in a new department
and found a brand new Macbook Pro on my
desk.  Naturally, my first instinct was to set up the system for efficient
Python development.  In order to help others who  might find themself in a
similar situation, I took some notes on the process, and I'll summarize
what I learned below.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;First, a disclaimer: I can't promise that these suggestions are the best or most
effective way to proceed.  I'm by no stretch of the imagination
a Mac expert: the last Apple product I used regularly was the trusty
Macintosh Classic my parents bought when I was in middle school.  I
primarily used it for all-day marathons of
&lt;a href="http://en.wikipedia.org/wiki/RoboSport"&gt;RoboSport&lt;/a&gt; and
&lt;a href="http://en.wikipedia.org/wiki/Civilization_%28video_game%29"&gt;Civilization&lt;/a&gt;,
with occasional breaks to teach myself programming in Hypercard. But I digress.&lt;/p&gt;
&lt;p&gt;Before moving on to the summary of what I learned,
I should note that all of the following was done on OSX 10.8: there
will likely be differences between OSX versions.  I've done my best to note
all the relevant details, and I hope you will find this helpful!&lt;/p&gt;
&lt;h2&gt;Accessing the Terminal&lt;/h2&gt;
&lt;p&gt;{% img left /images/OSX_terminal.png 'OSX 10.8 Terminal Icon' %} 
Being from a Linux background, I was interested in setting up a
Linux-like work environment, doing nearly everything from the terminal.
Fortunately, OSX is built on unix, with a terminal integrated into the
operating system.&lt;/p&gt;
&lt;p&gt;To open a terminal, open the finder, click "Applications" and search for
"Terminal".  To make it easier to access in the future, I dragged the icon down
to the &lt;em&gt;dock&lt;/em&gt;, the collection of icons usually found on the bottom or side
of the screen.  Clicking the icon will open a familiar bash terminal that
can be used to explore your Mac in a more user-friendly way.&lt;/p&gt;
&lt;h2&gt;Setting Up MacPorts&lt;/h2&gt;
&lt;p&gt;To set up the rest of the system components, I opted to use MacPorts, which is
a package management system similar to &lt;code&gt;apt&lt;/code&gt; or &lt;code&gt;yum&lt;/code&gt; on ubuntu and
debian systems.  There are probably alternatives to MacPorts, but I found
it very intuitive, quick, and powerful.&lt;/p&gt;
&lt;p&gt;You can download MacPorts for free on the
&lt;a href="http://www.macports.org"&gt;MacPorts website&lt;/a&gt;.  You'll have to install it for
the correct OSX version --  to check which OSX version you're running,
click "about this computer" under the apple icon at the top-left of
the desktop. Unfortunately, I was following the slightly outdated
&lt;a href="http://guide.macports.org/"&gt;MacPorts guide&lt;/a&gt; and got a few errors:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;No&lt;/span&gt; &lt;span class="n"&gt;Xcode&lt;/span&gt; &lt;span class="n"&gt;installation&lt;/span&gt; &lt;span class="n"&gt;was&lt;/span&gt; &lt;span class="n"&gt;found&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;Error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Please&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;Xcode&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;or&lt;/span&gt; &lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="n"&gt;xcode&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;specify&lt;/span&gt; &lt;span class="n"&gt;its&lt;/span&gt; &lt;span class="n"&gt;location&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;Error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;Warning&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;xcodebuild&lt;/span&gt; &lt;span class="n"&gt;exists&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;failed&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;execute&lt;/span&gt;
&lt;span class="n"&gt;Warning&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Xcode&lt;/span&gt; &lt;span class="n"&gt;does&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;appear&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="n"&gt;installed&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="n"&gt;most&lt;/span&gt; &lt;span class="n"&gt;ports&lt;/span&gt; &lt;span class="n"&gt;will&lt;/span&gt; &lt;span class="n"&gt;likely&lt;/span&gt; &lt;span class="n"&gt;fail&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This indicates that &lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;
is not yet installed.  Xcode is a a collection of developer tools for the
Mac, and it can be freely downloaded at the Apple App store.  You'll need
to create an Apple account to access it, and then make sure you have a
fast internet connection: the download is about 1.6GB.  Once it's downloaded,
find the XCode icon in the Applications menu and click to install.&lt;/p&gt;
&lt;p&gt;With this done, I tried installing MacPorts again, but still got an error:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Unable&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;open&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;can&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;t read &amp;quot;build.cmd&amp;quot;: Failed to locate &amp;#39;&lt;/span&gt;&lt;span class="n"&gt;make&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39; in path: &amp;#39;&lt;/span&gt;&lt;span class="sr"&gt;/opt/local/bin:/opt/local/sbin:/bin:/sbin:/usr/bin:/usr/s&lt;/span&gt;&lt;span class="n"&gt;bin&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; &lt;span class="n"&gt;or&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;its&lt;/span&gt; &lt;span class="n"&gt;MacPorts&lt;/span&gt; &lt;span class="n"&gt;configuration&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="n"&gt;location&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;did&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;move&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This indicates that the command-line tools are not installed by default.
To fix this, run Xcode, select Xcode-&amp;gt;preferences from the menu bar, click
downloads, select "command-line tools", and click install.
You'll also need Xorg tools, which I installed through
&lt;a href="http://xquartz.macosforge.org/landing/"&gt;XQuartz&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Installing Python&lt;/h2&gt;
&lt;p&gt;Now that MacPorts is installed, it's very straightforward to install several
versions of Python and other programs.  MacPorts allows access to a standard
repository of programs and packages, which can be explored, downloaded, and
installed using the &lt;code&gt;port&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;First of all, run&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;selfupdate&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;which updates the MacPorts base to the latest release.  Another useful
thing to know about is the MacPorts &lt;code&gt;search&lt;/code&gt; command.  For example, to
see all the available packages which mention "python", use&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will list all the python versions available.  I installed both Python
2.7 and Python 3.3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;python27&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;python33&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you want &lt;code&gt;python&lt;/code&gt; on the command-line to point to a particular version,
this can be specified with the &lt;code&gt;select&lt;/code&gt; command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;select&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;python27&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can now check that typing &lt;code&gt;python --version&lt;/code&gt; in the terminal returns
version 2.7.&lt;/p&gt;
&lt;h2&gt;Installing Numpy, Scipy, etc.&lt;/h2&gt;
&lt;p&gt;My scientific development in Python relies on several packages:
particularly &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt;, &lt;code&gt;ipython&lt;/code&gt;, &lt;code&gt;cython&lt;/code&gt;,
&lt;code&gt;scikits-learn&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, &lt;code&gt;nose&lt;/code&gt;, &lt;code&gt;pep8&lt;/code&gt;, and &lt;code&gt;pip&lt;/code&gt;.
Here is the series of commands to set these up for Python 2.7:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;scipy&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt;

&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tornado&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;zmq&lt;/span&gt;  &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;zmq&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;tornado&lt;/span&gt; &lt;span class="n"&gt;needed&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;notebook&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;parallel&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ipython&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;select&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ipython&lt;/span&gt; &lt;span class="n"&gt;ipython27&lt;/span&gt;

&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cython&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;select&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;cython27&lt;/span&gt;

&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;scikits&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;

&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;virtualenv&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;virtualenv_select&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;select&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;virtualenv&lt;/span&gt; &lt;span class="n"&gt;virtualenv27&lt;/span&gt;

&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;nose&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;testconfig&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;select&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;nosetests&lt;/span&gt; &lt;span class="n"&gt;nosetests27&lt;/span&gt;

&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;pep8&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;pep8_select&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;select&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;pep8&lt;/span&gt; &lt;span class="n"&gt;pep827&lt;/span&gt;

&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;py27&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, there seems to not yet be a &lt;code&gt;port select&lt;/code&gt; command
for pip.  This bug has been reported and is noted
&lt;a href="http://trac.macports.org/ticket/36178"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Setting up a Virtual Environment&lt;/h3&gt;
&lt;p&gt;For Python development, I find it vital to make a good use of virtual
environments.  Virtual environments, enabled by the
&lt;a href="http://pypi.python.org/pypi/virtualenv"&gt;virtualenv&lt;/a&gt; package,
allow you to install several different versions of various python packages,
such that the installations are mostly independent.  I generally keep
stable released versions of packages in the system-wide python install,
and use these environments to develop the packages.  That way, I can
test the compilation/installation of a new feature in scipy or scikit-learn
without breaking my tried-and-true system installation.&lt;/p&gt;
&lt;p&gt;Here we'll set up a virtual environment called &lt;code&gt;default&lt;/code&gt;
in a &lt;code&gt;PyEnv&lt;/code&gt; subdirectory, and
then install &lt;code&gt;numpy&lt;/code&gt; in that environment using &lt;code&gt;pip&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;mkdir&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;PyEnv&lt;/span&gt;
&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;PyEnv&lt;/span&gt;
&lt;span class="n"&gt;virtualenv&lt;/span&gt; &lt;span class="k"&gt;default&lt;/span&gt;
&lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;
&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Other Programs to Install&lt;/h2&gt;
&lt;p&gt;There are several other things I found helpful to install.  First, the &lt;code&gt;g95&lt;/code&gt;
Fortran compiler for building scipy and other packages which require fortran:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;g95&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Also, we'll install and configure the tool every open source developer needs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;
&lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;global&lt;/span&gt; &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;John Doe&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;global&lt;/span&gt; &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email&lt;/span&gt; &lt;span class="n"&gt;john&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;doe&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Another essential is a good text editor.  There are several good open source
options for this.&lt;/p&gt;
&lt;p&gt;{% img left /images/textmate_icon.jpg 80 80 'Textmate icon' %}
&lt;strong&gt;Textmate&lt;/strong&gt; is a Mac native text editor which has many nice features, works
nicely on mac, and is fairly clean and nice to use:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;textmate2&lt;/span&gt;
&lt;span class="n"&gt;mate&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;{% img left /images/vim_icon.png 80 80 'Vim icon' %}
&lt;strong&gt;Vim&lt;/strong&gt; is another popular text editor: there is both a command-line version
and a GUI version available:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;vim&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;MacVim&lt;/span&gt;
&lt;span class="n"&gt;vim&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;{% img left /images/emacs_icon.jpeg 80 80 'Emacs icon' %}
&lt;strong&gt;Emacs&lt;/strong&gt; is my text editor of choice, and like Vim there is both a
command-line version and a GUI version:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;emacs&lt;/span&gt;
&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;emacs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;app&lt;/span&gt;
&lt;span class="n"&gt;emacs&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are several other GUI emacs versions available as well (e.g.
&lt;code&gt;xemacs&lt;/code&gt; and &lt;code&gt;emacs-mac-app&lt;/code&gt;): I found that I liked &lt;code&gt;emacs-app&lt;/code&gt; the
best.  Unfortunately, it lives in the "Applications" folder, and there
doesn't seem to be a way to configure the emacs GUI to work the same way
as the default emacs behavior on linux (see the related discussion thread
&lt;a href="http://stackoverflow.com/questions/10171280/how-to-launch-gui-emacs-from-command-line-in-osx"&gt;here&lt;/a&gt;).
I ended up putting the emacs GUI in the dock next to the terminal, and I
access it from there.&lt;/p&gt;
&lt;h2&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;I've had this setup on my new Macbook for about two weeks now,
and it seems to be working well for my daily python programming tasks.
I hope that this post will be useful to someone out there.  I'm still
learning as well -- if you have any pro tips for me or for other readers,
feel free to leave them in the comments below!&lt;/p&gt;
&lt;p&gt;Happy hacking.&lt;/p&gt;</summary></entry><entry><title>Hacking Super Mario Bros. with Python</title><link href="/blog/2013/01/13/hacking-super-mario-bros-with-python/" rel="alternate"></link><updated>2013-01-13T10:32:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-01-13:blog/2013/01/13/hacking-super-mario-bros-with-python/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;This weekend I was coming home from the meeting of the
&lt;a href="http://www.lsst.org"&gt;LSST&lt;/a&gt; Dark Energy Science Collaboration,
and found myself with a few extra hours in the airport.
I started passing the time by poking around on the &lt;a href="http://imgur.com"&gt;imgur&lt;/a&gt;
gallery, and saw a couple animated gifs based on
one of my all-time favorite games, Super Mario Bros.
It got me wondering: could I use matplotlib's animation tools to create these
sorts of gifs in Python?  Over a few beers at an SFO bar, I started to try
to figure it out.  To spoil the punchline a bit, I managed to do it, and the
result looks like this:&lt;/p&gt;
&lt;p&gt;{% img center /images/mario.gif %}&lt;/p&gt;
&lt;p&gt;This animation was created &lt;em&gt;entirely in Python and matplotlib&lt;/em&gt;, by scraping the
image data directly from the Super Mario Bros. ROM.  Below I'll explain how
I managed to do it.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;h2&gt;Scraping the Pixel Data&lt;/h2&gt;
&lt;p&gt;Clearly, the first requirement for this pursuit
is to get the pixel data used to construct the
mario graphics.  My first thought was to do something sophisticated like
&lt;a href="http://en.wikipedia.org/wiki/Machine_learning#Sparse_Dictionary_Learning"&gt;dictionary learning&lt;/a&gt; on a collection of screen-shots from the game
to build up a library of thumbnails.  That would be an interesting pursuit
in itself, but it turns out it's much more straightforward to directly
scrape the graphics from the source.&lt;/p&gt;
&lt;p&gt;It's possible to find digital copies of most
Nintendo Entertainment System (NES) games online.
These are known as ROMs, and can be played using one of
several NES emulators available for various operating systems.
I'm not sure about the legality of these
digital game copies, so I won't provide a link to them here.  But the internet
being what it is, you can search Google for some variation of "Super Mario
ROM" and pretty easily find a copy to download.&lt;/p&gt;
&lt;p&gt;One interesting aspect of ROMs for the original NES is that
they use raw byte-strings to store 2-bit (i.e. 4-color), 8x8 thumbnails from
which all of the game's graphics are built.
The collection of these byte-strings
are known as the "pattern table" for the game, and there is generally a
separate pattern table for foreground and background images.
In the case of NES games, there are
256 foreground and 256 background tiles, which can be extracted directly from
the ROMs if you know where to look (incidentally, this is one of the things
that made the NES an "8-bit" system.  2^8 = 256, so eight bits are required
to specify any single tile from the table).&lt;/p&gt;
&lt;h2&gt;Extracting Raw Bits from a File&lt;/h2&gt;
&lt;p&gt;If you're able to obtain a copy of the ROM, the first step to getting at the
graphics is to extract the raw bit information.
This can be done easily in Python using &lt;code&gt;numpy.unpackbits&lt;/code&gt;
and &lt;code&gt;numpy.frombuffer&lt;/code&gt; or &lt;code&gt;numpy.fromfile&lt;/code&gt;.
Additionally, the ROMs are generally stored using
zip compression.  The uncompressed data can be extracted using Python's
built-in &lt;code&gt;zipfile&lt;/code&gt; module.  Combining all of this, we extract the raw file
bits using a function like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;zipfile&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;extract_bits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;zipfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_zipfile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;zp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;zipfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ZipFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;raw_buffer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;zp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filelist&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="nb"&gt;bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frombuffer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromfile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unpackbits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;bytes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This function checks whether the file is compressed using zip, and extracts
the raw bit information in the appropriate way.&lt;/p&gt;
&lt;h2&gt;Assembling the Pattern Tables&lt;/h2&gt;
&lt;p&gt;The thumbnails which contain the game's graphics patterns are not at any set
location within the file.  The location is specified within the assembly
code that comprises the program, but for our purposes
it's much simpler to just visualize
the data and find it by-eye.  To accomplish this,
I wrote a Python script
(download it &lt;a href="/downloads/code/mario/view_pattern_table.py"&gt;here&lt;/a&gt;)
based on the above data extraction code
which uses matplotlib to interactively display the contents of the file.
Each thumbnail is composed from 128 bits:
two 64-bit chunks each representing an 8x8 image with one bit per pixel.
Stacking the two results in two bits per pixel, which are able to
represent four colors within each thumbnail.
The first few hundred chunks are difficult to interpret by-eye. They appear
similar to a 2D bar code: in this case the "bar code" represents pieces of the
assembly code which store the Super Mario Bros. program.&lt;/p&gt;
&lt;p&gt;{% img center /images/mario_pattern_sourcecode.png 400 %}&lt;/p&gt;
&lt;p&gt;Scrolling down toward the end of the file, however, we can quickly recognize
the thumbnails which make up the game's graphics:&lt;/p&gt;
&lt;p&gt;{% img center /images/mario_pattern_foreground.png 400 %}&lt;/p&gt;
&lt;p&gt;This first pattern table contains all the foreground graphics for the game.
Looking closely, the first few thumbnails
are clearly recognizable as pieces of Mario's head and body.
Going on we see pieces of various enemies in the game, as well as the iconic
mushrooms and fire-flowers.&lt;/p&gt;
&lt;p&gt;{% img center /images/mario_pattern_background.png 400 %}&lt;/p&gt;
&lt;p&gt;The second pattern table contains all the background graphics for the game.
Along with numbers and text, this contains the pieces which make up mario's
world: bricks, blocks, clouds, bushes, and coins.
Though all of the above tiles are shown in grayscale, we can add color by
simply changing the matplotlib Colormap, as we'll see below.&lt;/p&gt;
&lt;h2&gt;Combining Thumbnails and Adding Color&lt;/h2&gt;
&lt;p&gt;Examining the pattern tables above, we can see that big Mario is made up of
eight pattern tiles stitched together, while small Mario is made up of four.
With a bit of trial and error, we can create each of the full frames and
add color to make them look more authentic.  Below are all of the frames used
to animate Mario's motion throughout the game:&lt;/p&gt;
&lt;p&gt;{% img center /images/mario_graphics1.png 400 %}&lt;/p&gt;
&lt;p&gt;Similarly, we can use the thumbnails to construct some of the other
familiar graphics from the game, including the goombas, koopa troopas,
beetle baileys, mushrooms, fire flowers, and more.&lt;/p&gt;
&lt;p&gt;{% img center /images/mario_graphics2.png 350 %}&lt;/p&gt;
&lt;p&gt;The Python code to extract, assemble, and plot these images can be downloaded
&lt;a href="/downloads/code/mario/draw_mario.py"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Animating Mario&lt;/h2&gt;
&lt;p&gt;With all of this in place, creating an animation of Mario is relatively easy.
Using matplotlib's animation tools (described in a
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;previous post&lt;/a&gt;), all it
takes is to decide on the content of each frame, and stitch the frames together
using matplotlib's animation toolkit.  Putting together big Mario with some
scenery and a few of his friends, we can create a cleanly looping animated gif.&lt;/p&gt;
&lt;p&gt;The code used to generate this animation is shown below.  We use the same
&lt;code&gt;NESGraphics&lt;/code&gt; class used to draw the frames above, and stitch them together
with a custom class that streamlines the building-up of the frames.
By uncommenting the line near the bottom, the result will be saved as an
animated GIF using the ImageMagick animation writer that I
&lt;a href="https://github.com/matplotlib/matplotlib/pull/1337"&gt;recently contributed&lt;/a&gt;
to matplotlib.  The ImageMatick plugin has not yet made it into a
released matplotlib version, so using the save command below will
require installing the development version of matplotlib, available for
download on &lt;a href="http://github.com/matplotlib/matplotlib"&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;{% include_code mario/animate_mario.py lang:python "Mario Animation" %}&lt;/p&gt;
&lt;p&gt;The result looks like this:&lt;/p&gt;
&lt;p&gt;{% img center /images/mario.gif %}&lt;/p&gt;
&lt;p&gt;Pretty good!  With a bit more work, it would
be relatively straightforward to use the above code to do some more
sophisticated animations: perhaps recreate a full
level from the original Super Mario Bros, or even design your own custom
level.  You might think about taking the extra step and trying to make Mario's
movements interactive.  This could be a lot of fun, but probably very difficult
to do well within matplotlib.
For tackling an interactive mario in Python, another framework such as
&lt;a href="http://docs.python.org/2/library/tkinter.html"&gt;Tkinter&lt;/a&gt; or
&lt;a href="http://www.pygame.org/"&gt;pygame&lt;/a&gt; might be a better choice.&lt;/p&gt;
&lt;p&gt;I hope you enjoyed this one as much as I did -- happy coding!&lt;/p&gt;</summary></entry><entry><title>Will Scientists Ever Move to Python 3?</title><link href="/blog/2013/01/03/will-scientists-ever-move-to-python-3/" rel="alternate"></link><updated>2013-01-03T17:08:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2013-01-03:blog/2013/01/03/will-scientists-ever-move-to-python-3/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;It's been just over four years since the introduction of Python 3, and there
are still about as many opinions on it as there are Python users.  For
those who haven't been following, Python 3 is a release
which offers several nice improvements over the 2.x series
(summarized &lt;a href="http://docs.python.org/3/whatsnew/3.0.html"&gt;here&lt;/a&gt;)
with the distinct disadvantage that it broke backward compatibility:
though Python 3.x (often referred to as "Py3k" for short)
is true to the spirit of earlier Python versions,
there are a few valid 2.x constructions which will not parse under 3.x.&lt;/p&gt;
&lt;p&gt;Breaking backward compatibility was controversial, to say the least.  I
think of the debate as one between the pragmatists -- those who see Python
as an extremely useful tool, which should not be unnecessarily tampered with --
and the idealists -- those who view the Python language
as a living, breathing entity, which should be allowed to grow into the
fullest and most Pythonic possible version of itself.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;The scientific Python community has largely leaned to the pragmatist side.  Some
of this is due to the pragmatism inherent to science (in the publish-or-perish
world, one does not often have time for idealistic thinking about one's tools),
and some of this is due to institutional pressures, which I'll mention below.
But regardless of the cause, the scientific Python community has been
particularly slow in moving to Py3k.  &lt;a href="http://www.numpy.org"&gt;Numpy&lt;/a&gt;, the
core of the scientific Python ecosystem, first supported Py3k in version
1.5, released in 2010, nearly two years after the release of Py3k.
&lt;a href="http://www.scipy.org"&gt;Scipy&lt;/a&gt; followed suit with version 0.9
in March 2011.  &lt;a href="http://www.ipython.org"&gt;IPython&lt;/a&gt; added Py3k support
with version 0.12 in December 2011.  The final holdout among
the core scientific packages was matplotlib, which now supports Py3k in the
1.2 release as of November 2012.&lt;/p&gt;
&lt;p&gt;The casual observer might look at this progress
and infer that the transition is near
complete: scientists can now start moving to Py3k without fear of losing
access to the tools of their trade.  But in reality, nothing could be further
from the truth.  Consider that the Numpy and Scipy development teams only
last month made the decision to drop support for Python 2.4 (which was first
released in March of 2005).  Even then, there has been considerable talk of how
to make sure the final 2.4-compatible release is long-term-stable for those
users who will use 2.4 well into the future (many institutional Linux
distributions, such as Red Hat Linux, are very slow to update their
native Python version).
All else being equal, we might extrapolate and say that support for Python 2.7
(first released in July 2010) might be dropped by mid 2018.  But this would
be an overly simplistic expectation, for reasons I'll outline below.
There's a vital component of this transition that I haven't yet heard
mentioned by anyone else:
I would argue that the main limitation to the adoption of Python 3
by the scientific community lies in &lt;em&gt;the lack of a well-developed 3-to-2
conversion tool&lt;/em&gt;.  I'll explain this thought below.&lt;/p&gt;
&lt;h2&gt;The Types of Users&lt;/h2&gt;
&lt;p&gt;To begin to evaluate what it will take for the
scientific community to transition to
Python 3, I'd like to divide members of the community into three general
categories.  These are certainly not mutually exclusive (I fall pretty
squarely in all three), but the categories will
help us think about the forces involved in the
decision to switch to Py3k.  The groups are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Individual Scientists&lt;/strong&gt; are the researchers who primarily use
  Python for their own individual tasks: statistical analysis of their data,
  creation of figures, and writing scripts to stitch together various legacy
  codes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Institutional Scientists&lt;/strong&gt; are the researchers who are part of a large
  research team or collaboration with a common Python code-base.  An example
  that I personally am
  familiar with is the &lt;a href="http://www.lsst.org"&gt;LSST&lt;/a&gt; collaboration:
  the LSST software stack has been developed by a large team over the course
  of several years, and is written primarily in C++ and Python 2.x.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scientific Python Developers&lt;/strong&gt;
  are the scientists who may be part of one or both of the above groups,
  but also go the extra mile and contribute to the packages that
  make the scientific Python ecosystem what it is.  I wouldn't limit this to
  just the NumPy/SciPy/IPython/Matplotlib packages mentioned above, but also
  the expanding circle of packages geared toward specific fields and
  applications.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Members of these three groups have very different needs and constraints that
will affect how easily they can move to Py3k:&lt;/p&gt;
&lt;h3&gt;Individual Scientists&lt;/h3&gt;
&lt;p&gt;This group is probably the most flexible of the three, and for that reason
are perhaps the lowest-hanging fruit of the bunch.
Free from the constraints of a large legacy
code-base, they can adopt Py3k virtually at-will.  I witnessed
a similar transition take place
over the course of my graduate schooling at University of Washington: at the
beginning of my PhD program, nearly everybody in the department was
using the proprietary language &lt;a href="http://www.exelisvis.com/idl/"&gt;IDL&lt;/a&gt;.
By the time I graduated,
close to half the department was primarily using Python.&lt;/p&gt;
&lt;p&gt;As much as I'd like
to take some of the credit for that transition (I was a tireless proseletizer
of the virtues of Python over IDL),
it likely had more to do with the adoption of
Python by several important astronomical research collaborations, as well
as the influence of several newer professors who recommended Python to
their advisees.  This points to the fact that
although an individual could easily upgrade to Py3k virtually at
will, in practice it is unlikely to happen unless others around them have
begun to do so as well.&lt;/p&gt;
&lt;h3&gt;Institutional Scientists&lt;/h3&gt;
&lt;p&gt;As hinted above, even the most independent scientists are not entirely
insulated from their colleagues, and the tools chosen by influential
members of their team will affect their choice of tools for their own tasks.
But aside from this peer pressure, scientists who are part of a large
collaboration are additionally constrained by the countless hours
already invested in their present code-base. And if that code-base is
in Python 2.x, it will take a lot more than some unicode and iterator
enhancements to effect a transition to Python 3.&lt;/p&gt;
&lt;p&gt;Because of this, I've seen a lot of incredulity (and even some
anger) about the decision of the Python core devs to move forward with a
backward-incompatible release.  In a conversation, one Princeton
astrophysicist I know (who is famous for -- among other things --
the brashness of his opining) called
the py3k release "utterly inane", and went on to say that astronomy will
&lt;em&gt;never&lt;/em&gt; adopt Python 3.  I'm a bit more optimistic myself, but this is
indicative of the general attitude toward Py3k within the scientific
community.&lt;/p&gt;
&lt;h3&gt;Scientific Python Developers&lt;/h3&gt;
&lt;p&gt;Those scientists who take the time to contribute to the greater community are
a bit of a special case.  They tend to be less pragmatic about Python than
their peers, and may have some silly hobbies (like using their free time
to write blog posts with "Python" in the title).
They are generally comfortable using multiple Python installs
on each of their several computers, and as such are less influenced by the
preferences of whatever research group they may be in at the time.
Yet even this group is unlikely to be using Python 3.x currently.
It might be because Matplotlib -- a core scientific tool -- only just moved
to Py3k compatibility, but I think it's even deeper than that.  I, for one,
did not jump up to make the switch the minute the matplotlib 1.2 announcement
came out, and I doubt that others did either.&lt;/p&gt;
&lt;p&gt;The core of the problem is this: even though NumPy/SciPy/IPython/Matplotlib
are compatible with Py3k, the &lt;em&gt;development&lt;/em&gt; still takes place in Python 2.x.
The Py3k compatibility is bootstrapped in using
&lt;a href="http://wiki.python.org/moin/2to3"&gt;2to3&lt;/a&gt;
and other scripts of that ilk.  And herein lies the problem:
absent another compelling reason, as long as the development takes place
in Python 2.x, these developers will be very unlikely to move
their own work to Py3k.&lt;/p&gt;
&lt;h2&gt;The Outlook&lt;/h2&gt;
&lt;p&gt;Exploring the needs and drivers of these three groups paints a pretty dim
picture for Py3k in the scientific world.
Individuals have no pressure to switch, and
collaborations become so entrenched that switching is near impossible.
Even those who are actively contributing to the Numpy and Scipy codebases
cannot use Python 3 for this task, and thus have no big driver for change.
This final piece holds perhaps the biggest opportunity,
because the Scientific Python developers have the potential
to catalyze change in the rest of the community: these are the folks who write
the online Python documentation and tutorials; they give talks and tutorials
at &lt;a href="http://conference.scipy.org/"&gt;SciPy&lt;/a&gt;, &lt;a href="http://www.pydata.org"&gt;PyData&lt;/a&gt;,
&lt;a href="http://www.pycon.org"&gt;PyCon&lt;/a&gt;,
and conferences specific to their own field; they influence the
curricula used in Python bootcamps like those facilitated by
&lt;a href="http://software-carpentry.org/"&gt;Software Carpentry&lt;/a&gt;.  In short, perhaps the
sole hope of moving the scientific community to Python 3 lies in the
scientific python developers.  Move the &lt;em&gt;development&lt;/em&gt; of Numpy, Scipy, IPython,
Matplotlib, and other core packages to Python 3, and the rest of the
community will follow.&lt;/p&gt;
&lt;p&gt;The problem is, this is impossible right now.  Realistically, Python 2.x will
have to be supported by Numpy and Scipy for at least another decade.
If Numpy &amp;amp; Scipy development is to be moved to Py3k, what is needed is a
fully-developed, mature 3-to-2 conversion tool which can convert 3.x back as
far as Python 2.5.  With this, development could continue in Py3k while still
maintaining 2.x support.  A basic form of such a tool
&lt;a href="http://wiki.python.org/moin/3to2"&gt;is available&lt;/a&gt;, but it is not nearly
as mature (nor as easy a task)
as the &lt;a href="http://wiki.python.org/moin/2to3"&gt;2to3&lt;/a&gt; tool.
The tool's relative immaturity
is understandable: converting the new to the old is not nearly as sexy as
converting the old to the new.  But for the reasons I outlined above, I
believe it to be vital.&lt;/p&gt;
&lt;p&gt;So here's my challenge to any Python idealists out there:
&lt;em&gt;if you want the scientific community to ever fully adopt Python 3,
prioritize the development of a full-featured 3to2 tool,
and start doing all you can to encourage NumPy to move to
developing in Py3k&lt;/em&gt;.  I'd do it myself, but I'm too much of
a pragmatist: python 2.7 is more than sufficient for my own research.
But I'd be willing to bet -- if someone does this, the rest of us will
soon follow.&lt;/p&gt;</summary></entry><entry><title>Sparse SVDs in Python</title><link href="/blog/2012/12/19/sparse-svds-in-python/" rel="alternate"></link><updated>2012-12-19T08:21:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-12-19:blog/2012/12/19/sparse-svds-in-python/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;After &lt;a href="http://fseoane.net/blog/2012/singular-value-decomposition-in-scipy/"&gt;Fabian's post&lt;/a&gt; on the topic, I have recently returned to thinking about the
subject of sparse singular value decompositions (SVDs) in Python.&lt;/p&gt;
&lt;p&gt;For those who haven't used it, the SVD is an extremely powerful technique.
It is the core routine of many applications,
from filtering to dimensionality
reduction to graph analysis to supervised classification and much, much more.&lt;/p&gt;
&lt;p&gt;I first came across the need for a fast sparse SVD when applying a technique
called Locally Linear Embedding (LLE) to astronomy spectra: it was the first
astronomy paper I published, and you can read it &lt;a href="http://adsabs.harvard.edu/abs/2009AJ....138.1365V"&gt;here&lt;/a&gt;.  In LLE, one visualizes the nonlinear relationship
between high-dimensional observations.  The computational cost is extreme: for
&lt;em&gt;N&lt;/em&gt; objects, one must compute the null space (intimately related to the SVD)
of a &lt;em&gt;N&lt;/em&gt; by &lt;em&gt;N&lt;/em&gt; matrix.  Using direct methods (e.g. LAPACK), this can scale
as bad as $\mathcal{O}[N^3]$ in both memory and speed!&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;I needed a better option.  I came across the package
&lt;a href="http://www.caam.rice.edu/software/ARPACK/"&gt;ARPACK&lt;/a&gt;, a well-tested
implementation of iterative Arnoldi Factorization written in Fortran.
The shift-invert mode of ARPACK served my needs, so I spent some time
extending the &lt;a href="http://docs.scipy.org/doc/scipy/reference/tutorial/arpack.html"&gt;scipy ARPACK wrapper&lt;/a&gt; so I could address my problem.  I also helped
Fabian and others implement the beginnings of the &lt;a href="http://scikit-learn.org/dev/modules/manifold.html"&gt;manifold learning&lt;/a&gt; module in scikit-learn.&lt;/p&gt;
&lt;p&gt;Even after moving on to other problems, I found that
the SVD was at the core of nearly every component of my research
while working toward my PhD.  You can see this in
&lt;a href="http://adsabs.harvard.edu/abs/2011AAS...21715304C"&gt;several&lt;/a&gt;
&lt;a href="http://adsabs.harvard.edu/abs/2011ApJ...727..118V"&gt;other&lt;/a&gt;
&lt;a href="http://adsabs.harvard.edu/abs/2011AJ....142..203D"&gt;projects&lt;/a&gt;
I was involved with over the years, including my
&lt;a href="http://gradworks.umi.com/35/42/3542228.html"&gt;PhD Thesis&lt;/a&gt;, which centered
on Astronomical applications of Karhunen-Loeve analysis -- a method, again,
intimately linked with the SVD.&lt;/p&gt;
&lt;p&gt;Hopefully this brief tour has convinced you of the power of the SVD in
addressing real research problems.  Now to the code.&lt;/p&gt;
&lt;h1&gt;Sparse SVD Implementations&lt;/h1&gt;
&lt;p&gt;What I didn't know at the time I worked on the ARPACK wrapper is that there
are several more good options available for computing SVDs - and most now have
passable Python wrappers which integrate well with scipy's sparse matrices.
I'll briefly describe them here.&lt;/p&gt;
&lt;h2&gt;LAPACK&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.netlib.org/lapack/"&gt;LAPACK&lt;/a&gt;
is the standard specification of efficient linear algebra routines
across computing systems, and contains routines to
compute a direct (i.e. non-iterative)
SVD of a dense matrix.  The performance of LAPACK varies from system to
system, and implementation to implementation.  The algorithm is generally
$\mathcal{O}[N^3]$,
and partial decompositions are (in general) not available.  Though
not technically the same, I would group alternatives like
&lt;a href="http://math-atlas.sourceforge.net/"&gt;ATLAS&lt;/a&gt; (an optimized open-source
matrix library) and &lt;a href="http://software.intel.com/en-us/intel-mkl"&gt;MKL&lt;/a&gt;
(Intel's proprietery library for fast numerics) in the same category.
I don't have much personal experience with MKL, so if I'm not doing it justice,
please feel free to admonish me in the comments!&lt;/p&gt;
&lt;p&gt;LAPACK is wrapped by Numpy and Scipy, and is
at the core of many of the routines in &lt;code&gt;numpy.linalg&lt;/code&gt; and
&lt;code&gt;scipy.linalg&lt;/code&gt;, including the &lt;code&gt;svd&lt;/code&gt; function in each.&lt;/p&gt;
&lt;h2&gt;ARPACK&lt;/h2&gt;
&lt;p&gt;As I mentioned above, &lt;a href="http://www.caam.rice.edu/software/ARPACK/"&gt;ARPACK&lt;/a&gt;
implements a fast iterative/partial eigenvalue decomposition on a general
linear operator.  One of its strengths is that unlike LAPACK, it does not
depend on your matrix being stored in any standard layout: all that is required
is to provide a routine which implements matrix-vector multiplication.  This
means that as well as dense matrices, ARPACK can be used on any sparse matrix
or even a general linear operator which maps one vector space to another.&lt;/p&gt;
&lt;p&gt;ARPACK does not have a native SVD implementation, but it is possible to
exploit the relationship between eigenvalue decompositions and singular
value decompositions to compute an ARPACK svd: this is what the current
&lt;code&gt;svds&lt;/code&gt; routine in &lt;code&gt;scipy.sparse.linalg&lt;/code&gt; does: see the documentation
&lt;a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html"&gt;here&lt;/a&gt;.  One issue with this implementation is that to compute the SVD of
a matrix &lt;em&gt;M&lt;/em&gt;, it must implicitly compute $M^T M$,
and that may lead to issues of both
numerical accuracy and computational efficiency.&lt;/p&gt;
&lt;h2&gt;SVDLIBC&lt;/h2&gt;
&lt;p&gt;Before Fabian's blog post, mentioned above, I had never heard of
&lt;a href="http://tedlab.mit.edu/~dr/SVDLIBC/"&gt;SVDLIBC&lt;/a&gt;.  It
is also an Arnoldi-iteration based implementation, but SVDLIBC requires a
specific sparse matrix format to operate.  Fortunately for scipy users, this
storage format maps directly to the CSC sparse matrix format, so the SVDLIBC
svd can be computed without any memory copies of the scipy matrix (assuming,
of course, your matrix is already stored as CSC or CSR!).  A bare-bones python
wrapper for the routine exists in the &lt;a href="http://pypi.python.org/pypi/sparsesvd/"&gt;sparsesvd&lt;/a&gt; package.&lt;/p&gt;
&lt;h2&gt;PROPACK&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://soi.stanford.edu/~rmunk/PROPACK/"&gt;PROPACK&lt;/a&gt; is another well-tested
Fortran package which computes the SVD directly using an Arnoldi Factorization
scheme: like ARPACK, it only depends on a callback implementing left- and
right-multiplication operations, rather than making use of any specific
sparse storage format.  Like SVDLIBC, it  computes the svd directly, saving
computation time and leading to greater numerical accuracy.  From my brief
search, it seems that
no python wrapper is readily available (though I heard that David Cournapeau
had worked on one).  Until recently, the PROPACK license was unspecified,
precluding its inclusion in Scipy or other BSD-licensed packages.  It appears
that just recently, PROPACK itself was moved to a BSD license, so there is
now the possibility of including it in the Scipy universe.&lt;/p&gt;
&lt;p&gt;I have begun working on a full-featured PROPACK wrapper in the Scipy style,
using the excellent F2Py Fortran interface generator.  You can find the 
code in my &lt;a href="https://github.com/jakevdp/pypropack"&gt;pypropack repository&lt;/a&gt;
on Github.  As of this writing, there is still a lot to do to make the
code releasable, but there is enough there to enable some quick benchmarks.&lt;/p&gt;
&lt;h1&gt;Benchmark Comparisons&lt;/h1&gt;
&lt;p&gt;To benchmark these four SVD options, I used the following code:&lt;/p&gt;
&lt;p&gt;{% include_code plot_svd_benchmarks.py lang:python SVD Benchmarks %}&lt;/p&gt;
&lt;p&gt;This creates square sparse matrices, measures the computation time as a function
of the matrix size, and plots the results.  The results on my 3-year old
linux box are below:&lt;/p&gt;
&lt;p&gt;{% img /figures/svd_benchmarks.png [SVD benchmarks] %}&lt;/p&gt;
&lt;p&gt;A few comments: First, as expected, LAPACK is much slower than the rest.  This
is due to two factors: first, LAPACK computes the full SVD, while the other
methods compute only partial SVDs (the &lt;em&gt;k=5&lt;/em&gt; largest singular values).
Second, the LAPACK on my system is not
well-optimized: I could probably reduce this by at least an order of magnitude
if I were to use an ATLAS install optimized for my system.  If you need a
full SVD, it will be hard to beat LAPACK/ATLAS/MKL in terms of speed (but
in terms of memory consumption, as
&lt;a href="http://fseoane.net/blog/2012/singular-value-decomposition-in-scipy/"&gt;Fabian showed&lt;/a&gt;,
LAPACK can be pretty bad).  Because SVDLIBC, ARPACK, and PROPACK all use
Lanczos/Arnoldi iteration, they should all similarly out-perform LAPACK on
the memory question.&lt;/p&gt;
&lt;p&gt;Second, the good performance of SVDLIBC for small matrices is probably due to
its direct use of the CSC memory within the Fortran code.  For matrices this
size, the Python overhead of invoking the callback in ARPACK and PROPACK kills
any performance gains from the more sophisticated algorithms.  As the matrices
grow, we see that ARPACK and PROPACK begin to out-perform SVDLIBC.&lt;/p&gt;
&lt;p&gt;Finally, we see that for these test cases, PROPACK is consistently
faster than ARPACK by a factor of 5 or so: nothing to scoff at!
I haven't rigorously tested the claims of increased numerical stability
in PROPACK, but those two pieces point to PROPACK as the
preferred method by far.&lt;/p&gt;
&lt;h1&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;I hope to continue developing the &lt;code&gt;pypropack&lt;/code&gt; wrapper on github, and once
I'm happy with it, incorporate it into Scipy's sparse linear algebra tools.
I would love help with this: in particular, if there are any F2Py wizards out
there, I'm currently having what I think is a
&lt;a href="https://github.com/jakevdp/pypropack/issues/1"&gt;memory issue&lt;/a&gt;
with the callback function that I can't seem to track down.&lt;/p&gt;
&lt;p&gt;Hopefully this post has helped convince you of the importance of SVDs in
scientific computing, and also of the benefits of working on PROPACK
incorporation in the scientific Python universe.  This sort of thing
won't happen unless someone like &lt;strong&gt;you&lt;/strong&gt; decides to work on it!  That
fact ends up being both a weakness and an incredible strength of
open-source packages.&lt;/p&gt;
&lt;p&gt;Happy coding!&lt;/p&gt;</summary></entry><entry><title>Minesweeper in Matplotlib</title><link href="/blog/2012/12/06/minesweeper-in-matplotlib/" rel="alternate"></link><updated>2012-12-06T18:23:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-12-06:blog/2012/12/06/minesweeper-in-matplotlib/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;Lately I've been playing around with interactivity in matplotlib.  A couple
weeks ago, I discussed briefly how to use event callbacks to implement
&lt;a href="/blog/2012/11/24/simple-3d-visualization-in-matplotlib/"&gt;simple 3D visualization&lt;/a&gt;
and later used this as a base for creating a
&lt;a href="/blog/2012/11/26/3d-interactive-rubiks-cube-in-python"&gt;working 3D Rubik's cube&lt;/a&gt;
entirely in matplotlib.&lt;/p&gt;
&lt;p&gt;Today I have a different goal: re-create
&lt;a href="http://en.wikipedia.org/wiki/Minesweeper_%28computer_game%29"&gt;minesweeper&lt;/a&gt;,
that ubiquitous single-player puzzle game that most of us will admit to
having binged on at least once or twice in their lives.  In minesweeper, the
goal is to discover and avoid hidden mines within a gridded minefield, and
the process takes some logic and quick thinking.&lt;/p&gt;
&lt;p&gt;{% img /images/minesweeper_2.gif 800 %}&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;To implement this in matplotlib, at its most stripped-down level, simply
requires us to register mouse clicks on the plot window, and to have the
window respond in the appropriate way.  The rest is just the logic underneath.&lt;/p&gt;
&lt;h2&gt;Event Callbacks&lt;/h2&gt;
&lt;p&gt;Matplotlib contains several built-in event callbacks.  You can register
key presses (with &lt;code&gt;'key_press_event'&lt;/code&gt; and &lt;code&gt;'key_release_event'&lt;/code&gt;),
mouse clicks (with &lt;code&gt;'button_press_event'&lt;/code&gt; and &lt;code&gt;'button_release_event'&lt;/code&gt;),
mouse movement (with &lt;code&gt;'motion_notify_event'&lt;/code&gt;), and much more.  For
a full listing of the events that can be bound to functionality, see the
documentation of the function &lt;code&gt;'matplotlib.pyplot.connect'&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As a simple example, here we'll create a polygon and a function which is called
each time the axis is clicked.  The function &lt;code&gt;on_click&lt;/code&gt; checks if the click
occured within the polygon, and if so changes the polygon to a random
color:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;111&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;polygon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Polygon&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_patch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;polygon&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Function to be called when mouse is clicked&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_click&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;polygon&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;contains_point&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="n"&gt;polygon&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_facecolor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c"&gt;# Connect the click function to the button press event&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mpl_connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;button_press_event&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;on_click&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The result will look something like this:&lt;/p&gt;
&lt;p&gt;{% img /images/poly_color.gif  400 %}&lt;/p&gt;
&lt;p&gt;Checking whether a click event is within a polygon or any other artist is
a very common pattern.  For this reason, matplotlib provides a built-in
 &lt;code&gt;pick&lt;/code&gt; event.  You can think of this as an event similar to a mouse click,
but specifically generated by a plot artist when it is clicked.
Furthermore, a &lt;code&gt;pick&lt;/code&gt; event is associated back to that particular plot
element, which can be easily referenced within the callback.
Here is a code snippet which gives is equivalent to the code above,
but uses pick events rather than button press events:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;111&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;polygon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Polygon&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_patch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;polygon&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# set the picker to True, so that pick events are registered&lt;/span&gt;
&lt;span class="n"&gt;polygon&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_picker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# create a function to be bound to pick events: here the event has an&lt;/span&gt;
&lt;span class="c"&gt;# attribute `artist` which points to the object which was clicked&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_pick&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;artist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_facecolor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c"&gt;# bind pick events to our on_pick function&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mpl_connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pick_event&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;on_pick&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we have used just a single polygon, but there's nothing to stop us
from using multiple interactive polygons in a single window.  Add some
logic beneath it all, and the results can be extremely flexible.  We'll
go through one in-depth example below.&lt;/p&gt;
&lt;h2&gt;Minesweeper&lt;/h2&gt;
&lt;p&gt;Using this simple machinery, let's create a basic implementation of the game
Minesweeper.  This involves creating a grid of polygons, with a certain number
of them "containing" mines.  Clicking the left mouse button will "uncover"
the square, ending the game if a mine is underneath.  If (as we'd hope)
an uncovered square does not contain a mine, it will reveal a number
reporting how many of the eight adjacent squares contain mines.
The right mouse button is used to mark where we believe mines are.&lt;/p&gt;
&lt;p&gt;There are some other more sophisticated features in the below code --
for example, clicking
an already uncovered square with the correct number of adjacent mines marked
will automatically clear the surrounding squares -- but rather than enumerating
every programming decision, I'll just show you the code.  It's less than
200 lines, but the results are pretty nice:&lt;/p&gt;
&lt;p&gt;{% img /images/minesweeper.gif 440 440 %}&lt;/p&gt;
&lt;p&gt;{% include_code minesweeper.py lang:python Minesweeper %}&lt;/p&gt;
&lt;p&gt;There are still some things missing from this which are present in any good
minesweeper implementation: a timer, the ability to reset the game without
restarting the program, the ability to keep track of fastest times, and
likely some more things I haven't thought of.&lt;/p&gt;
&lt;p&gt;Regardless, this little script shows how incredibly powerful a framework
matplotlib is.
It can create an interactive Rubik's cube one day, publication-quality plots
the next, and round out the season with a blast back to a classic Windows 3.1
time-sink.  And for some reason, I find I have much more fun playing the
minesweeper I built from scratch than the one that came with my system.&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;</summary></entry><entry><title>A Primer on Python Metaclasses</title><link href="/blog/2012/12/01/a-primer-on-python-metaclasses/" rel="alternate"></link><updated>2012-12-01T07:25:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-12-01:blog/2012/12/01/a-primer-on-python-metaclasses/</id><summary type="html">&lt;p&gt;{% notebook MetaClasses.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>3D Interactive Rubik's Cube in Python</title><link href="/blog/2012/11/26/3d-interactive-rubiks-cube-in-python/" rel="alternate"></link><updated>2012-11-26T22:00:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-11-26:blog/2012/11/26/3d-interactive-rubiks-cube-in-python/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;Over the weekend, I built a interactive 3D Rubik's cube simulator in python
using only &lt;a href="http://matplotlib.org"&gt;matplotlib&lt;/a&gt; for all the graphics and
interaction.  Check out the demonstration here:&lt;/p&gt;
&lt;p&gt;{% video /downloads/videos/MagicCube.mp4 680 400 /downloads/videos/MagicCube_frame.jpg %}&lt;/p&gt;
&lt;p&gt;You can browse the source code at the MagicCube github repository:
&lt;a href="http://github.com/davidwhogg/MagicCube"&gt;http://github.com/davidwhogg/MagicCube&lt;/a&gt;.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;The 3D rendering is based on the quaternions and projections  discussed in
my &lt;a href="/blog/2012/11/24/simple-3d-visualization-in-matplotlib/"&gt;previous post&lt;/a&gt;,
and many of the key bindings discussed there are used here.
The additional component is the turning of each face.  This is actually
fairly simple to accomplish using the tools discussed above.&lt;/p&gt;
&lt;p&gt;For example, the right face is perpendicular to the x-axis in the cube-frame.
Thus to turn it, you only need to manipulate polygons with x-coordinate
between 1/3 and 1 inclusive (the cube has side-length 2 and is centered on
the origin).  The correct faces are found quickly using
numpy's &lt;code&gt;where&lt;/code&gt; statement, and a quaternion rotation is applied only to
these faces.  Easy!&lt;/p&gt;
&lt;p&gt;The code and interface still needs some work, and I'm hoping to add more
features as I have time.  After spending my long weekend working on this,
I have some real work to catch-up on...&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update: I've heard from some folks that the key and mouse bindings don't
work on some operating systems or backends.  If you experience
system-dependent bugs and have any insight into the problem, I'd appreciate
help working out what's happening!&lt;/em&gt;&lt;/p&gt;</summary></entry><entry><title>Quaternions and Key Bindings: Simple 3D Visualization in Matplotlib</title><link href="/blog/2012/11/24/simple-3d-visualization-in-matplotlib/" rel="alternate"></link><updated>2012-11-24T11:04:00-08:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-11-24:blog/2012/11/24/simple-3d-visualization-in-matplotlib/</id><summary type="html">&lt;p&gt;{% notebook 3DCube.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Sparse Graphs in Python: Playing with Word Ladders</title><link href="/blog/2012/10/14/scipy-sparse-graph-module-word-ladders/" rel="alternate"></link><updated>2012-10-14T21:23:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-10-14:blog/2012/10/14/scipy-sparse-graph-module-word-ladders/</id><summary type="html">&lt;p&gt;{% notebook sparse-graph.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>XKCD-style plots in Matplotlib</title><link href="/blog/2012/10/07/xkcd-style-plots-in-matplotlib/" rel="alternate"></link><updated>2012-10-07T13:30:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-10-07:blog/2012/10/07/xkcd-style-plots-in-matplotlib/</id><summary type="html">&lt;p&gt;{% notebook XKCD_plots.ipynb cells[2:] %}&lt;/p&gt;</summary></entry><entry><title>Blogging with IPython in Octopress</title><link href="/blog/2012/10/04/blogging-with-ipython/" rel="alternate"></link><updated>2012-10-04T18:40:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-10-04:blog/2012/10/04/blogging-with-ipython/</id><summary type="html">&lt;p&gt;{% notebook nb_in_octopress.ipynb cells[1:] %}&lt;/p&gt;</summary></entry><entry><title>Optical Illusions in Matplotlib</title><link href="/blog/2012/09/26/optical-illusions-in-matplotlib/" rel="alternate"></link><updated>2012-09-26T07:27:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-09-26:blog/2012/09/26/optical-illusions-in-matplotlib/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;A while ago I posted some information on the new matplotlib animation
package (see my tutorial
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial"&gt;here&lt;/a&gt; and
a followup post &lt;a href="/blog/2012/09/05/quantum-python"&gt;here&lt;/a&gt;).  In them, I show
how easy it is to  use matplotlib to create simple animations.&lt;/p&gt;
&lt;p&gt;This morning I came across this cool optical illusion on
&lt;a href="http://gizmodo.com/5945194/this-optical-trick-is-annoying-the-hell-out-of-me"&gt;gizmodo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;{% img /images/original_illusion.gif %}&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;It intrigued me, so I decided to see if I could create it using matplotlib.
Using my previous template and a bit of geometry, I was able to finish it
before breakfast!  Here's the code:&lt;/p&gt;
&lt;p&gt;{% include_code animate_square.py lang:python Optical Illusion %}&lt;/p&gt;
&lt;p&gt;And here's the result:&lt;/p&gt;
&lt;p&gt;{% video /downloads/videos/animate_square.mp4 360 270 /downloads/videos/animate_square.png %}&lt;/p&gt;
&lt;p&gt;This just confirms my suspicion that a few lines of python really can do
anything.&lt;/p&gt;</summary></entry><entry><title>Why Python is the Last Language You'll Have To Learn</title><link href="/blog/2012/09/20/why-python-is-the-last/" rel="alternate"></link><updated>2012-09-20T20:50:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-09-20:blog/2012/09/20/why-python-is-the-last/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;This week, for part of a textbook I'm helping to write,
I spent some time reading and researching the history of Python as
a scientific computing tool.  I had heard bits and pieces of this in the past,
but it was fascinating to put it all together and learn about how all the
individual contributions that have made Python what it is today.
All of this got me thinking: for most of us, Python was a replacement for
something: IDL, MatLab, Java, Mathematica, Perl... you name it.
But what will replace Python?
Ten years down the road, what language will people be espousing in
blogs with awkwardly-alliterated titles?  As I thought it through, I
became more and more convinced that, at least in the scientific computing
world, Python is here to stay.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Now Im not simply talking about inertia.  Javascript has inertia, and that's
a main reason that web admins still begrudgingly use it.  But Python is 
different.  Yes, it's everywhere, and yes, something so ubiquitous is
hard to shake.  But look at the 1970s: punch card programming was
everywhere, and now it's nothing but a footnote. Inertia can be overcome
with time.  But I think Pythons hold is much deeper than that: I think it
will remain relevant long into the future.  Heres why:&lt;/p&gt;
&lt;h2&gt;GitHub&lt;/h2&gt;
&lt;p&gt;The first reason Python will be around for a while is
&lt;a href="http://github.com"&gt;GitHub&lt;/a&gt;.  GitHub has done wonders both for Python
and for the broader open source community. 
It has replaced the clunky Trac system of
submitting static patches to projects, and removed the contribution barrier
for the core scientific python projects.  Numpy, Scipy, and Matplotlib were
all moved to GitHub in late 2010, and the results have been impressive.
I did some quick data mining of the commit logs on GitHub to learn
about the rate of new author contributions to core python projects with
time, and this is what I found:&lt;/p&gt;
&lt;p&gt;{% img /figures/author_count.png 600 [Cumulative number of contributors for python packages] %}&lt;/p&gt;
&lt;p&gt;See it? The late 2010 transition to GitHub is extremely apparent,
and this reflects the first reason that NumPy, SciPy, Matplotlib,
and Python will remain relevant far into the future.
Python not only has an astoundingly large user-base; thanks to GitHub,
it has an astoundingly large and ever-increasing &lt;em&gt;developer&lt;/em&gt; base.
And that means Python is well-poised to evolve as the needs of users change.&lt;/p&gt;
&lt;h2&gt;Julia&lt;/h2&gt;
&lt;p&gt;The second reason Python will be around for a while is 
&lt;a href="http://julialang.org/"&gt;Julia&lt;/a&gt;.  This statement may strike some as strange:
Julia is a 
language which aims to improve on many of Pythons weaknesses.
It uses JIT compilation and efficient built-in array 
support to beat Python on nearly every benchmark.  It seems a likely 
candidate to &lt;em&gt;replace&lt;/em&gt; Python, not a support for my assertion that Python will 
remain relevant. But this is the thing: Pythons strength lies in community, 
and that community is incredibly difficult to replicate.&lt;/p&gt;
&lt;p&gt;A recent
&lt;a href="https://groups.google.com/forum/?fromgroups=#!topic/julia-dev/YftOOEfcwrk"&gt;thread&lt;/a&gt;
on the julia-dev list highlights what Im talking about:
in it, Dag Seljebotn, a core developer of Cython, contrasts the
strengths of Python (large user- and developer-base, large collection of
libraries) with the strengths of Julia (state-of-the-art performance,
JIT compilation).  He
proposes that the two languages should work together, each drawing from the
strengths of the other.  The response from the Julia community was incredibly
positive.&lt;/p&gt;
&lt;p&gt;The Julia developers know that Julia cant succeed as a scientific
computing platform without building an active community, and currently the
best way to do that is to work hand-in-hand with Python.  After this thread
on julia-dev, the Julia  developers were invited to give 
&lt;a href="http://pyvideo.org/video/1204/julia-a-fast-dynamic-language-for-technical-comp"&gt;a talk&lt;/a&gt; 
at the Scipy2012 conference,
and I think many would say that some good bridges were built.
I'm extremely excited about the prospects of Julia as a scientific computing
platform, but it will only succeed if it can embrace Python, and if Python
can embrace it.&lt;/p&gt;
&lt;h2&gt;The next Travis Oliphant&lt;/h2&gt;
&lt;p&gt;The third reason Python will be around for a while is this: &lt;em&gt;there will be 
another Travis Oliphant&lt;/em&gt;.  What do I mean by this?  Well, if you go back 
ten years or so, the Python scientific community was looking a bit weak.
Numeric was a 
well-established array interface, and the beginnings of SciPy were built 
upon it.  But Numeric was clunky, so some folks got together and built 
Numarray.  Numarray fixed some of the problems, but had its own weaknesses.
The biggest problem, though, was that it split the community:
when the core of your platform has divided allegiances, neither side wins.
Travis realized this, and against the advice of many, audaciously set out 
on a quest to unify the two.  The result was NumPy, which is now the 
unrivaled basis for nearly all scientific tools in Python.&lt;/p&gt;
&lt;p&gt;Python faces a similar crisis today: it is split in the area of
High-performance and parallel computing.  There is an alphabet soup of 
packages which aim to address this:
Cython, PyPy, Theano, Numba, Numexpr, and more.  But 
heres the thing: someone &lt;em&gt;will&lt;/em&gt; come along who has the audacity to strike
out and unify them.  I love this recent
&lt;a href="http://twitter.com/dwf/status/246756226367643650"&gt;tweet&lt;/a&gt; by Dave Warde-Farley:&lt;/p&gt;
&lt;p&gt;{% img /images/dwf_tweet.png 400 [Cumulative number of contributors for python packages] %}&lt;/p&gt;
&lt;p&gt;Somebody is going to do this: somebody will be the next Travis Oliphant
and create NumTron to re-unite the community.
Maybe Dave will be the next Travis Oliphant: he's done some great work on
&lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt;.
But then again, the merging of Python and LLVM in Travis'
&lt;a href="http://numba.pydata.org/"&gt;Numba&lt;/a&gt; project is
&lt;a href="/blog/2012/08/24/numba-vs-cython/"&gt;pretty exciting&lt;/a&gt;:
maybe Travis Oliphant will be the next Travis Oliphant --
hes done it before, after all.  Or perhaps it will be someone
weve never heard of, who as we speak is brewing a new idea in
an unwatched GitHub repository. Time will tell,
but Im confident that it will happen.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Maybe Ive convinced you, maybe I havent.  But Im going to continue using 
Python, and I predict you will too.  We'll see what the future holds for 
scientific computing, but in my mind, Python remains a pretty solid bet.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Finally, a brief post-script on the history of Python:
some of the most interesting sources I found were
&lt;a href="http://www.artima.com/intv/pythonP.html"&gt;this interview&lt;/a&gt; with Guido Van Rossum,
the official &lt;a href="http://www.scipy.org/History_of_SciPy"&gt;Scipy history page&lt;/a&gt;, the
&lt;a href="http://pyvideo.org/video/1192/matplotlib-lessons-from-middle-age-or-how-you"&gt;Scipy2012 talk&lt;/a&gt;
John Hunter gave this summer shortly before his sudden passing,
and the &lt;a href="http://mail.scipy.org/pipermail/numpy-discussion/2012-February/060640.html"&gt;numpy-discussion post&lt;/a&gt;
John referenced in his talk.  If you use Python regularly and have some
time, Id highly recommend browsing these: its incredible to see
how the unwavering vision of folks throughout the years has led to what we
have today: an unmatched open-source environment for scientific computing.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edit: also check out the
&lt;a href="http://python-history.blogspot.com/"&gt;History of Python&lt;/a&gt; blog.  Thanks to
Fernando for the tip.&lt;/em&gt;&lt;/p&gt;</summary></entry><entry><title>Dynamic Programming in Python: Bayesian Blocks</title><link href="/blog/2012/09/12/dynamic-programming-in-python/" rel="alternate"></link><updated>2012-09-12T19:02:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-09-12:blog/2012/09/12/dynamic-programming-in-python/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;Of all the programming styles I have learned,
&lt;a href="http://en.wikipedia.org/wiki/Dynamic_programming"&gt;dynamic programming&lt;/a&gt;
is perhaps the most beautiful.  It can take problems that, at first glance,
look ugly and intractable, and solve the problem with clean, concise code.
Where a simplistic algorithm might accomplish something by brute force,
dynamic programming steps back, breaks the task into a smaller set of
sequential parts, and then proceeds in the most efficient way possible.&lt;/p&gt;
&lt;h3&gt;Bayesian Blocks&lt;/h3&gt;
&lt;p&gt;I'll go through an example here where the ideas of dynamic programming
are vital to some very cool data analysis resuts.
This post draws heavily from a recent
&lt;a href="http://adsabs.harvard.edu/abs/2012arXiv1207.5578S"&gt;paper&lt;/a&gt; by Jeff Scargle
and collaborators (this is the Scargle of &lt;em&gt;Lomb-Scargle Periodogram&lt;/em&gt;
fame), as well as some conversations I had with Jeff at
&lt;a href="http://www.astro.caltech.edu/ai12/"&gt;Astroinformatics 2012&lt;/a&gt;.
The paper discusses
a framework called &lt;em&gt;Bayesian Blocks&lt;/em&gt;, which is essentially a method of
creating histograms with bin sizes that adapt to the data (there's a bit
more to it than that: here we'll focus on histograms for simplicity).&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;To motivate this, let's take a look at the histogram of some sampled data.
We'll create a complicated set of random data in the following way:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Define our test distribution: a mix of Cauchy-distributed variables&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stats&lt;/span&gt;

&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cauchy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rvs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                    &lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cauchy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rvs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                    &lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cauchy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rvs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                    &lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cauchy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rvs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                    &lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cauchy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rvs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

&lt;span class="c"&gt;# truncate values to a reasonable range&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now what does this distribution look like?  We can plot a histogram to find
out:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pylab&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pl&lt;/span&gt;
&lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;normed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;{% img /figures/bayesblocks1.png [Simple Histogram of our Distribution] %}&lt;/p&gt;
&lt;p&gt;Not too informative.  The default bins in &lt;code&gt;matplotlib&lt;/code&gt; are too wide for this
dataset.  We might be able to do better by increasing the number of bins:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;normed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;{% img /figures/bayesblocks2.png [More Detailed Histogram of our Distribution] %}&lt;/p&gt;
&lt;p&gt;This is better.  But having to choose the bin width each time we plot a
distribution is not only tiresome, it may lead to missing some important
information in our data.  In a perfect world, we'd like for
the bin width to be learned in an automated fashion, based on the
properties of the data itself.
There have been many rules-of-thumb proposed for this task
(look up &lt;em&gt;Scott's Rule&lt;/em&gt;, &lt;em&gt;Knuth's Rule&lt;/em&gt;, the &lt;em&gt;Freedman-Diaconis Rule&lt;/em&gt;,
and others in your favorite statistics text).
But all these rules of thumb share a disadvantage: they make the assumption
that all the bins are the same size.  This is not necessarily optimal.  But
can we do better?&lt;/p&gt;
&lt;p&gt;Scargle and collaborators showed that the answer is yes.  This is their insight:
For a set of histogram bins or &lt;em&gt;blocks&lt;/em&gt;, each of an arbitrary size,
one can use a Bayesian
likelihood framework to compute a &lt;em&gt;fitness function&lt;/em&gt; which only depends on
two numbers: the width of each block, and the number of points in each block.
The edges between these blocks (the &lt;em&gt;change-points&lt;/em&gt;) can be varied, and
the overall block configuration with the maximum fitness is quantitatively
the best binning.&lt;/p&gt;
&lt;p&gt;Simple, right?&lt;/p&gt;
&lt;p&gt;Well, no.  The problem is, as the number of points N grows large, the number
of possible configurations grows as $2^N$.  For N=300 points, there are already
more possible configurations than the number of subatomic particles in the
observable universe!  Clearly an exhaustive search will fail in cases of
interest.  This is where &lt;em&gt;dynamic programming&lt;/em&gt; comes to the rescue.&lt;/p&gt;
&lt;h3&gt;Dynamic Programming&lt;/h3&gt;
&lt;p&gt;Dynamic programming is very similar to mathematical proof by induction. By
way of example, consider the formula&lt;/p&gt;
&lt;p&gt;$$1 + 2 + \cdots + n = \frac{n(n+1)}{2}.$$&lt;/p&gt;
&lt;p&gt;How could you prove that this is true for all positive integers $n$?
An inductive proof of this formula proceeds in the following fashion:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Base Case&lt;/strong&gt;: We can easily show that the formula holds for $n = 1$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Inductive Step&lt;/strong&gt;: For some value $k$, assume that
   $1 + 2 + \cdots + k = \frac{k(k+1)}{2}$ holds.
   Adding $(k + 1)$ to each side and rearranging the result yields
   $1 + 2 + \cdots + k + (k + 1) = \frac{(k + 1)(k + 2)}{2}$.  Looking
   closely at this, we see that we have shown the following:
   if our formula is true for $k$, then it must be true for $k + 1$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;By 1 and 2, we can show that the formula is true for any positive integer
   $n$, simply by starting at $n=1$ and repeating the inductive step
   $n - 1$ times.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Dynamic programming proceeds in much the same vein.  In our Bayesian Blocks
example, we can easily find the optimal binning for a single point.  By
making use of some mathematical proofs concerning the fitness functions,
we can devise a simple step from the optimal binning for $k$ points to the
optimal binning for $k + 1$ points (the details can be found in the
appendices of the
&lt;a href="http://adsabs.harvard.edu/abs/2012arXiv1207.5578S"&gt;Scargle paper&lt;/a&gt;).
In this way, Scargle and collaborators showed that the $2^N$ possible states
can be explored in $N^2$ time.&lt;/p&gt;
&lt;h3&gt;The Algorithm&lt;/h3&gt;
&lt;p&gt;The resulting algorithm is deceptively simple, but it can be proven to converge
to the single best configuration among the $2^N$ possibilities.  Below is the
basic code written in python.  Note that there are a few details that are
missing from this version (e.g. priors on the number of bins, other forms
of fitness functions, etc.) but this gets the basic job done:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bayesian_blocks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Bayesian Blocks Implementation&lt;/span&gt;

&lt;span class="sd"&gt;    By Jake Vanderplas.  License: BSD&lt;/span&gt;
&lt;span class="sd"&gt;    Based on algorithm outlined in http://adsabs.harvard.edu/abs/2012arXiv1207.5578S&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters&lt;/span&gt;
&lt;span class="sd"&gt;    ----------&lt;/span&gt;
&lt;span class="sd"&gt;    t : ndarray, length N&lt;/span&gt;
&lt;span class="sd"&gt;        data to be histogrammed&lt;/span&gt;

&lt;span class="sd"&gt;    Returns&lt;/span&gt;
&lt;span class="sd"&gt;    -------&lt;/span&gt;
&lt;span class="sd"&gt;    bins : ndarray&lt;/span&gt;
&lt;span class="sd"&gt;        array containing the (N+1) bin edges&lt;/span&gt;

&lt;span class="sd"&gt;    Notes&lt;/span&gt;
&lt;span class="sd"&gt;    -----&lt;/span&gt;
&lt;span class="sd"&gt;    This is an incomplete implementation: it may fail for some&lt;/span&gt;
&lt;span class="sd"&gt;    datasets.  Alternate fitness functions and prior forms can&lt;/span&gt;
&lt;span class="sd"&gt;    be found in the paper listed above.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c"&gt;# copy and sort the array&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;

    &lt;span class="c"&gt;# create length-(N + 1) array of cell edges&lt;/span&gt;
    &lt;span class="n"&gt;edges&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                            &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
                            &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]])&lt;/span&gt;
    &lt;span class="n"&gt;block_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;edges&lt;/span&gt;

    &lt;span class="c"&gt;# arrays needed for the iteration&lt;/span&gt;
    &lt;span class="n"&gt;nn_vec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;last&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;#-----------------------------------------------------------------&lt;/span&gt;
    &lt;span class="c"&gt;# Start with first data cell; add one cell at each iteration&lt;/span&gt;
    &lt;span class="c"&gt;#-----------------------------------------------------------------&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;K&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c"&gt;# Compute the width and count of the final bin for all possible&lt;/span&gt;
        &lt;span class="c"&gt;# locations of the K^th changepoint&lt;/span&gt;
        &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;block_length&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;block_length&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;count_vec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cumsum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn_vec&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="c"&gt;# evaluate fitness function for these possibilities&lt;/span&gt;
        &lt;span class="n"&gt;fit_vec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_vec&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_vec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;fit_vec&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="c"&gt;# 4 comes from the prior on the number of changepoints&lt;/span&gt;
        &lt;span class="n"&gt;fit_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="c"&gt;# find the max of the fitness: this is the K^th changepoint&lt;/span&gt;
        &lt;span class="n"&gt;i_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_vec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i_max&lt;/span&gt;
        &lt;span class="n"&gt;best&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_max&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c"&gt;#-----------------------------------------------------------------&lt;/span&gt;
    &lt;span class="c"&gt;# Recover changepoints by iteratively peeling off the last block&lt;/span&gt;
    &lt;span class="c"&gt;#-----------------------------------------------------------------&lt;/span&gt;
    &lt;span class="n"&gt;change_points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;i_cp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;
    &lt;span class="n"&gt;ind&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;i_cp&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;change_points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_cp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ind&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ind&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
        &lt;span class="n"&gt;ind&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ind&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;change_points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;change_points&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i_cp&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;edges&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;change_points&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The details of the step from $K$ to $K + 1$ may be a bit confusing from this
implementation: it boils down to the fact that Scargle &lt;em&gt;et al.&lt;/em&gt; were able to
show that given an optimal configuration of $K$ points, the $(K + 1)$^th
configuration is limited to one of $K$ possibilities.&lt;/p&gt;
&lt;p&gt;The function as written above takes a sequence of points, and returns the
edges of the optimal bins.  We'll visualize the result on top of the histogram
we saw earlier:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# plot a standard histogram in the background, with alpha transparency&lt;/span&gt;
&lt;span class="n"&gt;H1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;histtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;stepfilled&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;normed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# plot an adaptive-width histogram on top&lt;/span&gt;
&lt;span class="n"&gt;H2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bayesian_blocks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="n"&gt;histtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;step&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;normed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;{% img /figures/bayesblocks3.png [Adaptive Histogram of our Distribution] %}&lt;/p&gt;
&lt;p&gt;The adaptive-width bins lead to a very clean representation of the important
features in the data.  More importantly, these bins are quantifiably optimal,
and their properties can be used to make quantitative statistical
statements about the nature of the data.  This type of procedure has proven
very useful in analysis of time-series data in Astronomy.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;We've just scratched the surface of Bayesian Blocks and Dynamic Programming.
Some of the more interesting details of this algorithm require much more
depth: the appendicies of the
&lt;a href="http://adsabs.harvard.edu/abs/2012arXiv1207.5578S"&gt;Scargle paper&lt;/a&gt;
provide these details.  Dynamic Programming ideas have been shown to be
useful in many optimization problems.  One other example I've worked with
extensively is
&lt;a href="http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm"&gt;Dijkstra's Algorithm&lt;/a&gt;
for computing the shortest paths on a connected graph.  This is available in
the &lt;a href="http://docs.scipy.org/doc/scipy/reference/tutorial/csgraph.html"&gt;scipy.sparse.csgraph&lt;/a&gt;
submodule, which is included in the most recent release of scipy.&lt;/p&gt;
&lt;p&gt;The above python implementation of Bayesian Blocks
is an extremely basic form of the algorithm: I plan to include some
more sophisticated options in the python package I'm currently
working on, called &lt;em&gt;astroML: Machine Learning for Astrophysics&lt;/em&gt;.
I'll release version 0.1 of astroML at the end of October 2012,
in time to present it at &lt;a href="http://c3.nasa.gov/dashlink/events/1/"&gt;CIDU 2012&lt;/a&gt;.
If you're interested, I'll have updates here on the blog, as well as on
my &lt;a href="http://twitter.com/jakevdp"&gt;twitter feed&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update: astroML version 0.1 has been released: see the web site
&lt;a href="http://astroML.github.com"&gt;here&lt;/a&gt;.  It includes a full-featured Bayesian
blocks implementation with histogram tools, which you can read about
&lt;a href="http://astroml.github.com/user_guide/density_estimation.html#bayesian-blocks-histograms-the-right-way"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Finally, all of the above code snippets are available as an ipython
notebook: &lt;a href="/downloads/notebooks/bayesian_blocks.ipynb"&gt;bayesian_blocks.ipynb&lt;/a&gt;.
For information on how to view this file, see the
&lt;a href="http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html"&gt;IPython page&lt;/a&gt;.
Alternatively, you can view this notebook (but not modify it) using the
nbviewer utility &lt;a href="http://nbviewer.ipython.org/url/jakevdp.github.com/downloads/notebooks/bayesian_blocks.ipynb"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary></entry><entry><title>Quantum Python: Animating the Schrodinger Equation</title><link href="/blog/2012/09/05/quantum-python/" rel="alternate"></link><updated>2012-09-05T20:12:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-09-05:blog/2012/09/05/quantum-python/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;&lt;em&gt;Update: a reader contributed some improvements to the Python code presented
 below.  Please see the
&lt;a href="https://github.com/jakevdp/pySchrodinger"&gt;pySchrodinger&lt;/a&gt; github repository
for updated code&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In a &lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;previous post&lt;/a&gt;
I explored the new animation capabilities of the latest
&lt;a href="http://matplotlib.sourceforge.net"&gt;matplotlib&lt;/a&gt; release.
It got me wondering whether it would be possible to simulate more complicated
physical systems in real time in python.  Quantum Mechanics was the first
thing that came to mind.  It turns out that by mixing a bit of Physics
knowledge with a bit of computing knowledge, it's quite straightforward
to simulate and animate a simple quantum mechanical system with python.&lt;/p&gt;
&lt;h2&gt;The Schrodinger Equation&lt;/h2&gt;
&lt;p&gt;The dynamics of a one-dimensional quantum system are governed by the
time-dependent Schrodinger equation:&lt;/p&gt;
&lt;p&gt;$$
i\hbar\frac{\partial \psi}{\partial t}
  = \frac{-\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} + V \psi
$$&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;The &lt;em&gt;wave function&lt;/em&gt; $\psi$ is a function of both position $x$ and time $t$,
and is the fundamental description of the realm of the very small.
Imagine we are following the motion of a single particle in one
dimension.  This wave function represents a probability of measuring
the particle at a position $x$ at a time $t$. Quantum mechanics tells us that
(contrary to our familiar classical reasoning) this probability is not
a limitation of our knowledge of the system, but a reflection of an
unavoidable uncertainty about the position and time of events in the realm
of the very small.&lt;/p&gt;
&lt;p&gt;Still, this equation is a bit opaque, but to visualize the results we'll need
to solve this numerically.  We'll approach this using the split-step Fourier
method.&lt;/p&gt;
&lt;h2&gt;The Split-step Fourier Method&lt;/h2&gt;
&lt;p&gt;A standard way to numerically solve certain differential equations is
through the use of the Fourier transform.  We'll use a Fourier convention
of the following form:&lt;/p&gt;
&lt;p&gt;$$
\widetilde{\psi}(k, t) = \frac{1}{\sqrt{2\pi}}
  \int_{-\infty}^{\infty} \psi(x, t) e^{-ikx} dx
$$&lt;/p&gt;
&lt;p&gt;Under this convention, the associated inverse Fourier Transform is given by:&lt;/p&gt;
&lt;p&gt;$$
\psi(x, t) = \frac{1}{\sqrt{2\pi}}
  \int_{-\infty}^{\infty} \widetilde{\psi}(k, t) e^{ikx} dk
$$&lt;/p&gt;
&lt;p&gt;Substituting this into the Schrodinger equation and simplifying gives the
Fourier-space form of the Schrodinger equation:&lt;/p&gt;
&lt;p&gt;$$
i\hbar\frac{\partial \widetilde{\psi}}{\partial t}
  = \frac{\hbar^2 k^2}{2m} \widetilde{\psi}
  + V(i\frac{\partial}{\partial k})\widetilde{\psi}
$$&lt;/p&gt;
&lt;p&gt;The two versions of the Schrodinger equation contain an interesting symmetry:
the time step in each case depends on a straightforward multiplication of
the wave function $\psi$, as well as a more complicated term involving
derivatives with respect to $x$ or $k$.  The key observation is that while
the equation is difficult to evaluate fully within one of the forms, each
basis offers a straightforward calculation of one of the two contributions.
This suggests an efficient strategy to numerically solve the Schrodinger
Equation.&lt;/p&gt;
&lt;p&gt;First we solve the straightforward part of the $x$-space Schrodinger
equation:&lt;/p&gt;
&lt;p&gt;$$
i\hbar\frac{\partial \psi}{\partial t}
  = V(x) \psi
$$&lt;/p&gt;
&lt;p&gt;For a small time step $\Delta t$, this has a solution of the form&lt;/p&gt;
&lt;p&gt;$$
\psi(x, t + \Delta t) = \psi(x, t) e^{-i V(x) \Delta t / \hbar}
$$&lt;/p&gt;
&lt;p&gt;Second, we solve the straightforward part of the $k$-space Schrodinger
equation:&lt;/p&gt;
&lt;p&gt;$$
i\hbar\frac{\partial \widetilde{\psi}}{\partial t}
  = \frac{\hbar^2 k^2}{2 m} \widetilde{\psi}
$$&lt;/p&gt;
&lt;p&gt;For a small time step $\Delta t$, this has a solution of the form&lt;/p&gt;
&lt;p&gt;$$
\widetilde{\psi}(k, t + \Delta t)
    = \widetilde{\psi}(k, t) e^{-i \hbar k^2 \Delta t / 2m}
$$&lt;/p&gt;
&lt;h2&gt;Numerical Considerations&lt;/h2&gt;
&lt;p&gt;Solving this system numerically will require repeated computations of the
Fourier transform of $\psi(x, t)$ and the inverse Fourier transform of
$\widetilde{\psi}(k, t)$.  The best-known algorithm for computation of
numerical Fourier transforms is the Fast Fourier Transform (FFT), which
is &lt;a href="http://docs.scipy.org/doc/scipy/reference/fftpack.html"&gt;available in scipy&lt;/a&gt;
and efficiently computes the following form of the
discrete Fourier transform:&lt;/p&gt;
&lt;p&gt;$$
  \widetilde{F_m} = \sum_{n=0}^{N-1} F_n e^{-2\pi i n m / N}
$$&lt;/p&gt;
&lt;p&gt;and its inverse&lt;/p&gt;
&lt;p&gt;$$
  F_n = \frac{1}{N} \sum_{m=0}^{N-1} \widetilde{F_m} e^{2\pi i n m / N}
$$&lt;/p&gt;
&lt;p&gt;We need to know how these relate to the continuous Fourier transforms defined
and used above.  Let's take the example of the forward transform.  Assume that
the infinite integral is well-approximated by the finite integral from
$a$ to $b$, so that we can write&lt;/p&gt;
&lt;p&gt;$$
\widetilde{\psi}(k, t) = \frac{1}{\sqrt{2\pi}}
   \int_a^b \psi(x, t) e^{-ikx} dx
$$&lt;/p&gt;
&lt;p&gt;This approximation ends up being equivalent to assuming that the potential
$V(x) \to \infty$ at $x \le a$ and $x \ge b$.  We'll now approximate this
integral as a Riemann sum of $N$ terms, and define $\Delta x = (b - a) / N$,
and $x_n = a + n\Delta x$:&lt;/p&gt;
&lt;p&gt;$$
\widetilde{\psi}(k, t) \simeq \frac{1}{\sqrt{2\pi}}
   \sum_{n=0}^{N-1} \psi(x_n, t) e^{-ikx_n} \Delta x
$$&lt;/p&gt;
&lt;p&gt;This is starting to look like the discrete Fourier transform!  To bring it
even closer, let's define $k_m = k_0 + m\Delta k$, with
$\Delta k = 2\pi / (N\Delta x)$.  Then our approximation becomes&lt;/p&gt;
&lt;p&gt;$$
\widetilde{\psi}(k_m, t) \simeq \frac{1}{\sqrt{2\pi}}
   \sum_{n=0}^{N-1} \psi(x_n, t) e^{-ik_m x_n} \Delta x
$$&lt;/p&gt;
&lt;p&gt;(Note that just as we have limited the range of $x$ above, we have here limited
the range of $k$ as well.  This means that high-frequency components of the
signal will be lost in our approximation.  The Nyquist sampling theorem tells
us that this is an unavoidable consequence of choosing discrete steps in
space, and it can be shown that the spacing we chose above exactly satisfies
the Nyquist limit if we choose $k_0 = - \pi / \Delta x$).&lt;/p&gt;
&lt;p&gt;Plugging our expressions for $x_n$ and $k_m$ into the Fourier
approximation and rearranging, we find the following:&lt;/p&gt;
&lt;p&gt;$$
\left[\widetilde{\psi}(k_m, t) e^{i m x_0 \Delta k}\right]
   \simeq \sum_{n=0}^{N-1} 
   \left[ \frac{\Delta x}{\sqrt{2\pi}}
   \psi(x_n, t) e^{-ik_0 x_n} \right]
   e^{-2\pi i m n / N}
$$&lt;/p&gt;
&lt;p&gt;Similar arguments from the inverse Fourier transform yield:&lt;/p&gt;
&lt;p&gt;$$
\left[\frac{\Delta x}{\sqrt{2 \pi}} \psi(x_n, t) e^{-i k_0 x_n}\right]
   \simeq \frac{1}{N} \sum_{m=0}^{N-1} 
   \left[\widetilde{\psi}(k_m, t) e^{-i m x_0 \Delta k} \right]
   e^{2\pi i m n / N}
$$&lt;/p&gt;
&lt;p&gt;Comparing these to the discrete Fourier transforms above, we find that the
&lt;em&gt;continuous&lt;/em&gt; Fourier pair&lt;/p&gt;
&lt;p&gt;$$
   \psi(x, t) \Longleftrightarrow \widetilde{\psi}(k, t)
$$&lt;/p&gt;
&lt;p&gt;corresponds to the &lt;em&gt;discrete&lt;/em&gt; Fourier pair&lt;/p&gt;
&lt;p&gt;$$
   \frac{\Delta x}{\sqrt{2 \pi}} \psi(x_n, t) e^{-i k_0 x_n}
   \Longleftrightarrow
   \widetilde{\psi}(k_m, t) e^{-i m x_0 \Delta k}
$$&lt;/p&gt;
&lt;p&gt;subject to the approximations mentioned above.  This allows a fast numerical
evaluation of the Schrodinger equation.&lt;/p&gt;
&lt;h2&gt;Putting It All Together: the Algorithm&lt;/h2&gt;
&lt;p&gt;We now put this all together using the following algorithm&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Choose $a$, $b$, $N$, and $k_0$ as above, sufficient to represent the
   initial state of your wave function $\psi(x)$. (&lt;strong&gt;Warning:&lt;/strong&gt; this is perhaps
   the hardest part of the entire solution. If limits in $x$ or $k$ are chosen
   which do not suit your problem, then the approximations used above can
   destroy the accuracy of the calculation!)  Once these are chosen, then
   $\Delta x = (b - a) / N$ and $\Delta k = 2\pi / (b - a)$.  Define
   $x_n = a + n \Delta x$ and $k_m = k_0 + m \Delta k$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discretize the wave-functions on this grid.  Let $\psi_n(t) = \psi(x_n, t)$,
   $V_n = V(x_n)$, and $\widetilde{\psi}_m = \widetilde{\psi}(k_m, t)$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To progress the system by a time-step $\Delta t$, perform the following:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute a half-step in $x$:
      $\psi_n \longleftarrow \psi_n
       \exp[-i (\Delta t / 2) (V_n / \hbar)]$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Calculate $\widetilde{\psi}_m$ from $\psi_n$ using the FFT.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute a full-step in $k$:
      $\widetilde{\psi}_m \longleftarrow \widetilde{\psi}_m
      \exp[-i \hbar (k \cdot k) \Delta t / (2 m)]$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Calculate $\psi_n$ from $\widetilde{\psi}_m$ using the inverse FFT.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute a second half-step in $x$:
      $\psi_n \longleftarrow \psi_n
       \exp[-i (\Delta t / 2)(V_n / \hbar)]$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat step 3 until the desired time is reached.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that we have split the $x$-space time-step into two half-steps: this
turns out to lead to a more stable numerical solution than performing
the step all at once. Those familiar with numerical integration
algorithms may recognize this as an example of the
well-known leap-frog integration technique.&lt;/p&gt;
&lt;p&gt;To test this out, I've written a python code which sets up a particle in a
box with a potential barrier.  The barrier is high enough that a classical
particle would be unable to penetrate it.  A quantum particle, however, can
"tunnel" through, leading to a non-zero probability of finding the particle
on the other side of the partition.  This quantum tunneling effect lies at
the core of technologies as diverse as electron microsopy, semiconding diodes,
and perhaps even the future of low-powered transistors.&lt;/p&gt;
&lt;p&gt;The animation of the result is below (for a brief introduction to the animation
capabilities of python, see
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;this post&lt;/a&gt;).
The top panel shows the position-space wave function, while the bottom panel
shows the momentum-space wave function.&lt;/p&gt;
&lt;p&gt;{% video /downloads/videos/schrodinger_barrier.mp4 360 270 /downloads/videos/schrodinger_barrier_frame.png %}&lt;/p&gt;
&lt;p&gt;Notice that the height of the potential barrier (denoted by the dashed line in
the bottom panel) is far larger than the energy of the particle.  Still, due
to quantum effects, a small part of the wave function is able to tunnel through
the barrier and reach the other side.&lt;/p&gt;
&lt;p&gt;The python code used to generate this animation is included below.  It's pretty
long, but I've tried to comment extensively to make the algorithm more clear.
If you're so inclined, you might try running the example and adjusting the
potential or the input wave function to see the effect on the dynamics of
the quantum system.&lt;/p&gt;
&lt;p&gt;{% include_code schrodinger.py lang:python Schrodinger %}&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edit: I changed the legend font properties to play nicely with older
 matplotlib versions.  Thanks to Yann for pointing it out.&lt;/em&gt;&lt;/p&gt;</summary></entry><entry><title>Numba vs Cython</title><link href="/blog/2012/08/24/numba-vs-cython/" rel="alternate"></link><updated>2012-08-24T10:41:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-08-24:blog/2012/08/24/numba-vs-cython/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;&lt;em&gt;For a more up-to-date comparison of Numba and Cython, see the&lt;/em&gt;
&lt;a href="http://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/"&gt;&lt;em&gt;newer post&lt;/em&gt;&lt;/a&gt;
&lt;em&gt;on this subject.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Often I'll tell people that I use python for computational analysis, and they
look at me inquisitively.  "Isn't python pretty slow?"  They have a point.
Python is an interpreted language, and as such cannot natively perform
many operations as quickly as a compiled language such as C or Fortran.
There is also the issue of the oft-misunderstood and much-maligned
&lt;a href="http://wiki.python.org/moin/GlobalInterpreterLock"&gt;GIL&lt;/a&gt;,
which calls into question python's ability to allow true parallel computing.&lt;/p&gt;
&lt;p&gt;Many solutions have been proposed: &lt;a href="http://pypy.org/"&gt;PyPy&lt;/a&gt; is a much faster
version of the core python language; 
&lt;a href="http://code.google.com/p/numexpr/"&gt;numexpr&lt;/a&gt; provides optimized performance
on certain classes of operations from within python;
&lt;a href="http://www.scipy.org/Weave/"&gt;weave&lt;/a&gt; allows inline inclusion of compiled
C/C++ code;
&lt;a href="http://www.cython.org/"&gt;cython&lt;/a&gt; provides extra markup that allows python
and/or python-like code to be compiled into C for fast operations.  But
a naysayer might point out: many of these "python" solutions in practice
are not really python at all, but clever hacks into Fortran or C.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;I personally have no problem with this. I like python because it gives me a nice
work-flow: it has a clean syntax, I don't need to spend my time hunting down
memory errors, it's quick to try-out code snippets, it's easy to wrap legacy
code written in C and Fortran, and I'm much more productive when writing
python vs writing C or C++.  &lt;a href="http://numpy.scipy.org"&gt;Numpy&lt;/a&gt;,
&lt;a href="http://www.scipy.org"&gt;scipy&lt;/a&gt;, and &lt;a href="http://www.scikit-learn.org"&gt;scikit-learn&lt;/a&gt;
give me optimized routines for most of what I need to do on a daily basis,
and if something more specialized comes up, cython has never failed me.
Nevertheless, the whole setup is a bit clunky:
why can't I have the best of both worlds: a beautiful, scripted, dynamically
typed language like python, with the speed of C or Fortran?&lt;/p&gt;
&lt;p&gt;In recent years, new languages like &lt;a href="http://golang.org/"&gt;go&lt;/a&gt; and
&lt;a href="http://julialang.org/"&gt;julia&lt;/a&gt; have popped up which try to address some of
these issues.  Julia in particular has a number of nice properties (see the
&lt;a href="http://www.youtube.com/watch?v=VCp1jUgVRgE"&gt;talk&lt;/a&gt; from Scipy 2012 for a
good introduction) and uses &lt;a href="http://llvm.org"&gt;LLVM&lt;/a&gt; to enable just-in-time
(JIT) compilation and achieve some impressive benchmarks.  Julia holds promise,
but I'm not yet ready to abandon the incredible code-base and user-base
of the python community.&lt;/p&gt;
&lt;p&gt;Enter &lt;a href="http://numba.pydata.org/"&gt;numba&lt;/a&gt;.  This is an attempt to bring JIT
compilation cleanly to python, using the LLVM framework.  In a
&lt;a href="/blog/2012/08/08/memoryview-benchmarks/"&gt;recent post&lt;/a&gt;, one commenter pointed
out numba as an alternative to cython.  I had heard about it before (See
Travis Oliphant's scipy 2012 talk
&lt;a href="http://www.youtube.com/watch?v=WYi1cymszqY"&gt;here&lt;/a&gt;) but hadn't had the chance
to try it out until now. Installation is a bit involved, but the directions
on the &lt;a href="http://numba.pydata.org/"&gt;numba website&lt;/a&gt; are pretty good.&lt;/p&gt;
&lt;p&gt;To test this out, I decided to run some benchmarks using the
pairwise distance function I've explored before (see posts
&lt;a href="/blog/2012/08/08/memoryview-benchmarks/"&gt;here&lt;/a&gt;
and &lt;a href="/blog/2012/08/16/memoryview-benchmarks-2/"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;h3&gt;Pure Python Version&lt;/h3&gt;
&lt;p&gt;The pure python version of the function looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pairwise_python&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;M&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Not surprisingly, this is very slow.  For an array consisting of 1000 points
in three dimensions, execution takes over 12 seconds on my machine:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise_python&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;12.1&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Numba Version&lt;/h3&gt;
&lt;p&gt;Once numba is installed, we add only a single line to our above definition
to allow numba to interface our code with LLVM:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;numba&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;
&lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;numba&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decorators&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;jit&lt;/span&gt;

&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg_types&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;pairwise_numba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;M&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I should emphasize that this is the &lt;em&gt;exact same&lt;/em&gt; code, except for numba's
&lt;code&gt;jit&lt;/code&gt; decorator.  The results are pretty astonishing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise_numba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;15.5&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is a three order-of-magnitude speedup, simply by adding a numba
decorator!&lt;/p&gt;
&lt;h3&gt;Cython Version&lt;/h3&gt;
&lt;p&gt;For completeness, let's do the same thing in cython.  Cython
takes a bit more than just some decorators: there are also type specifiers
and other imports required.  Additionally, we'll use the &lt;code&gt;sqrt&lt;/code&gt; function
from the C math library rather than from numpy.  Here's the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;libc.math&lt;/span&gt; &lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pairwise_cython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;M&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;d&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Running this shows about a 30% speedup over numba:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise_numba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;9.86&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;The Takeaway&lt;/h3&gt;
&lt;p&gt;So numba is 1000 times faster than a pure python implementation, and only
marginally slower than nearly identical cython code.
There are some caveats here: first of all, I have years of experience with
cython, and only an hour's experience with numba.  I've used every optimization
I know for the cython version, and just the basic vanilla syntax for numba.
There are likely ways to tweak the numba version to make it even faster,
as indicated in the comments of
&lt;a href="/blog/2012/08/08/memoryview-benchmarks/"&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All in all, I should say I'm very impressed.  Using numba, I added
just a &lt;em&gt;single line&lt;/em&gt; to the original python code, and
was able to attain speeds competetive with a highly-optimized (and
significantly less "pythonic")  cython implementation.  Based on this,
I'm extremely excited to see what numba brings in the future.&lt;/p&gt;
&lt;p&gt;All the above code is available as an ipython notebook:
&lt;a href="/downloads/notebooks/numba_vs_cython.ipynb"&gt;numba_vs_cython.ipynb&lt;/a&gt;.
For information on how to view this file, see the
&lt;a href="http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html"&gt;IPython page&lt;/a&gt;
Alternatively, you can view this notebook (but not modify it) using the
nbviewer &lt;a href="http://nbviewer.ipython.org/url/jakevdp.github.com/downloads/notebooks/numba_vs_cython.ipynb"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary></entry><entry><title>Matplotlib Animation Tutorial</title><link href="/blog/2012/08/18/matplotlib-animation-tutorial/" rel="alternate"></link><updated>2012-08-18T08:01:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-08-18:blog/2012/08/18/matplotlib-animation-tutorial/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;&lt;a href="http://matplotlib.sourceforge.net"&gt;Matplotlib&lt;/a&gt; version 1.1 added some tools
for creating
&lt;a href="http://matplotlib.sourceforge.net/api/animation_api.html"&gt;animations&lt;/a&gt;
which are really slick.  You can find some good example animations on
the matplotlib
&lt;a href="http://matplotlib.sourceforge.net/examples/animation/index.html"&gt;examples&lt;/a&gt;
page.  I thought I'd share here some of the things I've learned when playing
around with these tools.&lt;/p&gt;
&lt;h3&gt;Basic Animation&lt;/h3&gt;
&lt;p&gt;The animation tools center around the &lt;code&gt;matplotlib.animation.Animation&lt;/code&gt; base
class, which provides a framework around which the animation functionality
is built.  The main interfaces are &lt;code&gt;TimedAnimation&lt;/code&gt; and &lt;code&gt;FuncAnimation&lt;/code&gt;,
which you can read more about in the
&lt;a href="http://matplotlib.sourceforge.net/api/animation_api.html"&gt;documentation&lt;/a&gt;.
Here I'll explore using the &lt;code&gt;FuncAnimation&lt;/code&gt; tool, which I have found
to be the most useful.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;First we'll use &lt;code&gt;FuncAnimation&lt;/code&gt; to do a basic animation of a sine wave moving
across the screen:&lt;/p&gt;
&lt;p&gt;{% include_code basic_animation.py lang:python Basic Animation %}&lt;/p&gt;
&lt;p&gt;Let's step through this and see what's going on.  After importing required
pieces of &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt;, The script sets up the plot:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we create a figure window, create a single axis in the figure, and then
create our line object which will be modified in the animation.  Note that
here we simply plot an empty line: we'll add data to the line later.&lt;/p&gt;
&lt;p&gt;Next we'll create the functions which make the animation happen.  &lt;code&gt;init()&lt;/code&gt;
is the function which will be called to create the base frame upon which
the animation takes place.  Here we use just a simple function which sets
the line data to nothing.  It is important that this function return the
line object, because this tells the animator which objects on the plot to
update after each frame:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The next piece is the animation function.  It takes a single parameter, the
frame number &lt;code&gt;i&lt;/code&gt;, and draws a sine wave with a shift that depends on &lt;code&gt;i&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nx"&gt;animation&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;  &lt;span class="nx"&gt;This&lt;/span&gt; &lt;span class="nx"&gt;is&lt;/span&gt; &lt;span class="nx"&gt;called&lt;/span&gt; &lt;span class="nx"&gt;sequentially&lt;/span&gt;
&lt;span class="nx"&gt;def&lt;/span&gt; &lt;span class="nx"&gt;animate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nx"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nx"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;pi&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nx"&gt;line&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;set_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that again here we return a tuple of the plot objects which have been
modified.  This tells the animation framework what parts of the plot should
be animated.&lt;/p&gt;
&lt;p&gt;Finally, we create the animation object:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;animate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This object needs to persist, so it must be assigned to a variable.  We've
chosen a 100 frame animation with a 20ms delay between frames.  The
&lt;code&gt;blit&lt;/code&gt; keyword is an important one: this tells the animation to only re-draw
the pieces of the plot which have changed.  The time saved with &lt;code&gt;blit=True&lt;/code&gt;
means that the animations display much more quickly.&lt;/p&gt;
&lt;p 270="270" 360="360" _="%" _downloads_videos_basic_animation.mp4="/downloads/videos/basic_animation.mp4" _downloads_videos_basic_animation_frame.png="/downloads/videos/basic_animation_frame.png" video="video"&gt;We end with an optional save command, and then a show command to show the
result.  Here's what the script generates:&lt;/p&gt;
&lt;p&gt;This framework for generating and saving animations is very powerful and
flexible: if we put some physics into the &lt;code&gt;animate&lt;/code&gt; function, the possibilities
are endless.  Below are a couple examples of some physics animations that
I've been playing around with.&lt;/p&gt;
&lt;h3&gt;Double Pendulum&lt;/h3&gt;
&lt;p&gt;One of the examples provided on the matplotlib
&lt;a href="http://matplotlib.sourceforge.net/examples/animation/index.html"&gt;example page&lt;/a&gt;
is an animation of a double pendulum.  This example operates by precomputing
the pendulum position over 10 seconds, and then animating the results.  I
saw this and wondered if python would be fast enough to compute the dynamics
on the fly.  It turns out it is:&lt;/p&gt;
&lt;p&gt;{% include_code double_pendulum.py lang:python Double Pendulum %}&lt;/p&gt;
&lt;p&gt;Here we've created a class which stores the state of the double pendulum
(encoded in the angle of each arm plus the angular velocity of each arm)
and also provides some functions for computing the dynamics.  The animation
functions are the same as above, but we just have a bit more complicated
update function: it not only changes the position of the points, but also
changes the text to keep track of time and energy (energy should be constant
if our math is correct: it's comforting that it is).  The video below
lasts only ten seconds, but by running the script you can watch the
pendulum chaotically oscillate until your laptop runs out of power:&lt;/p&gt;
&lt;p&gt;{% video /downloads/videos/double_pendulum.mp4 360 270 /downloads/videos/double_pendulum_frame.png %}&lt;/p&gt;
&lt;h3&gt;Particles in a Box&lt;/h3&gt;
&lt;p&gt;Another animation I created is the elastic collisions of a group of particles
in a box under the force of gravity.  The collisions are elastic: they conserve
energy and 2D momentum, and the particles bounce realistically off the walls
of the box and fall under the influence of a constant gravitational force:&lt;/p&gt;
&lt;p&gt;{% include_code particle_box.py lang:python Particles in a Box %}&lt;/p&gt;
&lt;p&gt;The math should be familiar to anyone with a physics background, and the
result is pretty mesmerizing.  I coded this up during a flight, and ended
up just sitting and watching it for about ten minutes.&lt;/p&gt;
&lt;p&gt;{% video /downloads/videos/particle_box.mp4 360 270 /downloads/videos/particle_box_frame.png %}&lt;/p&gt;
&lt;p&gt;This is just the beginning: it might be an interesting exercise to add
other elements, like computation of the temperature and pressure to demonstrate
the ideal gas law, or real-time plotting of the velocity distribution to
watch it approach the expected Maxwellian distribution.  It opens up many
possibilities for virtual physics demos...&lt;/p&gt;
&lt;h3&gt;Summing it up&lt;/h3&gt;
&lt;p&gt;The matplotlib animation module is an excellent addition to what was already
an excellent package.  I think I've just scratched the surface of what's
possible with these tools... what cool animation ideas can you come up
with?&lt;/p&gt;
&lt;p&gt;Edit: in a &lt;a href="/blog/2012/09/05/quantum-python"&gt;followup post&lt;/a&gt;, I show how
these tools can be used to generate an animation of a simple Quantum
Mechanical system.&lt;/p&gt;</summary></entry><entry><title>Memoryview Benchmarks 2</title><link href="/blog/2012/08/16/memoryview-benchmarks-2/" rel="alternate"></link><updated>2012-08-16T14:19:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-08-16:blog/2012/08/16/memoryview-benchmarks-2/</id><summary type="html">&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;In the &lt;a href="/blog/2012/08/08/memoryview-benchmarks/"&gt;previous post&lt;/a&gt;, I explored
how cython typed memoryviews can be used to speed up repeated array
operations.  It became clear that typed memoryviews are superior to
the ndarray syntax for slicing, and as fast as raw pointers for single
element access.  In the comments, Mathieu brought up an interesting
question: is the ndarray syntax as good as typed memoryviews if you're
not doing slicing?&lt;/p&gt;
&lt;p&gt;The answer turns out to be yes, &lt;em&gt;unless&lt;/em&gt; the compiler tries to inline your
function.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;h3&gt;Inlined Memoryview&lt;/h3&gt;
&lt;p&gt;We'll use a slightly simpler benchmark script here for simplicity.  We'll
use inlined typed memoryviews for the inner function, and call this function
within an outer loop:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;inner_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loop_1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;[&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mf"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c"&gt;# this should be inlined by the compiler&lt;/span&gt;
        &lt;span class="n"&gt;inner_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The inner function is called &lt;code&gt;N&lt;/code&gt; times.  We've used the "inline" keyword here:
it turns out this is optional with common compiler optimizations turned on.
&lt;code&gt;gcc&lt;/code&gt; and other compilers are smart enough to figure out that this function
should be inlined, even if the cython code doesn't mark it as such.  Timing
the function on one million loops gives us our comparison benchmark:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;%timeit loop_1(1E6)&lt;/span&gt;
&lt;span class="mi"&gt;100000&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;10.1&lt;/span&gt; &lt;span class="n"&gt;us&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Just over a millisecond to perform this loop one million times.&lt;/p&gt;
&lt;h3&gt;Non-inlined Memoryview&lt;/h3&gt;
&lt;p&gt;Because the compilers are generally so smart, we actually need to be a bit
clever to make sure our function is &lt;em&gt;not&lt;/em&gt; inlined.  We'll do that through
a switch statement in the loop call, which selects between two possible
inner functions.  This may seem a bit contrived, but it could come up
in practice: for example, if we wanted to create a KDTree for nearest neighbor
searches which can use one of several distance metrics within a single tree
framework, we might be tempted to try a solution like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;

&lt;span class="k"&gt;ctypedef&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;inner_func_ptr&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;inner_func_1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;inner_func_2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loop_2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c"&gt;# use a switch to ensure that inlining can&amp;#39;t happen: compilers&lt;/span&gt;
    &lt;span class="c"&gt;# are usually smart enough to figure it out otherwise.&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;inner_func_ptr&lt;/span&gt; &lt;span class="nf"&gt;func&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inner_func_1&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inner_func_2&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;[&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mf"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;By adding the switch function, it means the compiler cannot know at compile
time which of the inner functions will be used in the loop, and they
cannot be inlined.  The timing results are as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;%timeit loop_2(1E6)&lt;/span&gt;
&lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;22.9&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using a non-inlined function makes things significantly slower in this case!
So, if you're repeatedly calling a small function, inlining can be &lt;em&gt;very&lt;/em&gt;
important for optimal execution times.&lt;/p&gt;
&lt;h3&gt;The Problem with ndarray&lt;/h3&gt;
&lt;p&gt;It turns out that beyond slicing, the problem with the ndarray type is that
multi-dimensional arrays require relatively expensive buffer checks whenever
a function is called.  This causes similar code with ndarrays to be
significantly slower:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;inner_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ndim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loop_3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;switch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;ndarray&lt;/span&gt;[&lt;span class="nf"&gt;double&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;ndim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mf"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;inner_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Compiling this gives the following warning:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;warning&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Buffer&lt;/span&gt; &lt;span class="n"&gt;unpacking&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;optimized&lt;/span&gt; &lt;span class="n"&gt;away&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The result of this buffer unpacking in each loop is a much slower execution
time:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;%timeit loop_3(1E6)&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;617&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is about 30 times slower than the non-inlined version of the memoryview,
and 6000 times slower than the inlined memoryview above!
Is there any way around this?
Well, there are two options: raw pointers, or explicit inlining in the
code (that is, copying and pasting your code).  Both options will have
speeds similar to that of the inlined memoryviews, but each solution
is inconvenient in its own way.&lt;/p&gt;
&lt;p&gt;So why wouldn't you use memoryviews?  Well, several projects strive to
remain compatible with python 2.4 (one example is scipy) and python 2.4 is
not compatible with cython's typed memoryviews.  Other projects seek to
remain compatible with earlier cython versions which don't support
the relatively new memoryview syntax.
In these situations, one of the two partial solutions above
probably need to be used.  In practice, I have usually resorted to passing
around raw pointers.&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;Here are the timings we found above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inlined memoryviews: 0.1 ms&lt;/li&gt;
&lt;li&gt;Non-inlined memoryviews: 22.9 ms&lt;/li&gt;
&lt;li&gt;Inlined ndarray: 617 ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So we see yet another reason that typed memoryviews are superior to
the ndarray syntax: they not only have very speedy slicing, but also
play well with the compiler's inlining optimization.  Granted, these
time differences will be insignificant if your inlined function does
some non-negligible amount of computation, but there may be situations
where this affects things.&lt;/p&gt;
&lt;h3&gt;Back to my problem&lt;/h3&gt;
&lt;p&gt;If you recall, I started all of this because I wanted to create a binary tree
that can compute pairwise distances with arbitrary distance metrics.  Where
do these results put me?  Not in a great position, it turns out.  Abstracting
out the distance function so that the same machinery can be used with
different functions will lead to speed penalties from the inability to inline.
C++ libraries accomplish this through compile-time conditionals (i.e. templates)
but cython doesn't have this capability.  Duplicating the tree
framework with a new hard-coded (and thus inlinable) distance metric may
be the only option.  That, or wrapping a templated C++ implementation.&lt;/p&gt;
&lt;p&gt;All of the above scripts are available as an ipython
notebook: &lt;a href="/downloads/notebooks/memview_bench_2.ipynb"&gt;memview_bench_2.ipynb&lt;/a&gt;.
For information on how to view this file, see the
&lt;a href="http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html"&gt;IPython page&lt;/a&gt;
Alternatively, you can view this notebook (but not modify it) using the
nbviewer &lt;a href="http://nbviewer.ipython.org/url/jakevdp.github.com/downloads/notebooks/memview_bench_2.ipynb"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary></entry><entry><title>Memoryview Benchmarks</title><link href="/blog/2012/08/08/memoryview-benchmarks/" rel="alternate"></link><updated>2012-08-08T18:50:00-07:00</updated><author><name>Jake Vanderplas</name></author><id>tag:,2012-08-08:blog/2012/08/08/memoryview-benchmarks/</id><summary type="html">&lt;hr /&gt;
&lt;!-- PELICAN_BEGIN_SUMMARY --&gt;

&lt;p&gt;There was recently a &lt;a href="https://groups.google.com/forum/?fromgroups#!topic/cython-users/8uuxjB_wbBQ[1-25]" title="cython-users archive"&gt;thread&lt;/a&gt;
on cython-users which caught my eye.  It has to do with 
&lt;a href="http://docs.cython.org/src/userguide/memoryviews.html"&gt;memoryviews&lt;/a&gt;, a new
way of working with memory buffers in cython.&lt;/p&gt;
&lt;p&gt;I've been thinking recently about how to do fast
and flexible memory buffer access in cython.  I contributed the
&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html"&gt;BallTree&lt;/a&gt;
implementation for nearest neighbors searching in
&lt;a href="http://www.scikit-learn.org"&gt;scikit-learn&lt;/a&gt;, and have been actively thinking
about how to make it faster and more flexible, including adding the ability
to specify distance metrics other than euclidean and minkowski.&lt;/p&gt;
&lt;p&gt;In order to accomplish this, I'd like to have a set of distance metric
functions which take two vectors and compute a distance.  There would
be many functions with similar call signatures which could then be
plugged into a code that would iterate over a set of vectors and
compute the appropriate distances.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;h3&gt;Pure python version&lt;/h3&gt;
&lt;p&gt;In pure python, the implementation described above might look something
like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# memview_bench_v1.py&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This looks promising.  Let's create a function based on this which will compute
the pairwise distance between all points in a matrix (this is similar
to &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html"&gt;pairwise_distances&lt;/a&gt; in scikit-learn or
&lt;a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html"&gt;pdist&lt;/a&gt; in scipy).  The simple form of the function might look
like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# memview_bench_v1 (continued)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_dim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;

    &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We could exploit symmetry to reduce the number of computations required, but
we'll skip that step for now: this simple version of the function will give
us a good benchmark for comparison with alternatives below.  Using the
&lt;code&gt;timeit&lt;/code&gt; magic in ipython, we can learn how fast this implementation is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;memview_bench_v1&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;6.51&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It takes nearly seven seconds to compute 250,000 distances.  This is much
too slow.&lt;/p&gt;
&lt;h3&gt;Cython Speedup&lt;/h3&gt;
&lt;p&gt;Perhaps we can speed this up using cython declarations.  Before typed
memoryviews were added in cython 0.16, the way to quickly index numpy
arrays in cython was through the numpy specific syntax, adding type
information to each array that specifies its data type, its dimension, and
its order:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# memview_bench.pyx&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;libc.math&lt;/span&gt; &lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;

&lt;span class="c"&gt;# define a function pointer to a metric&lt;/span&gt;
&lt;span class="k"&gt;ctypedef&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;metric_ptr&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ndim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ndim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;d&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;N&lt;/span&gt;

    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="c"&gt;# assume x2 has the same shape as x1.  This could be dangerous!&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ndim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;metric_ptr&lt;/span&gt; &lt;span class="nf"&gt;dist_func&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;dist_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unrecognized metric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;n_samples&lt;/span&gt;
    &lt;span class="n"&gt;n_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;ndarray&lt;/span&gt;[&lt;span class="nf"&gt;double&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;ndim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                            &lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dist_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice that we're essentially running the same code, except we have added
type identifiers to speed up function calls and loops.  The &lt;code&gt;mode='c'&lt;/code&gt;
argument in the &lt;code&gt;np.ndarray&lt;/code&gt; type says that the array is contiguous in
memory, and C-ordered.&lt;/p&gt;
&lt;p&gt;For reference, this can be compiled in-place by running
&lt;code&gt;python setup.py build_ext --inplace&lt;/code&gt; with the following
setup.py file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# setup.py&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;distutils.core&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;setup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;distutils.extension&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Extension&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;Cython.Distutils&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;build_ext&lt;/span&gt;

&lt;span class="n"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;memview_bench_v2&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmdclass&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;build_ext&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;build_ext&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
      &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1.0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;ext_modules&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;.pyx&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])],&lt;/span&gt;
      &lt;span class="n"&gt;include_dirs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_include&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_include&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;numpy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We'll time the resulting function on the same sized array as we did previously:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;memview_bench_v2&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;668&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That's a factor of 10 speedup over the pure python version!  It turns out,
though, that we can do better.  In particular, the slicing operation when
we call &lt;code&gt;X[i]&lt;/code&gt; and &lt;code&gt;X[j]&lt;/code&gt; must generate a new numpy array each time, which
leads to a lot of python overhead in reference counting, etc.  This is the
reason that the cython team introduced typed memoryviews in cython v0.16.&lt;/p&gt;
&lt;h3&gt;Typed Memoryviews&lt;/h3&gt;
&lt;p&gt;The equivalent of the above code using typed memoryviews looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# memview_bench_v3.pyx&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;libc.math&lt;/span&gt; &lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;

&lt;span class="c"&gt;# define a function pointer to a metric&lt;/span&gt;
&lt;span class="k"&gt;ctypedef&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;metric_ptr&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;d&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;N&lt;/span&gt;

    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="c"&gt;# assume x2 has the same shape as x1.  This could be dangerous!&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;metric_ptr&lt;/span&gt; &lt;span class="nf"&gt;dist_func&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;dist_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unrecognized metric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;n_samples&lt;/span&gt;
    &lt;span class="n"&gt;n_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;[&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dist_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The only change is that instead of using the &lt;code&gt;np.ndarray[...]&lt;/code&gt; type specifier,
we use the typed memoryview &lt;code&gt;double[:, ::1]&lt;/code&gt; specifier.  The &lt;code&gt;::1&lt;/code&gt; in the
second position means that we are passing a two-dimensional array, which
is contiguous and C-ordered.  We time the results and see the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;memview_bench_v3&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This gives another factor of 30 improvement over the previous version, simply
by switching to typed memoryviews rather than the numpy interface.  Still,
our function is creating memoryview objects each time we slice the array.  We
can determine how much overhead this is generating by using raw C pointers
instead.  It is not as clean, but it should be very fast:&lt;/p&gt;
&lt;h3&gt;Raw Pointers&lt;/h3&gt;
&lt;p&gt;The fundamental benchmark for this sort of operation should be working
directly with the pointers themselves.  While this is not a very "pythonic"
way of doing things, it does lead to very fast code, as we will see:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# memview_bench_v4.pyx&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;libc.math&lt;/span&gt; &lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;

&lt;span class="c"&gt;# define a function pointer to a metric&lt;/span&gt;
&lt;span class="k"&gt;ctypedef&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;metric_ptr&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;d&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;

    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;metric_ptr&lt;/span&gt; &lt;span class="nf"&gt;dist_func&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;dist_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unrecognized metric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;n_dim&lt;/span&gt;
    &lt;span class="n"&gt;n_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;n_dim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;[&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;* &lt;span class="nf"&gt;Dptr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;* &lt;span class="nf"&gt;Xptr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;Dptr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;n_samples&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dist_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Xptr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;n_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                &lt;span class="n"&gt;Xptr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;n_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                &lt;span class="n"&gt;n_dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Instead of passing around slices of arrays, we've accessed the raw memory
buffer using C pointer syntax.  This is not as easy to read, and can lead
to &lt;code&gt;glibc&lt;/code&gt; errors or segmentation faults if we're not careful.  Testing
this implementation, we find that it is extremely fast:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;memview_bench_v4&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2.47&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is another factor of 10 faster than the memoryview benchmark above!
Essentially, what this is telling us is that creating a memoryview slice
takes about 0.02 / 500,000 = 40 nanoseconds on our machine.  This is extremely
fast, but because we're performing this operation half a million times, the
cost of the allocations is significant compared to the rest of our
computation.  If our vectors were, say, length 1000, this cost may not be
a significant percentage of the total cost.&lt;/p&gt;
&lt;p&gt;So what are we left with?  Do we need to use raw pointers in all circumstances
when working with collections of small vectors?  Perhaps not.&lt;/p&gt;
&lt;h3&gt;A Faster Implementation with Memoryviews&lt;/h3&gt;
&lt;p&gt;The creation of memoryview slices, though extremely fast, is causing a problem
simply because we're creating so many slices.  Here is an alternative which
uses no raw pointers, but matches the speed of raw pointers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# memview_bench_v5.pyx&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;libc.math&lt;/span&gt; &lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;
&lt;span class="k"&gt;cimport&lt;/span&gt; &lt;span class="nn"&gt;cython&lt;/span&gt;

&lt;span class="c"&gt;# define a function pointer to a metric&lt;/span&gt;
&lt;span class="k"&gt;ctypedef&lt;/span&gt; &lt;span class="n"&gt;double&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;metric_ptr&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intp_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intp_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;euclidean_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intp_t&lt;/span&gt; &lt;span class="n"&gt;i1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intp_t&lt;/span&gt; &lt;span class="n"&gt;i2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;d&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;j&lt;/span&gt;

    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
        &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tmp&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundscheck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@cython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wraparound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;double&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;metric_ptr&lt;/span&gt; &lt;span class="nf"&gt;dist_func&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;dist_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;euclidean_distance&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;unrecognized metric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;np&lt;/span&gt;.&lt;span class="kt"&gt;intp_t&lt;/span&gt; &lt;span class="nf"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;n_dim&lt;/span&gt;
    &lt;span class="n"&gt;n_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;n_dim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;cdef&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;[&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dist_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Timing this implementation we find the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;memview_bench_v5&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="n"&gt;pairwise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2.45&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Just as fast as using raw pointers, but much cleaner and easier to read.&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;Here are the timing results we've seen above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Python + numpy&lt;/strong&gt;: 6510 ms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cython + numpy&lt;/strong&gt;: 668 ms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cython + memviews (slicing)&lt;/strong&gt;: 22 ms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cython + raw pointers&lt;/strong&gt;: 2.47 ms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cython + memviews (no slicing)&lt;/strong&gt;: 2.45 ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So what have we learned here?  First of all, typed memoryviews are fast.
Blazing fast.  If used correctly, they can be comparable to raw pointers,
but are much cleaner easier to debug.  For example, in the last
version, if we ran into a memory error we could simply turn on bounds-checking
and quickly find the source of the problem.  Slicing with memoryviews is
also fast, but should be used carefully if your operation time on each slice
is compararable to the cost of building the slice.&lt;/p&gt;
&lt;p&gt;The moral of the story?  &lt;em&gt;Use typed memoryviews.&lt;/em&gt;  It will lead to fast cython
code which is cleaner, more readable, and more easily debuggable than any other
alternative.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: All of the above scripts are now available as an ipython
notebook: &lt;a href="/downloads/notebooks/memview_bench.ipynb"&gt;memview_bench.ipynb&lt;/a&gt;.
For information on how to view this file, see the
&lt;a href="http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html"&gt;IPython page&lt;/a&gt;
Alternatively, you can view this notebook (but not modify it) using the
nbviewer &lt;a href="http://nbviewer.ipython.org/url/jakevdp.github.com/downloads/notebooks/memview_bench.ipynb"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thanks to Dave for the tip.&lt;/p&gt;</summary></entry></feed>